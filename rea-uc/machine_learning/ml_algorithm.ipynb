{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/CSV/correct_envelope_components.csv\",encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosing_structure</th>\n",
       "      <th>material</th>\n",
       "      <th>structure_heat_loss_coefficient</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>area</th>\n",
       "      <th>total_structure_heat_loss_coefficient</th>\n",
       "      <th>total_energy_consumption</th>\n",
       "      <th>total_area</th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walls</td>\n",
       "      <td>Calcium silicate bricks/Decoration</td>\n",
       "      <td>168.60</td>\n",
       "      <td>18072.0</td>\n",
       "      <td>137.70</td>\n",
       "      <td>2475.00</td>\n",
       "      <td>260187.0</td>\n",
       "      <td>2395.90</td>\n",
       "      <td>1000660229001</td>\n",
       "      <td>1.224401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walls</td>\n",
       "      <td>Calcium silicate bricks/Decoration</td>\n",
       "      <td>1050.30</td>\n",
       "      <td>112580.0</td>\n",
       "      <td>878.50</td>\n",
       "      <td>2475.00</td>\n",
       "      <td>260187.0</td>\n",
       "      <td>2395.90</td>\n",
       "      <td>1000660229001</td>\n",
       "      <td>1.195561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roof/attic</td>\n",
       "      <td>Hollow-core reinforced concrete/Wool</td>\n",
       "      <td>85.90</td>\n",
       "      <td>9204.0</td>\n",
       "      <td>470.90</td>\n",
       "      <td>2475.00</td>\n",
       "      <td>260187.0</td>\n",
       "      <td>2395.90</td>\n",
       "      <td>1000660229001</td>\n",
       "      <td>0.182417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basement/slab</td>\n",
       "      <td>Hollow-core reinforced concrete/Slag</td>\n",
       "      <td>238.10</td>\n",
       "      <td>25524.0</td>\n",
       "      <td>381.80</td>\n",
       "      <td>2475.00</td>\n",
       "      <td>260187.0</td>\n",
       "      <td>2395.90</td>\n",
       "      <td>1000660229001</td>\n",
       "      <td>0.623625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood (double glazed)</td>\n",
       "      <td>298.90</td>\n",
       "      <td>32039.0</td>\n",
       "      <td>107.70</td>\n",
       "      <td>2475.00</td>\n",
       "      <td>260187.0</td>\n",
       "      <td>2395.90</td>\n",
       "      <td>1000660229001</td>\n",
       "      <td>2.775302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>Basement/slab</td>\n",
       "      <td>Reinforced concrete/Expanded clay</td>\n",
       "      <td>167.72</td>\n",
       "      <td>9806.0</td>\n",
       "      <td>182.30</td>\n",
       "      <td>1092.99</td>\n",
       "      <td>90422.0</td>\n",
       "      <td>1063.13</td>\n",
       "      <td>1000740251001</td>\n",
       "      <td>0.920022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>doors</td>\n",
       "      <td>Wood</td>\n",
       "      <td>7.11</td>\n",
       "      <td>416.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1092.99</td>\n",
       "      <td>90422.0</td>\n",
       "      <td>1063.13</td>\n",
       "      <td>1000740251001</td>\n",
       "      <td>2.799213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood (double glazed)</td>\n",
       "      <td>64.61</td>\n",
       "      <td>5666.0</td>\n",
       "      <td>26.92</td>\n",
       "      <td>1092.99</td>\n",
       "      <td>90422.0</td>\n",
       "      <td>1063.13</td>\n",
       "      <td>1000740251001</td>\n",
       "      <td>2.400074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>windows</td>\n",
       "      <td>PVC</td>\n",
       "      <td>79.66</td>\n",
       "      <td>6986.0</td>\n",
       "      <td>61.28</td>\n",
       "      <td>1092.99</td>\n",
       "      <td>90422.0</td>\n",
       "      <td>1063.13</td>\n",
       "      <td>1000740251001</td>\n",
       "      <td>1.299935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood (double glazed)</td>\n",
       "      <td>10.92</td>\n",
       "      <td>638.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1092.99</td>\n",
       "      <td>90422.0</td>\n",
       "      <td>1063.13</td>\n",
       "      <td>1000740251001</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     enclosing_structure                              material  \\\n",
       "0                  Walls    Calcium silicate bricks/Decoration   \n",
       "1                  Walls    Calcium silicate bricks/Decoration   \n",
       "2             Roof/attic  Hollow-core reinforced concrete/Wool   \n",
       "3          Basement/slab  Hollow-core reinforced concrete/Slag   \n",
       "4                windows                  Wood (double glazed)   \n",
       "...                  ...                                   ...   \n",
       "3553       Basement/slab     Reinforced concrete/Expanded clay   \n",
       "3554               doors                                  Wood   \n",
       "3555             windows                  Wood (double glazed)   \n",
       "3556             windows                                   PVC   \n",
       "3557             windows                  Wood (double glazed)   \n",
       "\n",
       "      structure_heat_loss_coefficient  energy_consumption    area  \\\n",
       "0                              168.60             18072.0  137.70   \n",
       "1                             1050.30            112580.0  878.50   \n",
       "2                               85.90              9204.0  470.90   \n",
       "3                              238.10             25524.0  381.80   \n",
       "4                              298.90             32039.0  107.70   \n",
       "...                               ...                 ...     ...   \n",
       "3553                           167.72              9806.0  182.30   \n",
       "3554                             7.11               416.0    2.54   \n",
       "3555                            64.61              5666.0   26.92   \n",
       "3556                            79.66              6986.0   61.28   \n",
       "3557                            10.92               638.0    3.90   \n",
       "\n",
       "      total_structure_heat_loss_coefficient  total_energy_consumption  \\\n",
       "0                                   2475.00                  260187.0   \n",
       "1                                   2475.00                  260187.0   \n",
       "2                                   2475.00                  260187.0   \n",
       "3                                   2475.00                  260187.0   \n",
       "4                                   2475.00                  260187.0   \n",
       "...                                     ...                       ...   \n",
       "3553                                1092.99                   90422.0   \n",
       "3554                                1092.99                   90422.0   \n",
       "3555                                1092.99                   90422.0   \n",
       "3556                                1092.99                   90422.0   \n",
       "3557                                1092.99                   90422.0   \n",
       "\n",
       "      total_area  cadastre_number         U  \n",
       "0        2395.90    1000660229001  1.224401  \n",
       "1        2395.90    1000660229001  1.195561  \n",
       "2        2395.90    1000660229001  0.182417  \n",
       "3        2395.90    1000660229001  0.623625  \n",
       "4        2395.90    1000660229001  2.775302  \n",
       "...          ...              ...       ...  \n",
       "3553     1063.13    1000740251001  0.920022  \n",
       "3554     1063.13    1000740251001  2.799213  \n",
       "3555     1063.13    1000740251001  2.400074  \n",
       "3556     1063.13    1000740251001  1.299935  \n",
       "3557     1063.13    1000740251001  2.800000  \n",
       "\n",
       "[3558 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windows          1017\n",
       "Walls             983\n",
       "Roof/attic        601\n",
       "Basement/slab     488\n",
       "doors             469\n",
       "Name: enclosing_structure, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['enclosing_structure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['enclosing_structure'].str.contains('walls', case=False)\n",
    "df.loc[mask, 'enclosing_structure'] = 'Walls'\n",
    "df.dropna(subset=['area'],inplace=True)\n",
    "df= df[df['area'] != 0]\n",
    "df['U'] = df['structure_heat_loss_coefficient']/df['area']\n",
    "df\n",
    "df.to_csv(\"datasets/CSV/correct_envelope_components.csv\",encoding=\"utf-8\",index=False)\n",
    "\n",
    "#RESTRUCTURING ENVELOPE COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    315.000000\n",
       "mean      11.295238\n",
       "std        3.322162\n",
       "min        6.000000\n",
       "25%        9.000000\n",
       "50%       11.000000\n",
       "75%       13.000000\n",
       "max       26.000000\n",
       "Name: enclosing_structure, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_counts = df.groupby('cadastre_number')['enclosing_structure'].count().sort_values(ascending=False)\n",
    "grouped_= df.groupby('cadastre_number')\n",
    "\n",
    "group_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enclosing_structure</th>\n",
       "      <th>material</th>\n",
       "      <th>structure_heat_loss_coefficient</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>area</th>\n",
       "      <th>total_structure_heat_loss_coefficient</th>\n",
       "      <th>total_energy_consumption</th>\n",
       "      <th>total_area</th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>windows</td>\n",
       "      <td>PVC</td>\n",
       "      <td>1404.14</td>\n",
       "      <td>127584.09</td>\n",
       "      <td>877.59</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>1.599995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood</td>\n",
       "      <td>979.02</td>\n",
       "      <td>88956.50</td>\n",
       "      <td>326.34</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>doors</td>\n",
       "      <td>Metal</td>\n",
       "      <td>63.43</td>\n",
       "      <td>5763.43</td>\n",
       "      <td>35.24</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>1.799943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>windows</td>\n",
       "      <td>PVC</td>\n",
       "      <td>3607.76</td>\n",
       "      <td>327811.18</td>\n",
       "      <td>2254.85</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood</td>\n",
       "      <td>2082.09</td>\n",
       "      <td>189184.53</td>\n",
       "      <td>694.03</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>windows</td>\n",
       "      <td>Wood</td>\n",
       "      <td>1159.50</td>\n",
       "      <td>105355.42</td>\n",
       "      <td>386.50</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>doors</td>\n",
       "      <td>Wood</td>\n",
       "      <td>235.97</td>\n",
       "      <td>21440.89</td>\n",
       "      <td>98.32</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>2.400020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Basement/slab</td>\n",
       "      <td>Hollow-core reinforced concrete/Expanded clay/...</td>\n",
       "      <td>1517.46</td>\n",
       "      <td>137880.66</td>\n",
       "      <td>3701.11</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>0.410001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>Walls</td>\n",
       "      <td>Autoclaved aerated concrete</td>\n",
       "      <td>15341.04</td>\n",
       "      <td>1393929.85</td>\n",
       "      <td>17433.00</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Walls</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>1415.99</td>\n",
       "      <td>128660.82</td>\n",
       "      <td>382.70</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Walls</td>\n",
       "      <td>Autoclaved aerated concrete  (insulation)</td>\n",
       "      <td>187.14</td>\n",
       "      <td>17004.06</td>\n",
       "      <td>584.82</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>0.319996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Roof/attic</td>\n",
       "      <td>Hollow-core reinforced concrete/Wood wool (ins...</td>\n",
       "      <td>820.25</td>\n",
       "      <td>74530.21</td>\n",
       "      <td>3566.30</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>Roof/attic</td>\n",
       "      <td>Hollow-core reinforced concrete/Concrete</td>\n",
       "      <td>230.53</td>\n",
       "      <td>20946.60</td>\n",
       "      <td>134.81</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>1.710036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Roof/attic</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>443.84</td>\n",
       "      <td>40328.55</td>\n",
       "      <td>95.45</td>\n",
       "      <td>31644.25</td>\n",
       "      <td>2875285.16</td>\n",
       "      <td>30571.06</td>\n",
       "      <td>1001070529001</td>\n",
       "      <td>4.649974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     enclosing_structure                                           material  \\\n",
       "1523             windows                                                PVC   \n",
       "1524             windows                                               Wood   \n",
       "1525               doors                                              Metal   \n",
       "1526             windows                                                PVC   \n",
       "1527             windows                                               Wood   \n",
       "1528             windows                                               Wood   \n",
       "1529               doors                                               Wood   \n",
       "1530       Basement/slab  Hollow-core reinforced concrete/Expanded clay/...   \n",
       "1531               Walls                        Autoclaved aerated concrete   \n",
       "1532               Walls                                           Concrete   \n",
       "1533               Walls          Autoclaved aerated concrete  (insulation)   \n",
       "1534          Roof/attic  Hollow-core reinforced concrete/Wood wool (ins...   \n",
       "1535          Roof/attic           Hollow-core reinforced concrete/Concrete   \n",
       "1536          Roof/attic                                           Concrete   \n",
       "\n",
       "      structure_heat_loss_coefficient  energy_consumption      area  \\\n",
       "1523                          1404.14           127584.09    877.59   \n",
       "1524                           979.02            88956.50    326.34   \n",
       "1525                            63.43             5763.43     35.24   \n",
       "1526                          3607.76           327811.18   2254.85   \n",
       "1527                          2082.09           189184.53    694.03   \n",
       "1528                          1159.50           105355.42    386.50   \n",
       "1529                           235.97            21440.89     98.32   \n",
       "1530                          1517.46           137880.66   3701.11   \n",
       "1531                         15341.04          1393929.85  17433.00   \n",
       "1532                          1415.99           128660.82    382.70   \n",
       "1533                           187.14            17004.06    584.82   \n",
       "1534                           820.25            74530.21   3566.30   \n",
       "1535                           230.53            20946.60    134.81   \n",
       "1536                           443.84            40328.55     95.45   \n",
       "\n",
       "      total_structure_heat_loss_coefficient  total_energy_consumption  \\\n",
       "1523                               31644.25                2875285.16   \n",
       "1524                               31644.25                2875285.16   \n",
       "1525                               31644.25                2875285.16   \n",
       "1526                               31644.25                2875285.16   \n",
       "1527                               31644.25                2875285.16   \n",
       "1528                               31644.25                2875285.16   \n",
       "1529                               31644.25                2875285.16   \n",
       "1530                               31644.25                2875285.16   \n",
       "1531                               31644.25                2875285.16   \n",
       "1532                               31644.25                2875285.16   \n",
       "1533                               31644.25                2875285.16   \n",
       "1534                               31644.25                2875285.16   \n",
       "1535                               31644.25                2875285.16   \n",
       "1536                               31644.25                2875285.16   \n",
       "\n",
       "      total_area  cadastre_number         U  \n",
       "1523    30571.06    1001070529001  1.599995  \n",
       "1524    30571.06    1001070529001  3.000000  \n",
       "1525    30571.06    1001070529001  1.799943  \n",
       "1526    30571.06    1001070529001  1.600000  \n",
       "1527    30571.06    1001070529001  3.000000  \n",
       "1528    30571.06    1001070529001  3.000000  \n",
       "1529    30571.06    1001070529001  2.400020  \n",
       "1530    30571.06    1001070529001  0.410001  \n",
       "1531    30571.06    1001070529001  0.880000  \n",
       "1532    30571.06    1001070529001  3.700000  \n",
       "1533    30571.06    1001070529001  0.319996  \n",
       "1534    30571.06    1001070529001  0.230000  \n",
       "1535    30571.06    1001070529001  1.710036  \n",
       "1536    30571.06    1001070529001  4.649974  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_.get_group(1001070529001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Group by cadastre_number and component type\n",
    "grouped_data = df.groupby(['cadastre_number', 'enclosing_structure'])\n",
    "\n",
    "# Define a function to aggregate the data for each group\n",
    "def aggregate_data(group):\n",
    "    area_sum = group['area'].sum()\n",
    "    u_value = np.average(group['U'], weights=group['area'])\n",
    "    return pd.Series([area_sum, u_value], index=['area', 'U'])\n",
    "\n",
    "# Apply the aggregation function to each group\n",
    "aggregated_data = grouped_data.apply(aggregate_data)\n",
    "\n",
    "\n",
    "# Pivot the data to reshape it into the desired format\n",
    "pivoted_data = aggregated_data.reset_index().pivot(index='cadastre_number', columns='enclosing_structure')\n",
    "\n",
    "\n",
    "# Rename the columns to match the desired format\n",
    "pivoted_data.columns = [f'{col[0]}_{col[1]}' for col in pivoted_data.columns]\n",
    "\n",
    "# Reset the index to make the cadastre_number a column\n",
    "pivoted_data = pivoted_data.reset_index()\n",
    "\n",
    "pivoted_data.fillna(0, inplace=True)\n",
    "# Save the result to a new CSV file\n",
    "pivoted_data.to_csv('datasets/CSV/output_aggregated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pivoted_data[(pivoted_data == 0).any(axis=1)]\n",
    "\n",
    "check.to_csv('datasets/CSV/buildings_with_zero_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_data = pd.read_csv('datasets/CSV/output_aggregated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01000702031001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01000660229001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316/318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01000660171001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316/318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01000660177001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01000170149001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4595.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6519.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>01000722064001</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3588.1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5126.3</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>01000860273001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>01000840185001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>01000280019001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>01000740251001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316/318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cadastre_number  floors  useful_area  apartments  total_area    serie\n",
       "0    01000702031001     9.0      13077.4       252.0     15673.6      101\n",
       "1    01000660229001     5.0       1930.5        45.0      2478.7  316/318\n",
       "2    01000660171001     5.0       1927.5        45.0      2477.7  316/318\n",
       "3    01000660177001     5.0       1583.7        30.0      2041.9      103\n",
       "4    01000170149001     5.0       4595.3       120.0      6519.2        0\n",
       "..              ...     ...          ...         ...         ...      ...\n",
       "268  01000722064001    13.0       3588.1       102.0      5126.3      101\n",
       "269  01000860273001     4.0       1201.1        12.0      1433.3        0\n",
       "270  01000840185001     3.0        586.4        10.0       771.5        0\n",
       "271  01000280019001     4.0        665.1        12.0       750.7        0\n",
       "272  01000740251001     3.0        519.1        12.0       732.1  316/318\n",
       "\n",
       "[273 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine(\"postgresql://rea:rea@147.102.6.64:5555\")\n",
    "query = \"SELECT * FROM ml_input\"\n",
    "ml_input = pd.read_sql(query, engine)\n",
    "ml_input.to_csv('datasets/CSV/ml_input.csv', index=False)\n",
    "\n",
    "ml_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serie\n",
       "0          97\n",
       "316/318    71\n",
       "103        18\n",
       "467        18\n",
       "602        16\n",
       "110        15\n",
       "101        10\n",
       "464        10\n",
       "119         9\n",
       "104         4\n",
       "102         4\n",
       "105         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_input['serie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serie\n",
       "0      97\n",
       "316    71\n",
       "103    18\n",
       "467    18\n",
       "602    16\n",
       "110    15\n",
       "101    10\n",
       "464    10\n",
       "119     9\n",
       "104     4\n",
       "102     4\n",
       "105     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_input['cadastre_number'] = ml_input['cadastre_number'].astype(int)\n",
    "ml_input['serie'] = ml_input['serie'].replace('316/318', '316')\n",
    "ml_input['serie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    273.000000\n",
       "mean      51.549451\n",
       "std       44.857519\n",
       "min        4.000000\n",
       "25%       18.000000\n",
       "50%       45.000000\n",
       "75%       71.000000\n",
       "max      396.000000\n",
       "Name: apartments, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_input.apartments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005800174</td>\n",
       "      <td>1054.00</td>\n",
       "      <td>1054.00</td>\n",
       "      <td>5935.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1332.00</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.799810</td>\n",
       "      <td>0.870008</td>\n",
       "      <td>2.835484</td>\n",
       "      <td>2.445420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009180056</td>\n",
       "      <td>812.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1125.07</td>\n",
       "      <td>14.52</td>\n",
       "      <td>406.91</td>\n",
       "      <td>0.965090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.193632</td>\n",
       "      <td>1.599862</td>\n",
       "      <td>1.613625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100047072001</td>\n",
       "      <td>310.20</td>\n",
       "      <td>320.50</td>\n",
       "      <td>1606.50</td>\n",
       "      <td>5.70</td>\n",
       "      <td>359.00</td>\n",
       "      <td>0.809994</td>\n",
       "      <td>0.887426</td>\n",
       "      <td>0.867918</td>\n",
       "      <td>3.192982</td>\n",
       "      <td>1.959331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100252014001</td>\n",
       "      <td>214.40</td>\n",
       "      <td>214.40</td>\n",
       "      <td>603.40</td>\n",
       "      <td>4.80</td>\n",
       "      <td>144.10</td>\n",
       "      <td>0.820009</td>\n",
       "      <td>0.840019</td>\n",
       "      <td>1.080013</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>1.905135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000050083001</td>\n",
       "      <td>650.21</td>\n",
       "      <td>635.24</td>\n",
       "      <td>1923.94</td>\n",
       "      <td>14.71</td>\n",
       "      <td>425.65</td>\n",
       "      <td>0.457929</td>\n",
       "      <td>0.900006</td>\n",
       "      <td>1.202054</td>\n",
       "      <td>2.895309</td>\n",
       "      <td>2.378456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1001242115001</td>\n",
       "      <td>927.00</td>\n",
       "      <td>927.00</td>\n",
       "      <td>1938.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>641.00</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>4.712500</td>\n",
       "      <td>2.183463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1001242120001</td>\n",
       "      <td>657.76</td>\n",
       "      <td>657.76</td>\n",
       "      <td>1544.91</td>\n",
       "      <td>12.00</td>\n",
       "      <td>552.00</td>\n",
       "      <td>0.478670</td>\n",
       "      <td>0.779996</td>\n",
       "      <td>1.388631</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.848062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1001270052001</td>\n",
       "      <td>563.20</td>\n",
       "      <td>626.60</td>\n",
       "      <td>1612.80</td>\n",
       "      <td>29.20</td>\n",
       "      <td>447.60</td>\n",
       "      <td>0.809996</td>\n",
       "      <td>0.790808</td>\n",
       "      <td>0.870213</td>\n",
       "      <td>3.555479</td>\n",
       "      <td>1.928262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1001272045001</td>\n",
       "      <td>177.13</td>\n",
       "      <td>1.19</td>\n",
       "      <td>481.57</td>\n",
       "      <td>2.10</td>\n",
       "      <td>96.64</td>\n",
       "      <td>0.840738</td>\n",
       "      <td>178.823529</td>\n",
       "      <td>1.280001</td>\n",
       "      <td>2.228571</td>\n",
       "      <td>2.322951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1001280091001</td>\n",
       "      <td>362.90</td>\n",
       "      <td>542.90</td>\n",
       "      <td>718.80</td>\n",
       "      <td>6.30</td>\n",
       "      <td>115.10</td>\n",
       "      <td>1.155690</td>\n",
       "      <td>0.850064</td>\n",
       "      <td>1.139955</td>\n",
       "      <td>4.460317</td>\n",
       "      <td>2.460469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cadastre_number  area_Basement/slab  area_Roof/attic  area_Walls   \n",
       "0         1005800174             1054.00          1054.00     5935.00  \\\n",
       "1         1009180056              812.08             0.00     1125.07   \n",
       "2       100047072001              310.20           320.50     1606.50   \n",
       "3       100252014001              214.40           214.40      603.40   \n",
       "4      1000050083001              650.21           635.24     1923.94   \n",
       "..               ...                 ...              ...         ...   \n",
       "310    1001242115001              927.00           927.00     1938.00   \n",
       "311    1001242120001              657.76           657.76     1544.91   \n",
       "312    1001270052001              563.20           626.60     1612.80   \n",
       "313    1001272045001              177.13             1.19      481.57   \n",
       "314    1001280091001              362.90           542.90      718.80   \n",
       "\n",
       "     area_doors  area_windows  U_Basement/slab  U_Roof/attic   U_Walls   \n",
       "0         62.00       1332.00         0.979791      0.799810  0.870008  \\\n",
       "1         14.52        406.91         0.965090      0.000000  1.193632   \n",
       "2          5.70        359.00         0.809994      0.887426  0.867918   \n",
       "3          4.80        144.10         0.820009      0.840019  1.080013   \n",
       "4         14.71        425.65         0.457929      0.900006  1.202054   \n",
       "..          ...           ...              ...           ...       ...   \n",
       "310       16.00        641.00         0.810248      0.810248  0.872291   \n",
       "311       12.00        552.00         0.478670      0.779996  1.388631   \n",
       "312       29.20        447.60         0.809996      0.790808  0.870213   \n",
       "313        2.10         96.64         0.840738    178.823529  1.280001   \n",
       "314        6.30        115.10         1.155690      0.850064  1.139955   \n",
       "\n",
       "      U_doors  U_windows  \n",
       "0    2.835484   2.445420  \n",
       "1    1.599862   1.613625  \n",
       "2    3.192982   1.959331  \n",
       "3    3.366667   1.905135  \n",
       "4    2.895309   2.378456  \n",
       "..        ...        ...  \n",
       "310  4.712500   2.183463  \n",
       "311  3.033333   1.848062  \n",
       "312  3.555479   1.928262  \n",
       "313  2.228571   2.322951  \n",
       "314  4.460317   2.460469  \n",
       "\n",
       "[315 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.150000e+02</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>315.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.886726e+11</td>\n",
       "      <td>577.355302</td>\n",
       "      <td>566.326394</td>\n",
       "      <td>1962.862321</td>\n",
       "      <td>36.376603</td>\n",
       "      <td>477.673667</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>1.380282</td>\n",
       "      <td>1.009271</td>\n",
       "      <td>2.872699</td>\n",
       "      <td>2.031106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.067054e+11</td>\n",
       "      <td>427.587144</td>\n",
       "      <td>450.149785</td>\n",
       "      <td>3535.105493</td>\n",
       "      <td>193.087323</td>\n",
       "      <td>444.046351</td>\n",
       "      <td>0.226895</td>\n",
       "      <td>10.045585</td>\n",
       "      <td>0.212668</td>\n",
       "      <td>0.763100</td>\n",
       "      <td>0.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.005800e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000581e+12</td>\n",
       "      <td>310.090000</td>\n",
       "      <td>264.590000</td>\n",
       "      <td>766.550000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>0.533510</td>\n",
       "      <td>0.685969</td>\n",
       "      <td>0.887092</td>\n",
       "      <td>2.296512</td>\n",
       "      <td>1.871827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000730e+12</td>\n",
       "      <td>484.600000</td>\n",
       "      <td>492.300000</td>\n",
       "      <td>1521.800000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>415.200000</td>\n",
       "      <td>0.628274</td>\n",
       "      <td>0.816928</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>2.878947</td>\n",
       "      <td>1.997856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000912e+12</td>\n",
       "      <td>711.350000</td>\n",
       "      <td>718.850000</td>\n",
       "      <td>2423.645000</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>631.175000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.921224</td>\n",
       "      <td>1.125422</td>\n",
       "      <td>3.370242</td>\n",
       "      <td>2.161741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.001280e+12</td>\n",
       "      <td>3701.110000</td>\n",
       "      <td>3796.560000</td>\n",
       "      <td>58344.000000</td>\n",
       "      <td>2714.910000</td>\n",
       "      <td>4539.310000</td>\n",
       "      <td>1.584164</td>\n",
       "      <td>178.823529</td>\n",
       "      <td>1.757632</td>\n",
       "      <td>4.720639</td>\n",
       "      <td>2.858623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cadastre_number  area_Basement/slab  area_Roof/attic    area_Walls  \\\n",
       "count     3.150000e+02          315.000000       315.000000    315.000000   \n",
       "mean      9.886726e+11          577.355302       566.326394   1962.862321   \n",
       "std       1.067054e+11          427.587144       450.149785   3535.105493   \n",
       "min       1.005800e+09            0.000000         0.000000      0.000000   \n",
       "25%       1.000581e+12          310.090000       264.590000    766.550000   \n",
       "50%       1.000730e+12          484.600000       492.300000   1521.800000   \n",
       "75%       1.000912e+12          711.350000       718.850000   2423.645000   \n",
       "max       1.001280e+12         3701.110000      3796.560000  58344.000000   \n",
       "\n",
       "        area_doors  area_windows  U_Basement/slab  U_Roof/attic     U_Walls  \\\n",
       "count   315.000000    315.000000       315.000000    315.000000  315.000000   \n",
       "mean     36.376603    477.673667         0.669181      1.380282    1.009271   \n",
       "std     193.087323    444.046351         0.226895     10.045585    0.212668   \n",
       "min       0.000000     27.500000         0.000000      0.000000    0.000000   \n",
       "25%       6.400000    182.500000         0.533510      0.685969    0.887092   \n",
       "50%      13.800000    415.200000         0.628274      0.816928    0.999821   \n",
       "75%      23.150000    631.175000         0.820000      0.921224    1.125422   \n",
       "max    2714.910000   4539.310000         1.584164    178.823529    1.757632   \n",
       "\n",
       "          U_doors   U_windows  \n",
       "count  315.000000  315.000000  \n",
       "mean     2.872699    2.031106  \n",
       "std      0.763100    0.269500  \n",
       "min      0.000000    1.300018  \n",
       "25%      2.296512    1.871827  \n",
       "50%      2.878947    1.997856  \n",
       "75%      3.370242    2.161741  \n",
       "max      4.720639    2.858623  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000702031001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000660229001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000660171001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000660177001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000170149001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4595.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6519.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1000722064001</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3588.1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5126.3</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1000860273001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1000840185001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1000280019001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1000740251001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cadastre_number  floors  useful_area  apartments  total_area serie\n",
       "0      1000702031001     9.0      13077.4       252.0     15673.6   101\n",
       "1      1000660229001     5.0       1930.5        45.0      2478.7   316\n",
       "2      1000660171001     5.0       1927.5        45.0      2477.7   316\n",
       "3      1000660177001     5.0       1583.7        30.0      2041.9   103\n",
       "4      1000170149001     5.0       4595.3       120.0      6519.2     0\n",
       "..               ...     ...          ...         ...         ...   ...\n",
       "268    1000722064001    13.0       3588.1       102.0      5126.3   101\n",
       "269    1000860273001     4.0       1201.1        12.0      1433.3     0\n",
       "270    1000840185001     3.0        586.4        10.0       771.5     0\n",
       "271    1000280019001     4.0        665.1        12.0       750.7     0\n",
       "272    1000740251001     3.0        519.1        12.0       732.1   316\n",
       "\n",
       "[272 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE ALL VALUES WITH 0 IN ANY COLUMN, AND THE OUTLIER THAT EXISTS WITH 396 APARTMENTS.\n",
    "ml_input = ml_input[ml_input.apartments != 396]\n",
    "ml_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005800174</td>\n",
       "      <td>1054.00</td>\n",
       "      <td>1054.00</td>\n",
       "      <td>5935.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1332.00</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.799810</td>\n",
       "      <td>0.870008</td>\n",
       "      <td>2.835484</td>\n",
       "      <td>2.445420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100047072001</td>\n",
       "      <td>310.20</td>\n",
       "      <td>320.50</td>\n",
       "      <td>1606.50</td>\n",
       "      <td>5.70</td>\n",
       "      <td>359.00</td>\n",
       "      <td>0.809994</td>\n",
       "      <td>0.887426</td>\n",
       "      <td>0.867918</td>\n",
       "      <td>3.192982</td>\n",
       "      <td>1.959331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100252014001</td>\n",
       "      <td>214.40</td>\n",
       "      <td>214.40</td>\n",
       "      <td>603.40</td>\n",
       "      <td>4.80</td>\n",
       "      <td>144.10</td>\n",
       "      <td>0.820009</td>\n",
       "      <td>0.840019</td>\n",
       "      <td>1.080013</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>1.905135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000050083001</td>\n",
       "      <td>650.21</td>\n",
       "      <td>635.24</td>\n",
       "      <td>1923.94</td>\n",
       "      <td>14.71</td>\n",
       "      <td>425.65</td>\n",
       "      <td>0.457929</td>\n",
       "      <td>0.900006</td>\n",
       "      <td>1.202054</td>\n",
       "      <td>2.895309</td>\n",
       "      <td>2.378456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000090005001</td>\n",
       "      <td>216.00</td>\n",
       "      <td>231.00</td>\n",
       "      <td>1108.00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>182.00</td>\n",
       "      <td>0.463426</td>\n",
       "      <td>0.601299</td>\n",
       "      <td>0.725271</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>1.743956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1001242115001</td>\n",
       "      <td>927.00</td>\n",
       "      <td>927.00</td>\n",
       "      <td>1938.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>641.00</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.810248</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>4.712500</td>\n",
       "      <td>2.183463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1001242120001</td>\n",
       "      <td>657.76</td>\n",
       "      <td>657.76</td>\n",
       "      <td>1544.91</td>\n",
       "      <td>12.00</td>\n",
       "      <td>552.00</td>\n",
       "      <td>0.478670</td>\n",
       "      <td>0.779996</td>\n",
       "      <td>1.388631</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.848062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1001270052001</td>\n",
       "      <td>563.20</td>\n",
       "      <td>626.60</td>\n",
       "      <td>1612.80</td>\n",
       "      <td>29.20</td>\n",
       "      <td>447.60</td>\n",
       "      <td>0.809996</td>\n",
       "      <td>0.790808</td>\n",
       "      <td>0.870213</td>\n",
       "      <td>3.555479</td>\n",
       "      <td>1.928262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1001272045001</td>\n",
       "      <td>177.13</td>\n",
       "      <td>1.19</td>\n",
       "      <td>481.57</td>\n",
       "      <td>2.10</td>\n",
       "      <td>96.64</td>\n",
       "      <td>0.840738</td>\n",
       "      <td>178.823529</td>\n",
       "      <td>1.280001</td>\n",
       "      <td>2.228571</td>\n",
       "      <td>2.322951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1001280091001</td>\n",
       "      <td>362.90</td>\n",
       "      <td>542.90</td>\n",
       "      <td>718.80</td>\n",
       "      <td>6.30</td>\n",
       "      <td>115.10</td>\n",
       "      <td>1.155690</td>\n",
       "      <td>0.850064</td>\n",
       "      <td>1.139955</td>\n",
       "      <td>4.460317</td>\n",
       "      <td>2.460469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cadastre_number  area_Basement/slab  area_Roof/attic  area_Walls   \n",
       "0         1005800174             1054.00          1054.00     5935.00  \\\n",
       "2       100047072001              310.20           320.50     1606.50   \n",
       "3       100252014001              214.40           214.40      603.40   \n",
       "4      1000050083001              650.21           635.24     1923.94   \n",
       "5      1000090005001              216.00           231.00     1108.00   \n",
       "..               ...                 ...              ...         ...   \n",
       "310    1001242115001              927.00           927.00     1938.00   \n",
       "311    1001242120001              657.76           657.76     1544.91   \n",
       "312    1001270052001              563.20           626.60     1612.80   \n",
       "313    1001272045001              177.13             1.19      481.57   \n",
       "314    1001280091001              362.90           542.90      718.80   \n",
       "\n",
       "     area_doors  area_windows  U_Basement/slab  U_Roof/attic   U_Walls   \n",
       "0         62.00       1332.00         0.979791      0.799810  0.870008  \\\n",
       "2          5.70        359.00         0.809994      0.887426  0.867918   \n",
       "3          4.80        144.10         0.820009      0.840019  1.080013   \n",
       "4         14.71        425.65         0.457929      0.900006  1.202054   \n",
       "5          4.60        182.00         0.463426      0.601299  0.725271   \n",
       "..          ...           ...              ...           ...       ...   \n",
       "310       16.00        641.00         0.810248      0.810248  0.872291   \n",
       "311       12.00        552.00         0.478670      0.779996  1.388631   \n",
       "312       29.20        447.60         0.809996      0.790808  0.870213   \n",
       "313        2.10         96.64         0.840738    178.823529  1.280001   \n",
       "314        6.30        115.10         1.155690      0.850064  1.139955   \n",
       "\n",
       "      U_doors  U_windows  \n",
       "0    2.835484   2.445420  \n",
       "2    3.192982   1.959331  \n",
       "3    3.366667   1.905135  \n",
       "4    2.895309   2.378456  \n",
       "5    3.652174   1.743956  \n",
       "..        ...        ...  \n",
       "310  4.712500   2.183463  \n",
       "311  3.033333   1.848062  \n",
       "312  3.555479   1.928262  \n",
       "313  2.228571   2.322951  \n",
       "314  4.460317   2.460469  \n",
       "\n",
       "[296 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_data = pivoted_data[pivoted_data !=0 ].dropna()\n",
    "pivoted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000702031001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "      <td>1013.73</td>\n",
       "      <td>1043.93</td>\n",
       "      <td>1830.05</td>\n",
       "      <td>60.88</td>\n",
       "      <td>211.62</td>\n",
       "      <td>0.530260</td>\n",
       "      <td>0.737655</td>\n",
       "      <td>1.137215</td>\n",
       "      <td>2.726675</td>\n",
       "      <td>2.389519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000660229001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "      <td>412.80</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1062.10</td>\n",
       "      <td>15.60</td>\n",
       "      <td>389.50</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.181237</td>\n",
       "      <td>1.201017</td>\n",
       "      <td>3.134615</td>\n",
       "      <td>2.054429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000660171001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "      <td>417.00</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1054.60</td>\n",
       "      <td>15.60</td>\n",
       "      <td>397.00</td>\n",
       "      <td>0.622302</td>\n",
       "      <td>0.181237</td>\n",
       "      <td>1.201309</td>\n",
       "      <td>3.134615</td>\n",
       "      <td>2.045844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000660177001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "      <td>321.40</td>\n",
       "      <td>379.50</td>\n",
       "      <td>913.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>299.60</td>\n",
       "      <td>0.581207</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.978206</td>\n",
       "      <td>3.168675</td>\n",
       "      <td>1.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000670322003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2189.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2731.9</td>\n",
       "      <td>316</td>\n",
       "      <td>495.80</td>\n",
       "      <td>590.50</td>\n",
       "      <td>1381.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>390.20</td>\n",
       "      <td>0.569988</td>\n",
       "      <td>0.805080</td>\n",
       "      <td>1.195122</td>\n",
       "      <td>3.202247</td>\n",
       "      <td>2.058688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1000870260004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272.3</td>\n",
       "      <td>110</td>\n",
       "      <td>119.93</td>\n",
       "      <td>110.88</td>\n",
       "      <td>279.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>55.10</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>0.927471</td>\n",
       "      <td>2.798611</td>\n",
       "      <td>1.479129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1000860273001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "      <td>259.00</td>\n",
       "      <td>308.56</td>\n",
       "      <td>957.38</td>\n",
       "      <td>13.69</td>\n",
       "      <td>166.59</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.960008</td>\n",
       "      <td>0.985868</td>\n",
       "      <td>1.817385</td>\n",
       "      <td>1.300018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1000840185001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "      <td>226.04</td>\n",
       "      <td>262.22</td>\n",
       "      <td>526.03</td>\n",
       "      <td>12.00</td>\n",
       "      <td>117.85</td>\n",
       "      <td>0.742258</td>\n",
       "      <td>0.869995</td>\n",
       "      <td>1.121590</td>\n",
       "      <td>2.487500</td>\n",
       "      <td>1.647773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1000280019001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "      <td>120.50</td>\n",
       "      <td>142.10</td>\n",
       "      <td>596.92</td>\n",
       "      <td>6.65</td>\n",
       "      <td>171.08</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>2.042105</td>\n",
       "      <td>1.818389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1000740251001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "      <td>182.30</td>\n",
       "      <td>209.70</td>\n",
       "      <td>576.49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>92.10</td>\n",
       "      <td>0.920022</td>\n",
       "      <td>0.850024</td>\n",
       "      <td>1.014276</td>\n",
       "      <td>2.799213</td>\n",
       "      <td>1.685016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cadastre_number  floors  useful_area  apartments  total_area serie   \n",
       "0      1000702031001     9.0      13077.4       252.0     15673.6   101  \\\n",
       "1      1000660229001     5.0       1930.5        45.0      2478.7   316   \n",
       "2      1000660171001     5.0       1927.5        45.0      2477.7   316   \n",
       "3      1000660177001     5.0       1583.7        30.0      2041.9   103   \n",
       "4      1000670322003     5.0       2189.3        53.0      2731.9   316   \n",
       "..               ...     ...          ...         ...         ...   ...   \n",
       "251    1000870260004     2.0        194.8         4.0       272.3   110   \n",
       "252    1000860273001     4.0       1201.1        12.0      1433.3     0   \n",
       "253    1000840185001     3.0        586.4        10.0       771.5     0   \n",
       "254    1000280019001     4.0        665.1        12.0       750.7     0   \n",
       "255    1000740251001     3.0        519.1        12.0       732.1   316   \n",
       "\n",
       "     area_Basement/slab  area_Roof/attic  area_Walls  area_doors   \n",
       "0               1013.73          1043.93     1830.05       60.88  \\\n",
       "1                412.80           515.90     1062.10       15.60   \n",
       "2                417.00           515.90     1054.60       15.60   \n",
       "3                321.40           379.50      913.10        8.30   \n",
       "4                495.80           590.50     1381.70        8.90   \n",
       "..                  ...              ...         ...         ...   \n",
       "251              119.93           110.88      279.06        2.88   \n",
       "252              259.00           308.56      957.38       13.69   \n",
       "253              226.04           262.22      526.03       12.00   \n",
       "254              120.50           142.10      596.92        6.65   \n",
       "255              182.30           209.70      576.49        2.54   \n",
       "\n",
       "     area_windows  U_Basement/slab  U_Roof/attic   U_Walls   U_doors   \n",
       "0          211.62         0.530260      0.737655  1.137215  2.726675  \\\n",
       "1          389.50         0.622093      0.181237  1.201017  3.134615   \n",
       "2          397.00         0.622302      0.181237  1.201309  3.134615   \n",
       "3          299.60         0.581207      0.782609  0.978206  3.168675   \n",
       "4          390.20         0.569988      0.805080  1.195122  3.202247   \n",
       "..            ...              ...           ...       ...       ...   \n",
       "251         55.10         0.588093      0.799964  0.927471  2.798611   \n",
       "252        166.59         1.050000      0.960008  0.985868  1.817385   \n",
       "253        117.85         0.742258      0.869995  1.121590  2.487500   \n",
       "254        171.08         0.400000      0.850035  0.867403  2.042105   \n",
       "255         92.10         0.920022      0.850024  1.014276  2.799213   \n",
       "\n",
       "     U_windows  \n",
       "0     2.389519  \n",
       "1     2.054429  \n",
       "2     2.045844  \n",
       "3     1.971963  \n",
       "4     2.058688  \n",
       "..         ...  \n",
       "251   1.479129  \n",
       "252   1.300018  \n",
       "253   1.647773  \n",
       "254   1.818389  \n",
       "255   1.685016  \n",
       "\n",
       "[256 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(ml_input, pivoted_data, on='cadastre_number', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cadastre_number</th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.560000e+02</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000759e+12</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>2568.334766</td>\n",
       "      <td>49.269531</td>\n",
       "      <td>3294.778516</td>\n",
       "      <td>559.375937</td>\n",
       "      <td>557.854156</td>\n",
       "      <td>1927.470590</td>\n",
       "      <td>20.658125</td>\n",
       "      <td>461.076465</td>\n",
       "      <td>0.669857</td>\n",
       "      <td>1.545179</td>\n",
       "      <td>1.007739</td>\n",
       "      <td>2.892369</td>\n",
       "      <td>2.010589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.963218e+08</td>\n",
       "      <td>3.080616</td>\n",
       "      <td>2140.141820</td>\n",
       "      <td>40.167805</td>\n",
       "      <td>2738.721834</td>\n",
       "      <td>380.593767</td>\n",
       "      <td>394.793811</td>\n",
       "      <td>3742.786967</td>\n",
       "      <td>26.622540</td>\n",
       "      <td>397.983328</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>11.139048</td>\n",
       "      <td>0.195134</td>\n",
       "      <td>0.685652</td>\n",
       "      <td>0.259594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000090e+12</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>186.900000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.037214</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>1.300018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000602e+12</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>897.675000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1161.350000</td>\n",
       "      <td>286.575000</td>\n",
       "      <td>267.625000</td>\n",
       "      <td>742.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>171.060000</td>\n",
       "      <td>0.550016</td>\n",
       "      <td>0.710842</td>\n",
       "      <td>0.889946</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.855652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000751e+12</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2188.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2819.950000</td>\n",
       "      <td>459.250000</td>\n",
       "      <td>494.060000</td>\n",
       "      <td>1482.045000</td>\n",
       "      <td>13.745000</td>\n",
       "      <td>397.600000</td>\n",
       "      <td>0.624511</td>\n",
       "      <td>0.821410</td>\n",
       "      <td>1.006141</td>\n",
       "      <td>2.917422</td>\n",
       "      <td>1.995380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000921e+12</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3581.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>4628.225000</td>\n",
       "      <td>700.650000</td>\n",
       "      <td>713.657500</td>\n",
       "      <td>2393.872500</td>\n",
       "      <td>22.647500</td>\n",
       "      <td>638.807500</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.930837</td>\n",
       "      <td>1.114058</td>\n",
       "      <td>3.351671</td>\n",
       "      <td>2.148173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.001280e+12</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13077.400000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>16850.800000</td>\n",
       "      <td>2146.300000</td>\n",
       "      <td>2298.300000</td>\n",
       "      <td>58344.000000</td>\n",
       "      <td>242.310000</td>\n",
       "      <td>2760.600000</td>\n",
       "      <td>1.584164</td>\n",
       "      <td>178.823529</td>\n",
       "      <td>1.491562</td>\n",
       "      <td>4.712500</td>\n",
       "      <td>2.858623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cadastre_number      floors   useful_area  apartments    total_area  \\\n",
       "count     2.560000e+02  256.000000    256.000000  256.000000    256.000000   \n",
       "mean      1.000759e+12    5.625000   2568.334766   49.269531   3294.778516   \n",
       "std       2.963218e+08    3.080616   2140.141820   40.167805   2738.721834   \n",
       "min       1.000090e+12    2.000000    170.400000    4.000000    186.900000   \n",
       "25%       1.000602e+12    3.000000    897.675000   16.000000   1161.350000   \n",
       "50%       1.000751e+12    5.000000   2188.250000   43.000000   2819.950000   \n",
       "75%       1.000921e+12    7.500000   3581.000000   71.000000   4628.225000   \n",
       "max       1.001280e+12   19.000000  13077.400000  252.000000  16850.800000   \n",
       "\n",
       "       area_Basement/slab  area_Roof/attic    area_Walls  area_doors  \\\n",
       "count          256.000000       256.000000    256.000000  256.000000   \n",
       "mean           559.375937       557.854156   1927.470590   20.658125   \n",
       "std            380.593767       394.793811   3742.786967   26.622540   \n",
       "min             60.000000         1.190000    160.000000    2.100000   \n",
       "25%            286.575000       267.625000    742.250000    6.000000   \n",
       "50%            459.250000       494.060000   1482.045000   13.745000   \n",
       "75%            700.650000       713.657500   2393.872500   22.647500   \n",
       "max           2146.300000      2298.300000  58344.000000  242.310000   \n",
       "\n",
       "       area_windows  U_Basement/slab  U_Roof/attic     U_Walls     U_doors  \\\n",
       "count    256.000000       256.000000    256.000000  256.000000  256.000000   \n",
       "mean     461.076465         0.669857      1.545179    1.007739    2.892369   \n",
       "std      397.983328         0.201955     11.139048    0.195134    0.685652   \n",
       "min       27.500000         0.037214      0.130000    0.017436    0.392157   \n",
       "25%      171.060000         0.550016      0.710842    0.889946    2.300000   \n",
       "50%      397.600000         0.624511      0.821410    1.006141    2.917422   \n",
       "75%      638.807500         0.819997      0.930837    1.114058    3.351671   \n",
       "max     2760.600000         1.584164    178.823529    1.491562    4.712500   \n",
       "\n",
       "        U_windows  \n",
       "count  256.000000  \n",
       "mean     2.010589  \n",
       "std      0.259594  \n",
       "min      1.300018  \n",
       "25%      1.855652  \n",
       "50%      1.995380  \n",
       "75%      2.148173  \n",
       "max      2.858623  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "      <td>1013.73</td>\n",
       "      <td>1043.93</td>\n",
       "      <td>1830.05</td>\n",
       "      <td>60.88</td>\n",
       "      <td>211.62</td>\n",
       "      <td>0.530260</td>\n",
       "      <td>0.737655</td>\n",
       "      <td>1.137215</td>\n",
       "      <td>2.726675</td>\n",
       "      <td>2.389519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "      <td>412.80</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1062.10</td>\n",
       "      <td>15.60</td>\n",
       "      <td>389.50</td>\n",
       "      <td>0.622093</td>\n",
       "      <td>0.181237</td>\n",
       "      <td>1.201017</td>\n",
       "      <td>3.134615</td>\n",
       "      <td>2.054429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "      <td>417.00</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1054.60</td>\n",
       "      <td>15.60</td>\n",
       "      <td>397.00</td>\n",
       "      <td>0.622302</td>\n",
       "      <td>0.181237</td>\n",
       "      <td>1.201309</td>\n",
       "      <td>3.134615</td>\n",
       "      <td>2.045844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "      <td>321.40</td>\n",
       "      <td>379.50</td>\n",
       "      <td>913.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>299.60</td>\n",
       "      <td>0.581207</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.978206</td>\n",
       "      <td>3.168675</td>\n",
       "      <td>1.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2189.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2731.9</td>\n",
       "      <td>316</td>\n",
       "      <td>495.80</td>\n",
       "      <td>590.50</td>\n",
       "      <td>1381.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>390.20</td>\n",
       "      <td>0.569988</td>\n",
       "      <td>0.805080</td>\n",
       "      <td>1.195122</td>\n",
       "      <td>3.202247</td>\n",
       "      <td>2.058688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272.3</td>\n",
       "      <td>110</td>\n",
       "      <td>119.93</td>\n",
       "      <td>110.88</td>\n",
       "      <td>279.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>55.10</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>0.927471</td>\n",
       "      <td>2.798611</td>\n",
       "      <td>1.479129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "      <td>259.00</td>\n",
       "      <td>308.56</td>\n",
       "      <td>957.38</td>\n",
       "      <td>13.69</td>\n",
       "      <td>166.59</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.960008</td>\n",
       "      <td>0.985868</td>\n",
       "      <td>1.817385</td>\n",
       "      <td>1.300018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "      <td>226.04</td>\n",
       "      <td>262.22</td>\n",
       "      <td>526.03</td>\n",
       "      <td>12.00</td>\n",
       "      <td>117.85</td>\n",
       "      <td>0.742258</td>\n",
       "      <td>0.869995</td>\n",
       "      <td>1.121590</td>\n",
       "      <td>2.487500</td>\n",
       "      <td>1.647773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "      <td>120.50</td>\n",
       "      <td>142.10</td>\n",
       "      <td>596.92</td>\n",
       "      <td>6.65</td>\n",
       "      <td>171.08</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>2.042105</td>\n",
       "      <td>1.818389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "      <td>182.30</td>\n",
       "      <td>209.70</td>\n",
       "      <td>576.49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>92.10</td>\n",
       "      <td>0.920022</td>\n",
       "      <td>0.850024</td>\n",
       "      <td>1.014276</td>\n",
       "      <td>2.799213</td>\n",
       "      <td>1.685016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     floors  useful_area  apartments  total_area serie  area_Basement/slab   \n",
       "0       9.0      13077.4       252.0     15673.6   101             1013.73  \\\n",
       "1       5.0       1930.5        45.0      2478.7   316              412.80   \n",
       "2       5.0       1927.5        45.0      2477.7   316              417.00   \n",
       "3       5.0       1583.7        30.0      2041.9   103              321.40   \n",
       "4       5.0       2189.3        53.0      2731.9   316              495.80   \n",
       "..      ...          ...         ...         ...   ...                 ...   \n",
       "251     2.0        194.8         4.0       272.3   110              119.93   \n",
       "252     4.0       1201.1        12.0      1433.3     0              259.00   \n",
       "253     3.0        586.4        10.0       771.5     0              226.04   \n",
       "254     4.0        665.1        12.0       750.7     0              120.50   \n",
       "255     3.0        519.1        12.0       732.1   316              182.30   \n",
       "\n",
       "     area_Roof/attic  area_Walls  area_doors  area_windows  U_Basement/slab   \n",
       "0            1043.93     1830.05       60.88        211.62         0.530260  \\\n",
       "1             515.90     1062.10       15.60        389.50         0.622093   \n",
       "2             515.90     1054.60       15.60        397.00         0.622302   \n",
       "3             379.50      913.10        8.30        299.60         0.581207   \n",
       "4             590.50     1381.70        8.90        390.20         0.569988   \n",
       "..               ...         ...         ...           ...              ...   \n",
       "251           110.88      279.06        2.88         55.10         0.588093   \n",
       "252           308.56      957.38       13.69        166.59         1.050000   \n",
       "253           262.22      526.03       12.00        117.85         0.742258   \n",
       "254           142.10      596.92        6.65        171.08         0.400000   \n",
       "255           209.70      576.49        2.54         92.10         0.920022   \n",
       "\n",
       "     U_Roof/attic   U_Walls   U_doors  U_windows  \n",
       "0        0.737655  1.137215  2.726675   2.389519  \n",
       "1        0.181237  1.201017  3.134615   2.054429  \n",
       "2        0.181237  1.201309  3.134615   2.045844  \n",
       "3        0.782609  0.978206  3.168675   1.971963  \n",
       "4        0.805080  1.195122  3.202247   2.058688  \n",
       "..            ...       ...       ...        ...  \n",
       "251      0.799964  0.927471  2.798611   1.479129  \n",
       "252      0.960008  0.985868  1.817385   1.300018  \n",
       "253      0.869995  1.121590  2.487500   1.647773  \n",
       "254      0.850035  0.867403  2.042105   1.818389  \n",
       "255      0.850024  1.014276  2.799213   1.685016  \n",
       "\n",
       "[256 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.drop(columns=['cadastre_number'], axis=1, inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serie\n",
       "0      93\n",
       "316    67\n",
       "103    18\n",
       "467    18\n",
       "602    16\n",
       "110    14\n",
       "464    10\n",
       "119     7\n",
       "101     4\n",
       "104     4\n",
       "102     4\n",
       "105     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['serie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8,  8,  3,  8,  3,  3,  8,  0,  4,  0,  8,  4,  8,  8,  8,  8,\n",
       "        3,  3, 11, 10,  0,  7,  8,  0,  8, 11,  4, 11,  8,  8,  8,  0,  0,\n",
       "        0,  0,  0, 10, 11,  9,  0,  0, 10,  8, 10,  0,  0,  0,  0,  0,  8,\n",
       "        0,  0,  0,  0,  8,  8, 10,  0, 11,  0,  8,  8,  8,  7,  9,  8,  8,\n",
       "        0,  3,  0,  0,  9,  0,  9,  9,  0,  8,  4,  8,  0,  0,  0,  6,  0,\n",
       "        0,  8,  8,  8,  8,  3,  8,  6,  8,  8,  0,  0,  0,  1,  0,  2,  0,\n",
       "        0,  0,  0,  0,  8,  0,  0,  0,  8,  1,  8,  8,  0,  6, 10,  8,  0,\n",
       "        0,  0, 11, 11,  8,  8, 11,  9,  0, 11,  0,  0, 10, 10, 10, 10,  0,\n",
       "        8,  7,  8,  8,  8,  3,  0,  0,  0,  8,  3,  1, 11,  0,  8,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  3,  7,  9,  0,  0, 10,  0,  0, 10,  6,  0,\n",
       "        0,  3,  9,  6,  5,  2,  9, 11, 10, 11,  0,  2, 10, 10, 10,  8,  8,\n",
       "        0,  0,  0,  8,  8,  0,  6,  3,  8,  8,  8,  8,  0,  8,  8,  0,  2,\n",
       "        3,  8,  8,  0, 10,  7,  0, 11,  7,  0,  6,  8,  6,  8,  0,  0, 11,\n",
       "        0,  3,  3,  8,  0,  8,  8, 11,  8,  6,  0,  6,  0,  3,  0,  9,  3,\n",
       "        8,  8,  0,  0,  8,  7, 10,  0,  3, 11,  6,  6,  6,  6,  0,  0,  0,\n",
       "        8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#label_encoder.fit(merged_df['serie'])\n",
    "#label_encoder.classes_\n",
    "integer_encoder = label_encoder.fit_transform(merged_df['serie'])\n",
    "integer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8,  8,  3,  8,  3,  3,  8,  0,  4,  0,  8,  4,  8,  8,  8,  8,\n",
       "        3,  3, 11, 10,  0,  7,  8,  0,  8, 11,  4, 11,  8,  8,  8,  0,  0,\n",
       "        0,  0,  0, 10, 11,  9,  0,  0, 10,  8, 10,  0,  0,  0,  0,  0,  8,\n",
       "        0,  0,  0,  0,  8,  8, 10,  0, 11,  0,  8,  8,  8,  7,  9,  8,  8,\n",
       "        0,  3,  0,  0,  9,  0,  9,  9,  0,  8,  4,  8,  0,  0,  0,  6,  0,\n",
       "        0,  8,  8,  8,  8,  3,  8,  6,  8,  8,  0,  0,  0,  1,  0,  2,  0,\n",
       "        0,  0,  0,  0,  8,  0,  0,  0,  8,  1,  8,  8,  0,  6, 10,  8,  0,\n",
       "        0,  0, 11, 11,  8,  8, 11,  9,  0, 11,  0,  0, 10, 10, 10, 10,  0,\n",
       "        8,  7,  8,  8,  8,  3,  0,  0,  0,  8,  3,  1, 11,  0,  8,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  3,  7,  9,  0,  0, 10,  0,  0, 10,  6,  0,\n",
       "        0,  3,  9,  6,  5,  2,  9, 11, 10, 11,  0,  2, 10, 10, 10,  8,  8,\n",
       "        0,  0,  0,  8,  8,  0,  6,  3,  8,  8,  8,  8,  0,  8,  8,  0,  2,\n",
       "        3,  8,  8,  0, 10,  7,  0, 11,  7,  0,  6,  8,  6,  8,  0,  0, 11,\n",
       "        0,  3,  3,  8,  0,  8,  8, 11,  8,  6,  0,  6,  0,  3,  0,  9,  3,\n",
       "        8,  8,  0,  0,  8,  7, 10,  0,  3, 11,  6,  6,  6,  6,  0,  0,  0,\n",
       "        8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#label_encoder.fit(merged_df['serie'])\n",
    "#label_encoder.classes_\n",
    "integer_encoder = label_encoder.fit_transform(merged_df['serie'])\n",
    "integer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.transform(['103'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m integer_encoder\u001b[39m.\u001b[39;49mvalue_counts()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "integer_encoder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./apisrc/models/my_encoder.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "encoding_filename = \"./apisrc/models/my_encoder.pkl\"\n",
    "joblib.dump(label_encoder, encoding_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "251  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "252  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "253  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "254  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "255  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "\n",
       "[256 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = OneHotEncoder()\n",
    "integer_encoder = integer_encoder.reshape(256,1)\n",
    "onehot_encoded = pd.DataFrame(onehot.fit_transform(integer_encoder).toarray())\n",
    "onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.join(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "      <td>1013.73</td>\n",
       "      <td>1043.93</td>\n",
       "      <td>1830.05</td>\n",
       "      <td>60.88</td>\n",
       "      <td>211.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "      <td>412.80</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1062.10</td>\n",
       "      <td>15.60</td>\n",
       "      <td>389.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "      <td>417.00</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1054.60</td>\n",
       "      <td>15.60</td>\n",
       "      <td>397.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "      <td>321.40</td>\n",
       "      <td>379.50</td>\n",
       "      <td>913.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>299.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2189.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2731.9</td>\n",
       "      <td>316</td>\n",
       "      <td>495.80</td>\n",
       "      <td>590.50</td>\n",
       "      <td>1381.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>390.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272.3</td>\n",
       "      <td>110</td>\n",
       "      <td>119.93</td>\n",
       "      <td>110.88</td>\n",
       "      <td>279.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>55.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "      <td>259.00</td>\n",
       "      <td>308.56</td>\n",
       "      <td>957.38</td>\n",
       "      <td>13.69</td>\n",
       "      <td>166.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "      <td>226.04</td>\n",
       "      <td>262.22</td>\n",
       "      <td>526.03</td>\n",
       "      <td>12.00</td>\n",
       "      <td>117.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "      <td>120.50</td>\n",
       "      <td>142.10</td>\n",
       "      <td>596.92</td>\n",
       "      <td>6.65</td>\n",
       "      <td>171.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "      <td>182.30</td>\n",
       "      <td>209.70</td>\n",
       "      <td>576.49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>92.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     floors  useful_area  apartments  total_area serie  area_Basement/slab  \\\n",
       "0       9.0      13077.4       252.0     15673.6   101             1013.73   \n",
       "1       5.0       1930.5        45.0      2478.7   316              412.80   \n",
       "2       5.0       1927.5        45.0      2477.7   316              417.00   \n",
       "3       5.0       1583.7        30.0      2041.9   103              321.40   \n",
       "4       5.0       2189.3        53.0      2731.9   316              495.80   \n",
       "..      ...          ...         ...         ...   ...                 ...   \n",
       "251     2.0        194.8         4.0       272.3   110              119.93   \n",
       "252     4.0       1201.1        12.0      1433.3     0              259.00   \n",
       "253     3.0        586.4        10.0       771.5     0              226.04   \n",
       "254     4.0        665.1        12.0       750.7     0              120.50   \n",
       "255     3.0        519.1        12.0       732.1   316              182.30   \n",
       "\n",
       "     area_Roof/attic  area_Walls  area_doors  area_windows  ...    2    3  \\\n",
       "0            1043.93     1830.05       60.88        211.62  ...  0.0  0.0   \n",
       "1             515.90     1062.10       15.60        389.50  ...  0.0  0.0   \n",
       "2             515.90     1054.60       15.60        397.00  ...  0.0  0.0   \n",
       "3             379.50      913.10        8.30        299.60  ...  0.0  1.0   \n",
       "4             590.50     1381.70        8.90        390.20  ...  0.0  0.0   \n",
       "..               ...         ...         ...           ...  ...  ...  ...   \n",
       "251           110.88      279.06        2.88         55.10  ...  0.0  0.0   \n",
       "252           308.56      957.38       13.69        166.59  ...  0.0  0.0   \n",
       "253           262.22      526.03       12.00        117.85  ...  0.0  0.0   \n",
       "254           142.10      596.92        6.65        171.08  ...  0.0  0.0   \n",
       "255           209.70      576.49        2.54         92.10  ...  0.0  0.0   \n",
       "\n",
       "       4    5    6    7    8    9   10   11  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "251  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "252  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "253  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "254  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "255  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[256 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            'floors',        'useful_area',         'apartments',\n",
       "               'total_area',              'serie', 'area_Basement/slab',\n",
       "          'area_Roof/attic',         'area_Walls',         'area_doors',\n",
       "             'area_windows',    'U_Basement/slab',       'U_Roof/attic',\n",
       "                  'U_Walls',            'U_doors',          'U_windows',\n",
       "                          0,                    1,                    2,\n",
       "                          3,                    4,                    5,\n",
       "                          6,                    7,                    8,\n",
       "                          9,                   10,                   11],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.625000</td>\n",
       "      <td>2568.334766</td>\n",
       "      <td>49.269531</td>\n",
       "      <td>3294.778516</td>\n",
       "      <td>559.375937</td>\n",
       "      <td>557.854156</td>\n",
       "      <td>1927.470590</td>\n",
       "      <td>20.658125</td>\n",
       "      <td>461.076465</td>\n",
       "      <td>0.669857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.080616</td>\n",
       "      <td>2140.141820</td>\n",
       "      <td>40.167805</td>\n",
       "      <td>2738.721834</td>\n",
       "      <td>380.593767</td>\n",
       "      <td>394.793811</td>\n",
       "      <td>3742.786967</td>\n",
       "      <td>26.622540</td>\n",
       "      <td>397.983328</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.256174</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.227815</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>0.440431</td>\n",
       "      <td>0.194123</td>\n",
       "      <td>0.256174</td>\n",
       "      <td>0.242536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>186.900000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.037214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>897.675000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1161.350000</td>\n",
       "      <td>286.575000</td>\n",
       "      <td>267.625000</td>\n",
       "      <td>742.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>171.060000</td>\n",
       "      <td>0.550016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2188.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2819.950000</td>\n",
       "      <td>459.250000</td>\n",
       "      <td>494.060000</td>\n",
       "      <td>1482.045000</td>\n",
       "      <td>13.745000</td>\n",
       "      <td>397.600000</td>\n",
       "      <td>0.624511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>3581.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>4628.225000</td>\n",
       "      <td>700.650000</td>\n",
       "      <td>713.657500</td>\n",
       "      <td>2393.872500</td>\n",
       "      <td>22.647500</td>\n",
       "      <td>638.807500</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>13077.400000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>16850.800000</td>\n",
       "      <td>2146.300000</td>\n",
       "      <td>2298.300000</td>\n",
       "      <td>58344.000000</td>\n",
       "      <td>242.310000</td>\n",
       "      <td>2760.600000</td>\n",
       "      <td>1.584164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           floors   useful_area  apartments    total_area  area_Basement/slab  \\\n",
       "count  256.000000    256.000000  256.000000    256.000000          256.000000   \n",
       "mean     5.625000   2568.334766   49.269531   3294.778516          559.375937   \n",
       "std      3.080616   2140.141820   40.167805   2738.721834          380.593767   \n",
       "min      2.000000    170.400000    4.000000    186.900000           60.000000   \n",
       "25%      3.000000    897.675000   16.000000   1161.350000          286.575000   \n",
       "50%      5.000000   2188.250000   43.000000   2819.950000          459.250000   \n",
       "75%      7.500000   3581.000000   71.000000   4628.225000          700.650000   \n",
       "max     19.000000  13077.400000  252.000000  16850.800000         2146.300000   \n",
       "\n",
       "       area_Roof/attic    area_Walls  area_doors  area_windows  \\\n",
       "count       256.000000    256.000000  256.000000    256.000000   \n",
       "mean        557.854156   1927.470590   20.658125    461.076465   \n",
       "std         394.793811   3742.786967   26.622540    397.983328   \n",
       "min           1.190000    160.000000    2.100000     27.500000   \n",
       "25%         267.625000    742.250000    6.000000    171.060000   \n",
       "50%         494.060000   1482.045000   13.745000    397.600000   \n",
       "75%         713.657500   2393.872500   22.647500    638.807500   \n",
       "max        2298.300000  58344.000000  242.310000   2760.600000   \n",
       "\n",
       "       U_Basement/slab  ...           2           3           4           5  \\\n",
       "count       256.000000  ...  256.000000  256.000000  256.000000  256.000000   \n",
       "mean          0.669857  ...    0.015625    0.070312    0.015625    0.003906   \n",
       "std           0.201955  ...    0.124263    0.256174    0.124263    0.062500   \n",
       "min           0.037214  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "25%           0.550016  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "50%           0.624511  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "75%           0.819997  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "max           1.584164  ...    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "                6           7           8           9          10          11  \n",
       "count  256.000000  256.000000  256.000000  256.000000  256.000000  256.000000  \n",
       "mean     0.054688    0.027344    0.261719    0.039062    0.070312    0.062500  \n",
       "std      0.227815    0.163402    0.440431    0.194123    0.256174    0.242536  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1,  1,  3,  1,  3,  3,  1,  0,  9,  0,  1,  9,  1,  1,  1,  1,\n",
       "        3,  3,  2,  4,  0,  6,  1,  0,  1,  2,  9,  2,  1,  1,  1,  0,  0,\n",
       "        0,  0,  0,  4,  2,  7,  0,  0,  4,  1,  4,  0,  0,  0,  0,  0,  1,\n",
       "        0,  0,  0,  0,  1,  1,  4,  0,  2,  0,  1,  1,  1,  6,  7,  1,  1,\n",
       "        0,  3,  0,  0,  7,  0,  7,  7,  0,  1,  9,  1,  0,  0,  0,  5,  0,\n",
       "        0,  1,  1,  1,  1,  3,  1,  5,  1,  1,  0,  0,  0,  8,  0, 10,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  1,  8,  1,  1,  0,  5,  4,  1,  0,\n",
       "        0,  0,  2,  2,  1,  1,  2,  7,  0,  2,  0,  0,  4,  4,  4,  4,  0,\n",
       "        1,  6,  1,  1,  1,  3,  0,  0,  0,  1,  3,  8,  2,  0,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  3,  6,  7,  0,  0,  4,  0,  0,  4,  5,  0,\n",
       "        0,  3,  7,  5,  9, 10,  7,  2,  4,  2,  0, 10,  4,  4,  4,  1,  1,\n",
       "        0,  0,  0,  1,  1,  0,  5,  3,  1,  1,  1,  1,  0,  1,  1,  0, 10,\n",
       "        3,  1,  1,  0,  4,  6,  0,  2,  6,  0,  5,  1,  5,  1,  0,  0,  2,\n",
       "        0,  3,  3,  1,  0,  1,  1,  2,  1,  5,  0,  5,  0,  3,  0,  7,  3,\n",
       "        1,  1,  0,  0,  1,  6,  4,  0,  3,  2,  5,  5,  5,  5,  0,  0,  0,\n",
       "        1], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = np.array(merged_df['serie']).reshape(-1,1)\n",
    "kmeans = KMeans(n_clusters=11).fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "      <td>1013.73</td>\n",
       "      <td>1043.93</td>\n",
       "      <td>1830.05</td>\n",
       "      <td>60.88</td>\n",
       "      <td>211.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "      <td>412.80</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1062.10</td>\n",
       "      <td>15.60</td>\n",
       "      <td>389.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "      <td>417.00</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1054.60</td>\n",
       "      <td>15.60</td>\n",
       "      <td>397.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "      <td>321.40</td>\n",
       "      <td>379.50</td>\n",
       "      <td>913.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>299.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2189.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2731.9</td>\n",
       "      <td>316</td>\n",
       "      <td>495.80</td>\n",
       "      <td>590.50</td>\n",
       "      <td>1381.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>390.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272.3</td>\n",
       "      <td>110</td>\n",
       "      <td>119.93</td>\n",
       "      <td>110.88</td>\n",
       "      <td>279.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>55.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "      <td>259.00</td>\n",
       "      <td>308.56</td>\n",
       "      <td>957.38</td>\n",
       "      <td>13.69</td>\n",
       "      <td>166.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "      <td>226.04</td>\n",
       "      <td>262.22</td>\n",
       "      <td>526.03</td>\n",
       "      <td>12.00</td>\n",
       "      <td>117.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "      <td>120.50</td>\n",
       "      <td>142.10</td>\n",
       "      <td>596.92</td>\n",
       "      <td>6.65</td>\n",
       "      <td>171.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "      <td>182.30</td>\n",
       "      <td>209.70</td>\n",
       "      <td>576.49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>92.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     floors  useful_area  apartments  total_area serie  area_Basement/slab  \\\n",
       "0       9.0      13077.4       252.0     15673.6   101             1013.73   \n",
       "1       5.0       1930.5        45.0      2478.7   316              412.80   \n",
       "2       5.0       1927.5        45.0      2477.7   316              417.00   \n",
       "3       5.0       1583.7        30.0      2041.9   103              321.40   \n",
       "4       5.0       2189.3        53.0      2731.9   316              495.80   \n",
       "..      ...          ...         ...         ...   ...                 ...   \n",
       "251     2.0        194.8         4.0       272.3   110              119.93   \n",
       "252     4.0       1201.1        12.0      1433.3     0              259.00   \n",
       "253     3.0        586.4        10.0       771.5     0              226.04   \n",
       "254     4.0        665.1        12.0       750.7     0              120.50   \n",
       "255     3.0        519.1        12.0       732.1   316              182.30   \n",
       "\n",
       "     area_Roof/attic  area_Walls  area_doors  area_windows  ...    3    4  \\\n",
       "0            1043.93     1830.05       60.88        211.62  ...  0.0  0.0   \n",
       "1             515.90     1062.10       15.60        389.50  ...  0.0  0.0   \n",
       "2             515.90     1054.60       15.60        397.00  ...  0.0  0.0   \n",
       "3             379.50      913.10        8.30        299.60  ...  1.0  0.0   \n",
       "4             590.50     1381.70        8.90        390.20  ...  0.0  0.0   \n",
       "..               ...         ...         ...           ...  ...  ...  ...   \n",
       "251           110.88      279.06        2.88         55.10  ...  0.0  0.0   \n",
       "252           308.56      957.38       13.69        166.59  ...  0.0  0.0   \n",
       "253           262.22      526.03       12.00        117.85  ...  0.0  0.0   \n",
       "254           142.10      596.92        6.65        171.08  ...  0.0  0.0   \n",
       "255           209.70      576.49        2.54         92.10  ...  0.0  0.0   \n",
       "\n",
       "       5    6    7    8    9   10   11  kmeans  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0       8  \n",
       "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0       1  \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0       1  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0       3  \n",
       "4    0.0  0.0  0.0  1.0  0.0  0.0  0.0       1  \n",
       "..   ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "251  0.0  1.0  0.0  0.0  0.0  0.0  0.0       5  \n",
       "252  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "253  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "254  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0  \n",
       "255  0.0  0.0  0.0  1.0  0.0  0.0  0.0       1  \n",
       "\n",
       "[256 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmeans = pd.DataFrame(list(kmeans.labels_), columns=['kmeans'])\n",
    "merged_df = merged_df.join(df_kmeans)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find outliers and extract\n",
    "check = pivoted_data[(pivoted_data == 0).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('datasets/CSV/final-without-outliers.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING EVERYTHING , SPLITING THE DATASET AND PERFORMING A SIMPLE LINEAR REGRESSION + STANDARD SCALER (Min Max SCALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mixalako/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df[['floors', 'useful_area', 'apartments', 'total_area', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]], merged_df[['area_Basement/slab', 'area_Roof/attic', 'area_Walls', 'area_doors', 'area_windows', 'U_Basement/slab', 'U_Roof/attic', 'U_Walls', 'U_doors', 'U_windows']], test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', MinMaxScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "# Train the linear regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score:  -2.841317447997848\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "# Evaluate the model on the test set\n",
    "\n",
    "score = r2_score(y_test, pred)\n",
    "print(\"R-squared score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R-squared score:  -1.3535968964391707\n",
      "Decision Tree R-squared score:  -33.02022311504034\n",
      "Random Forest R-squared score:  -26.82484413544489\n",
      "Neural Network R-squared score:  -1.1866648355520373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mixalako/.local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "random_forest = RandomForestRegressor(n_estimators=100, max_depth=100,random_state=42)\n",
    "svm = SVR()\n",
    "neural_network = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', alpha=0.001, max_iter=1000, random_state=42)\n",
    "\n",
    "\n",
    "linear_regression.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "#svm.fit(X_train, y_train)\n",
    "neural_network.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lr_predictions = linear_regression.predict(X_test)\n",
    "dt_predictions = decision_tree.predict(X_test)\n",
    "rf_predictions = random_forest.predict(X_test)\n",
    "#svm_predictions = svm.predict(X_test)\n",
    "nn_predictions = neural_network.predict(X_test)\n",
    "\n",
    "\n",
    "lr_score = r2_score(y_test, lr_predictions)\n",
    "dt_score = r2_score(y_test, dt_predictions)\n",
    "rf_score = r2_score(y_test, rf_predictions)\n",
    "#svm_score = r2_score(y_test, svm_predictions)\n",
    "nn_score = r2_score(y_test, nn_predictions)\n",
    "\n",
    "print(\"Linear Regression R-squared score: \", lr_score)\n",
    "print(\"Decision Tree R-squared score: \", dt_score)\n",
    "print(\"Random Forest R-squared score: \", rf_score)\n",
    "#print(\"Support Vector Regression R-squared score: \", svm_score)\n",
    "print(\"Neural Network R-squared score: \", nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# Assuming you have a 5x3 output shape\n",
    "input_shape = (5, 3)\n",
    "\n",
    "# Define the RNN model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(units=64, activation='relu', input_shape=input_shape))\n",
    "rnn_model.add(Dense(units=10))\n",
    "\n",
    "# Compile the model\n",
    "rnn_model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING WITH MULTIOUTPUTREGRESSOR FUNCTION WITH A RANDOM FOREST , AN SVM AND A NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE FOR EVERY OUTPUT\n",
      "mae for first regressor: 32471.2090625474 - second regressor: 26201.825807813326\n",
      "mae for third regressor: 62295734.354888864 - fourth regressor: 190.10507300656874\n",
      "mae for fifth regressor: 6189.805731126069 - sixth regressor: 0.04723855352138999\n",
      "mae for seventh regressor: 2.398655439144056 - eighth regressor: 0.07619615976895983\n",
      "mae for nineth regressor: 0.5777785196201592 - tenth regressor: 0.05088359992005756\n",
      "MAE FOR EVERY OUTPUT\n",
      "mae for first regressor: 106.70415269230763 - second regressor: 90.68564057692318\n",
      "mae for third regressor: 1277.1348326923082 - fourth regressor: 7.781903461538438\n",
      "mae for fifth regressor: 50.16498153846083 - sixth regressor: 0.16274184490202778\n",
      "mae for seventh regressor: 0.6193930541589948 - eighth regressor: 0.1644417402441213\n",
      "mae for nineth regressor: 0.6270192402394149 - tenth regressor: 0.16411902477509502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "\n",
    "# wrap the Random Forest model with MultiOutputRegressor to make it a multi-output regression model\n",
    "multioutput_regressor = MultiOutputRegressor(rf_regressor)\n",
    "\n",
    "# train the multi-output regression model\n",
    "multioutput_regressor.fit(X_train.copy(), y_train.copy())\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred = multioutput_regressor.predict(X_test.copy())\n",
    "\n",
    "# Calculate R-squared and MAE for each output separately\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "\n",
    "# Evaluate the regressor\n",
    "\n",
    "mse_one = mean_squared_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mse_two = mean_squared_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mse_three = mean_squared_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mse_four = mean_squared_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mse_five = mean_squared_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mse_six = mean_squared_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mse_seven = mean_squared_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mse_eight = mean_squared_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mse_nine = mean_squared_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mse_ten = mean_squared_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MSE FOR EVERY OUTPUT\")\n",
    "print(f'mae for first regressor: {mse_one} - second regressor: {mse_two}')\n",
    "print(f'mae for third regressor: {mse_three} - fourth regressor: {mse_four}')\n",
    "print(f'mae for fifth regressor: {mse_five} - sixth regressor: {mse_six}')\n",
    "print(f'mae for seventh regressor: {mse_seven} - eighth regressor: {mse_eight}')\n",
    "print(f'mae for nineth regressor: {mse_nine} - tenth regressor: {mse_ten}')\n",
    "mae_one = mean_absolute_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mae_two = mean_absolute_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mae_three = mean_absolute_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mae_four = mean_absolute_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mae_five = mean_absolute_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mae_six = mean_absolute_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mae_seven = mean_absolute_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mae_eight = mean_absolute_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mae_nine = mean_absolute_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mae_ten = mean_absolute_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MAE FOR EVERY OUTPUT\")\n",
    "print(f'mae for first regressor: {mae_one} - second regressor: {mae_two}')\n",
    "print(f'mae for third regressor: {mae_three} - fourth regressor: {mae_four}')\n",
    "print(f'mae for fifth regressor: {mae_five} - sixth regressor: {mae_six}')\n",
    "print(f'mae for seventh regressor: {mae_seven} - eighth regressor: {mae_eight}')\n",
    "print(f'mae for nineth regressor: {mae_nine} - tenth regressor: {mae_ten}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE FOR EVERY OUTPUT\n",
      "mse for first regressor: 121197.14059024802 - second regressor: 116643.10768770258\n",
      "mse for third regressor: 63234287.829031944 - fourth regressor: 284.3939240816317\n",
      "mse for fifth regressor: 170138.07695458762 - sixth regressor: 0.03926288800828512\n",
      "mse for seventh regressor: 0.20303844147618644 - eighth regressor: 0.07933335149940264\n",
      "mse for nineth regressor: 0.47067356000759253 - tenth regressor: 0.05366967535314934\n",
      "MAE FOR EVERY OUTPUT\n",
      "mae for first regressor: 228.67501544536006 - second regressor: 225.9930215718919\n",
      "mae for third regressor: 1836.1095532484755 - fourth regressor: 10.944873503789466\n",
      "mae for fifth regressor: 240.13040145214927 - sixth regressor: 0.1554870921226648\n",
      "mae for seventh regressor: 0.24837268865380785 - eighth regressor: 0.17443992729128815\n",
      "mae for nineth regressor: 0.5781534422955041 - tenth regressor: 0.18356714753801479\n"
     ]
    }
   ],
   "source": [
    "# Create the SVR regressor\n",
    "svr = SVR(epsilon=0.2)\n",
    "\n",
    "# Create the Multioutput Regressor\n",
    "mor = MultiOutputRegressor(svr)\n",
    "\n",
    "# Train the regressor\n",
    "mor = mor.fit(X_train.copy(), y_train.copy())\n",
    "\n",
    "# Generate predictions for testing data\n",
    "y_pred = mor.predict(X_test.copy())\n",
    "\n",
    "# Evaluate the regressor\n",
    "mse_one = mean_squared_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mse_two = mean_squared_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mse_three = mean_squared_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mse_four = mean_squared_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mse_five = mean_squared_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mse_six = mean_squared_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mse_seven = mean_squared_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mse_eight = mean_squared_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mse_nine = mean_squared_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mse_ten = mean_squared_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MSE FOR EVERY OUTPUT\")\n",
    "print(f'mse for first regressor: {mse_one} - second regressor: {mse_two}')\n",
    "print(f'mse for third regressor: {mse_three} - fourth regressor: {mse_four}')\n",
    "print(f'mse for fifth regressor: {mse_five} - sixth regressor: {mse_six}')\n",
    "print(f'mse for seventh regressor: {mse_seven} - eighth regressor: {mse_eight}')\n",
    "print(f'mse for nineth regressor: {mse_nine} - tenth regressor: {mse_ten}')\n",
    "mae_one = mean_absolute_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mae_two = mean_absolute_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mae_three = mean_absolute_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mae_four = mean_absolute_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mae_five = mean_absolute_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mae_six = mean_absolute_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mae_seven = mean_absolute_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mae_eight = mean_absolute_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mae_nine = mean_absolute_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mae_ten = mean_absolute_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MAE FOR EVERY OUTPUT\")\n",
    "print(f'mae for first regressor: {mae_one} - second regressor: {mae_two}')\n",
    "print(f'mae for third regressor: {mae_three} - fourth regressor: {mae_four}')\n",
    "print(f'mae for fifth regressor: {mae_five} - sixth regressor: {mae_six}')\n",
    "print(f'mae for seventh regressor: {mae_seven} - eighth regressor: {mae_eight}')\n",
    "print(f'mae for nineth regressor: {mae_nine} - tenth regressor: {mae_ten}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE FOR EVERY OUTPUT\n",
      "mse for first regressor: 42518.563666457994 - second regressor: 36422.47580711968\n",
      "mse for third regressor: 61108736.216099896 - fourth regressor: 97.59105682526948\n",
      "mse for fifth regressor: 34821.247090959325 - sixth regressor: 0.05399557591445317\n",
      "mse for seventh regressor: 1.8952320902176896 - eighth regressor: 0.08140235093457886\n",
      "mse for nineth regressor: 0.5269852881267169 - tenth regressor: 0.05877832944351255\n",
      "MAE FOR EVERY OUTPUT\n",
      "mae for first regressor: 132.23012048779256 - second regressor: 131.79737957275333\n",
      "mae for third regressor: 1345.333208865975 - fourth regressor: 6.8151232432576005\n",
      "mae for fifth regressor: 99.54506149916867 - sixth regressor: 0.18125668006683565\n",
      "mae for seventh regressor: 0.9810618326088009 - eighth regressor: 0.17262404778869336\n",
      "mae for nineth regressor: 0.6152872962092414 - tenth regressor: 0.19096554353054587\n"
     ]
    }
   ],
   "source": [
    "# Create the SVR regressor\n",
    "neural_network = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', alpha=0.001, max_iter=1000, random_state=42)\n",
    "# Create the Multioutput Regressor\n",
    "mor = MultiOutputRegressor(neural_network)\n",
    "\n",
    "# Train the regressor\n",
    "mor = mor.fit(X_train.copy(), y_train.copy())\n",
    "\n",
    "# Generate predictions for testing data\n",
    "y_pred = mor.predict(X_test.copy())\n",
    "\n",
    "#print(mor.score(X_test, y_test ))\n",
    "# Evaluate the regressor\n",
    "mse_one = mean_squared_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mse_two = mean_squared_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mse_three = mean_squared_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mse_four = mean_squared_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mse_five = mean_squared_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mse_six = mean_squared_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mse_seven = mean_squared_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mse_eight = mean_squared_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mse_nine = mean_squared_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mse_ten = mean_squared_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MSE FOR EVERY OUTPUT\")\n",
    "print(f'mse for first regressor: {mse_one} - second regressor: {mse_two}')\n",
    "print(f'mse for third regressor: {mse_three} - fourth regressor: {mse_four}')\n",
    "print(f'mse for fifth regressor: {mse_five} - sixth regressor: {mse_six}')\n",
    "print(f'mse for seventh regressor: {mse_seven} - eighth regressor: {mse_eight}')\n",
    "print(f'mse for nineth regressor: {mse_nine} - tenth regressor: {mse_ten}')\n",
    "mae_one = mean_absolute_error(y_test.iloc[:,0], y_pred[:,0])\n",
    "mae_two = mean_absolute_error(y_test.iloc[:,1], y_pred[:,1])\n",
    "mae_three = mean_absolute_error(y_test.iloc[:,2], y_pred[:,2])\n",
    "mae_four = mean_absolute_error(y_test.iloc[:,3], y_pred[:,3])\n",
    "mae_five = mean_absolute_error(y_test.iloc[:,4], y_pred[:,4])\n",
    "mae_six = mean_absolute_error(y_test.iloc[:,5], y_pred[:,5])\n",
    "mae_seven = mean_absolute_error(y_test.iloc[:,6], y_pred[:,6])\n",
    "mae_eight = mean_absolute_error(y_test.iloc[:,7], y_pred[:,7])\n",
    "mae_nine = mean_absolute_error(y_test.iloc[:,8], y_pred[:,8])\n",
    "mae_ten = mean_absolute_error(y_test.iloc[:,9], y_pred[:,9])\n",
    "print(\"MAE FOR EVERY OUTPUT\")\n",
    "print(f'mae for first regressor: {mae_one} - second regressor: {mae_two}')\n",
    "print(f'mae for third regressor: {mae_three} - fourth regressor: {mae_four}')\n",
    "print(f'mae for fifth regressor: {mae_five} - sixth regressor: {mae_six}')\n",
    "print(f'mae for seventh regressor: {mae_seven} - eighth regressor: {mae_eight}')\n",
    "print(f'mae for nineth regressor: {mae_nine} - tenth regressor: {mae_ten}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 933.78597953,  896.94365869,  387.13269174,  585.1866057 ,\n",
       "        313.32770855,  527.07115942,  317.89358743,  838.31336115,\n",
       "        494.72133801,  322.00940752, 1823.46139449,  897.16500116,\n",
       "        622.73421617,  315.98526673,  536.1715705 ,  383.69478804,\n",
       "        237.15952382,  375.84387492,  323.23312387,  614.39106743,\n",
       "        614.74268367,  438.46196089,  288.30820208,  329.1234693 ,\n",
       "        319.12938545,  380.05485553,  261.39098563,  607.22414236,\n",
       "        223.23154674,  599.87515777,  347.72727056,  440.22916991,\n",
       "        697.29476172,  586.79586287,  717.11938577,  419.03254471,\n",
       "        420.3630833 ,  672.2956425 ,  653.61898879,  644.58163458,\n",
       "        721.18319109,  580.20815864,  772.41039603,  508.08590927,\n",
       "        229.49317436,  583.37951846,  544.23753515,  547.52152518,\n",
       "        312.74840965,  629.44251825,  703.21118158,  682.79987391])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "price_pred = y_pred[:,1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(price_pred)), price_pred.flatten(), color='green')\n",
    "plt.scatter(range(len(price_pred)), y_test.iloc[:,1], color='red')\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Actual and Predicted \" + y_test.columns[1], fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      256.000000\n",
       "mean      1927.470590\n",
       "std       3742.786967\n",
       "min        160.000000\n",
       "25%        742.250000\n",
       "50%       1482.045000\n",
       "75%       2393.872500\n",
       "max      58344.000000\n",
       "Name: area_Walls, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['area_Walls'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINING A SEQUENTIAL TENSORFLOW DEEP LEARNING ALGORITHM  (https://machinelearningmastery.com/deep-learning-models-for-multi-output-regression/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    " optimizer = Adam(learning_rate=0.001)\n",
    " model = Sequential()\n",
    " model.add(Dense(10, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " model.add(Dense(10, activation='relu'))\n",
    " model.add(Dense(10, activation='relu'))\n",
    " model.add(Dense(n_outputs))\n",
    " model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y):\n",
    " results = list()\n",
    " n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    " # define evaluation procedure\n",
    " \"\"\"\n",
    " cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " # enumerate folds\n",
    " for train_ix, test_ix in cv.split(X):\n",
    " # prepare data\n",
    " X_train, X_test = X[train_ix], X[test_ix]\n",
    " y_train, y_test = y[train_ix], y[test_ix]\n",
    " # define model\n",
    " \"\"\"\n",
    " model = get_model(n_inputs, n_outputs)\n",
    " # fit model\n",
    " model.fit(X_train, y_train, verbose=0, epochs=1000)\n",
    " # evaluate model on test set\n",
    " mae = model.evaluate(X_test, y_test, verbose=0)\n",
    " # store result\n",
    "\n",
    " print('>%.3f' % mae)\n",
    " results.append(mae)\n",
    " return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mixalako/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      ">172.256\n",
      "MAE: 172.256 (0.000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate model\n",
    "results = evaluate_model(X_train.copy(), y_train.copy())\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(results), np.std(results)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAME LOGIC (https://regenerativetoday.com/a-step-by-step-tutorial-to-develop-a-multi-output-model-in-tensorflow/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df['area_Basement/slab'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floors</th>\n",
       "      <th>useful_area</th>\n",
       "      <th>apartments</th>\n",
       "      <th>total_area</th>\n",
       "      <th>serie</th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13077.4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>15673.6</td>\n",
       "      <td>101</td>\n",
       "      <td>1013.73</td>\n",
       "      <td>1043.93</td>\n",
       "      <td>1830.05</td>\n",
       "      <td>60.88</td>\n",
       "      <td>211.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2478.7</td>\n",
       "      <td>316</td>\n",
       "      <td>412.80</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1062.10</td>\n",
       "      <td>15.60</td>\n",
       "      <td>389.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1927.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2477.7</td>\n",
       "      <td>316</td>\n",
       "      <td>417.00</td>\n",
       "      <td>515.90</td>\n",
       "      <td>1054.60</td>\n",
       "      <td>15.60</td>\n",
       "      <td>397.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2041.9</td>\n",
       "      <td>103</td>\n",
       "      <td>321.40</td>\n",
       "      <td>379.50</td>\n",
       "      <td>913.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>299.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2189.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2731.9</td>\n",
       "      <td>316</td>\n",
       "      <td>495.80</td>\n",
       "      <td>590.50</td>\n",
       "      <td>1381.70</td>\n",
       "      <td>8.90</td>\n",
       "      <td>390.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>194.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>272.3</td>\n",
       "      <td>110</td>\n",
       "      <td>119.93</td>\n",
       "      <td>110.88</td>\n",
       "      <td>279.06</td>\n",
       "      <td>2.88</td>\n",
       "      <td>55.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1201.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1433.3</td>\n",
       "      <td>0</td>\n",
       "      <td>259.00</td>\n",
       "      <td>308.56</td>\n",
       "      <td>957.38</td>\n",
       "      <td>13.69</td>\n",
       "      <td>166.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.0</td>\n",
       "      <td>586.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>771.5</td>\n",
       "      <td>0</td>\n",
       "      <td>226.04</td>\n",
       "      <td>262.22</td>\n",
       "      <td>526.03</td>\n",
       "      <td>12.00</td>\n",
       "      <td>117.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>4.0</td>\n",
       "      <td>665.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750.7</td>\n",
       "      <td>0</td>\n",
       "      <td>120.50</td>\n",
       "      <td>142.10</td>\n",
       "      <td>596.92</td>\n",
       "      <td>6.65</td>\n",
       "      <td>171.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.0</td>\n",
       "      <td>519.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>732.1</td>\n",
       "      <td>316</td>\n",
       "      <td>182.30</td>\n",
       "      <td>209.70</td>\n",
       "      <td>576.49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>92.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     floors  useful_area  apartments  total_area serie  area_Basement/slab  \\\n",
       "0       9.0      13077.4       252.0     15673.6   101             1013.73   \n",
       "1       5.0       1930.5        45.0      2478.7   316              412.80   \n",
       "2       5.0       1927.5        45.0      2477.7   316              417.00   \n",
       "3       5.0       1583.7        30.0      2041.9   103              321.40   \n",
       "4       5.0       2189.3        53.0      2731.9   316              495.80   \n",
       "..      ...          ...         ...         ...   ...                 ...   \n",
       "251     2.0        194.8         4.0       272.3   110              119.93   \n",
       "252     4.0       1201.1        12.0      1433.3     0              259.00   \n",
       "253     3.0        586.4        10.0       771.5     0              226.04   \n",
       "254     4.0        665.1        12.0       750.7     0              120.50   \n",
       "255     3.0        519.1        12.0       732.1   316              182.30   \n",
       "\n",
       "     area_Roof/attic  area_Walls  area_doors  area_windows  ...    3    4  \\\n",
       "0            1043.93     1830.05       60.88        211.62  ...  0.0  0.0   \n",
       "1             515.90     1062.10       15.60        389.50  ...  0.0  0.0   \n",
       "2             515.90     1054.60       15.60        397.00  ...  0.0  0.0   \n",
       "3             379.50      913.10        8.30        299.60  ...  1.0  0.0   \n",
       "4             590.50     1381.70        8.90        390.20  ...  0.0  0.0   \n",
       "..               ...         ...         ...           ...  ...  ...  ...   \n",
       "251           110.88      279.06        2.88         55.10  ...  0.0  0.0   \n",
       "252           308.56      957.38       13.69        166.59  ...  0.0  0.0   \n",
       "253           262.22      526.03       12.00        117.85  ...  0.0  0.0   \n",
       "254           142.10      596.92        6.65        171.08  ...  0.0  0.0   \n",
       "255           209.70      576.49        2.54         92.10  ...  0.0  0.0   \n",
       "\n",
       "       5    6    7    8    9   10   11  kmeans  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0       8  \n",
       "1    0.0  0.0  0.0  1.0  0.0  0.0  0.0       2  \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0       2  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0       9  \n",
       "4    0.0  0.0  0.0  1.0  0.0  0.0  0.0       2  \n",
       "..   ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "251  0.0  1.0  0.0  0.0  0.0  0.0  0.0       6  \n",
       "252  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1  \n",
       "253  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1  \n",
       "254  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1  \n",
       "255  0.0  0.0  0.0  1.0  0.0  0.0  0.0       2  \n",
       "\n",
       "[256 rows x 28 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_form(data):\n",
    "    outputs = []\n",
    "    for feature_name in ['area_Basement/slab', 'area_Roof/attic', 'area_Walls', 'area_doors', 'area_windows', 'U_Basement/slab', 'U_Roof/attic', 'U_Walls', 'U_doors', 'U_windows']:\n",
    "        output = data.pop(feature_name)\n",
    "        output = np.array(output)\n",
    "        outputs.append(output)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = train_test_split(X_train.copy(), test_size=0.2, random_state=42)\n",
    "train_y, val_y = train_test_split(y_train.copy(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = output_form(train_y.copy())\n",
    "test_y = output_form(y_test.copy())\n",
    "val_y = output_form(val_y.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def base_model(inputs):\n",
    "    x= Dense(500, activation='relu')(inputs)\n",
    "    x= Dense(500, activation='relu')(x)\n",
    "    x= Dense(300, activation='relu')(x)\n",
    "    x= Dense(300, activation='relu')(x)\n",
    "    x= Dense(300, activation='relu')(x)\n",
    "    x= Dense(300, activation='relu')(x)\n",
    "    x= Dense(150, activation='relu')(x)\n",
    "    x= Dense(150, activation='relu')(x)\n",
    "    return x\n",
    "def final_model(inputs):\n",
    "    x = base_model(inputs)\n",
    "    #area_Basement = Dense(units='1', name='area_Basement')(x)\n",
    "    #area_Roof = Dense(units = '1', name = 'area_Roof')(x)\n",
    "    #area_Walls = Dense(units='1', name='area_Walls')(x)\n",
    "    #area_doors = Dense(units = '1', name = 'area_doors')(x)\n",
    "    #area_windows = Dense(units='1', name='area_windows')(x)\n",
    "    #U_Basement = Dense(units='1', name='U_Basement')(x)\n",
    "    #U_Roof = Dense(units = '1', name = 'U_Roof')(x)\n",
    "    #U_Walls = Dense(units='1', name='U_Walls')(x)\n",
    "    #U_doors = Dense(units = '1', name = 'U_doors')(x)\n",
    "    U_windows = Dense(units = '1', name = 'area_Basement')(x)\n",
    "    model = Model(inputs=inputs, outputs = [ U_windows ])\n",
    "    #area_Basement, area_Roof, area_Walls, area_doors, area_windows, U_Basement, U_Roof, U_Walls, U_doors,\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(X_train.shape[1])\n",
    "model = final_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "             loss = {#'area_Basement': 'mae',\n",
    "                     #'area_Roof': 'mae',\n",
    "                     #'area_Walls': 'mae',\n",
    "                     #'area_doors': 'mae',\n",
    "                     #'area_windows': 'mae',\n",
    "                     #'U_Basement': 'mae',\n",
    "                     #'U_Roof': 'mae',\n",
    "                     #'U_Walls': 'mae',\n",
    "                     #'U_doors': 'mae',\n",
    "                     'area_Basement': 'mae'},\n",
    "             metrics={#'area_Basement': RootMeanSquaredError(),\n",
    "                      #'area_Roof': RootMeanSquaredError(),\n",
    "                      #'area_Walls': RootMeanSquaredError(),\n",
    "                      #'area_doors': RootMeanSquaredError(),\n",
    "                      #'area_windows': RootMeanSquaredError(),\n",
    "                      #'U_Basement': RootMeanSquaredError(),\n",
    "                      #'U_Roof': RootMeanSquaredError(),\n",
    "                      #'U_Walls': RootMeanSquaredError(),\n",
    "                      #'U_doors': RootMeanSquaredError(),\n",
    "                      'area_Basement': RootMeanSquaredError()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163 samples, validate on 41 samples\n",
      "Epoch 1/400\n",
      "163/163 [==============================] - 0s 3ms/sample - loss: 550.2591 - root_mean_squared_error: 667.3716 - val_loss: 0.7525 - val_root_mean_squared_error: 0.8634\n",
      "Epoch 2/400\n",
      "163/163 [==============================] - 0s 353us/sample - loss: 538.4116 - root_mean_squared_error: 657.3453 - val_loss: 70.4797 - val_root_mean_squared_error: 71.5990\n",
      "Epoch 3/400\n",
      "163/163 [==============================] - 0s 342us/sample - loss: 361.0271 - root_mean_squared_error: 493.0488 - val_loss: 751.6061 - val_root_mean_squared_error: 765.0194\n",
      "Epoch 4/400\n",
      "163/163 [==============================] - 0s 354us/sample - loss: 255.2977 - root_mean_squared_error: 349.0492 - val_loss: 341.3097 - val_root_mean_squared_error: 351.1086\n",
      "Epoch 5/400\n",
      "163/163 [==============================] - 0s 405us/sample - loss: 220.9375 - root_mean_squared_error: 337.4865 - val_loss: 735.6674 - val_root_mean_squared_error: 769.4213\n",
      "Epoch 6/400\n",
      "163/163 [==============================] - 0s 353us/sample - loss: 250.3286 - root_mean_squared_error: 314.4358 - val_loss: 457.1272 - val_root_mean_squared_error: 487.4913\n",
      "Epoch 7/400\n",
      "163/163 [==============================] - 0s 376us/sample - loss: 186.5720 - root_mean_squared_error: 296.5715 - val_loss: 510.0146 - val_root_mean_squared_error: 552.0019\n",
      "Epoch 8/400\n",
      "163/163 [==============================] - 0s 372us/sample - loss: 177.8371 - root_mean_squared_error: 279.9883 - val_loss: 532.5916 - val_root_mean_squared_error: 584.8917\n",
      "Epoch 9/400\n",
      "163/163 [==============================] - 0s 424us/sample - loss: 165.9272 - root_mean_squared_error: 254.6218 - val_loss: 550.6035 - val_root_mean_squared_error: 618.3254\n",
      "Epoch 10/400\n",
      "163/163 [==============================] - 0s 396us/sample - loss: 165.5658 - root_mean_squared_error: 259.2683 - val_loss: 621.0293 - val_root_mean_squared_error: 704.1167\n",
      "Epoch 11/400\n",
      "163/163 [==============================] - 0s 365us/sample - loss: 167.8152 - root_mean_squared_error: 248.2290 - val_loss: 505.1676 - val_root_mean_squared_error: 577.6959\n",
      "Epoch 12/400\n",
      "163/163 [==============================] - 0s 325us/sample - loss: 161.2232 - root_mean_squared_error: 260.5536 - val_loss: 540.3424 - val_root_mean_squared_error: 619.6437\n",
      "Epoch 13/400\n",
      "163/163 [==============================] - 0s 368us/sample - loss: 143.0728 - root_mean_squared_error: 228.9343 - val_loss: 475.5275 - val_root_mean_squared_error: 552.0710\n",
      "Epoch 14/400\n",
      "163/163 [==============================] - 0s 370us/sample - loss: 145.1956 - root_mean_squared_error: 242.1971 - val_loss: 577.7309 - val_root_mean_squared_error: 671.2740\n",
      "Epoch 15/400\n",
      "163/163 [==============================] - 0s 368us/sample - loss: 127.0599 - root_mean_squared_error: 217.1246 - val_loss: 413.6355 - val_root_mean_squared_error: 489.6013\n",
      "Epoch 16/400\n",
      "163/163 [==============================] - 0s 343us/sample - loss: 164.5993 - root_mean_squared_error: 265.6323 - val_loss: 681.9789 - val_root_mean_squared_error: 802.2791\n",
      "Epoch 17/400\n",
      "163/163 [==============================] - 0s 371us/sample - loss: 157.6839 - root_mean_squared_error: 251.3130 - val_loss: 410.2706 - val_root_mean_squared_error: 497.0352\n",
      "Epoch 18/400\n",
      "163/163 [==============================] - 0s 336us/sample - loss: 141.2718 - root_mean_squared_error: 234.4068 - val_loss: 695.3322 - val_root_mean_squared_error: 828.6224\n",
      "Epoch 19/400\n",
      "163/163 [==============================] - 0s 368us/sample - loss: 146.4641 - root_mean_squared_error: 238.8692 - val_loss: 357.0504 - val_root_mean_squared_error: 438.1202\n",
      "Epoch 20/400\n",
      "163/163 [==============================] - 0s 374us/sample - loss: 216.3597 - root_mean_squared_error: 299.5969 - val_loss: 554.2824 - val_root_mean_squared_error: 662.6972\n",
      "Epoch 21/400\n",
      "163/163 [==============================] - 0s 381us/sample - loss: 141.5773 - root_mean_squared_error: 238.7906 - val_loss: 489.8752 - val_root_mean_squared_error: 590.4678\n",
      "Epoch 22/400\n",
      "163/163 [==============================] - 0s 351us/sample - loss: 125.4051 - root_mean_squared_error: 218.8820 - val_loss: 624.1273 - val_root_mean_squared_error: 741.9791\n",
      "Epoch 23/400\n",
      "163/163 [==============================] - 0s 340us/sample - loss: 127.3113 - root_mean_squared_error: 222.6133 - val_loss: 478.2923 - val_root_mean_squared_error: 574.3198\n",
      "Epoch 24/400\n",
      "163/163 [==============================] - 0s 450us/sample - loss: 135.4935 - root_mean_squared_error: 230.3641 - val_loss: 638.9446 - val_root_mean_squared_error: 758.4484\n",
      "Epoch 25/400\n",
      "163/163 [==============================] - 0s 306us/sample - loss: 135.6802 - root_mean_squared_error: 228.7327 - val_loss: 439.0712 - val_root_mean_squared_error: 525.1208\n",
      "Epoch 26/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 157.7196 - root_mean_squared_error: 248.7714 - val_loss: 629.9700 - val_root_mean_squared_error: 739.1550\n",
      "Epoch 27/400\n",
      "163/163 [==============================] - 0s 269us/sample - loss: 131.8535 - root_mean_squared_error: 217.9744 - val_loss: 493.4570 - val_root_mean_squared_error: 586.5986\n",
      "Epoch 28/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 119.0767 - root_mean_squared_error: 211.7954 - val_loss: 637.2155 - val_root_mean_squared_error: 758.3721\n",
      "Epoch 29/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 124.1248 - root_mean_squared_error: 212.0927 - val_loss: 494.7484 - val_root_mean_squared_error: 598.8643\n",
      "Epoch 30/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 113.6971 - root_mean_squared_error: 202.2713 - val_loss: 627.0349 - val_root_mean_squared_error: 754.7722\n",
      "Epoch 31/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 109.9514 - root_mean_squared_error: 204.5882 - val_loss: 506.6055 - val_root_mean_squared_error: 625.5505\n",
      "Epoch 32/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 114.6017 - root_mean_squared_error: 210.0416 - val_loss: 577.1973 - val_root_mean_squared_error: 714.5045\n",
      "Epoch 33/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 107.3432 - root_mean_squared_error: 205.5090 - val_loss: 552.1292 - val_root_mean_squared_error: 682.8246\n",
      "Epoch 34/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 105.7537 - root_mean_squared_error: 206.6080 - val_loss: 503.3698 - val_root_mean_squared_error: 619.0924\n",
      "Epoch 35/400\n",
      "163/163 [==============================] - 0s 291us/sample - loss: 110.4935 - root_mean_squared_error: 209.5771 - val_loss: 655.1956 - val_root_mean_squared_error: 800.2112\n",
      "Epoch 36/400\n",
      "163/163 [==============================] - 0s 277us/sample - loss: 138.6601 - root_mean_squared_error: 231.0173 - val_loss: 443.0223 - val_root_mean_squared_error: 558.7443\n",
      "Epoch 37/400\n",
      "163/163 [==============================] - 0s 368us/sample - loss: 122.4120 - root_mean_squared_error: 217.4825 - val_loss: 653.5805 - val_root_mean_squared_error: 806.7747\n",
      "Epoch 38/400\n",
      "163/163 [==============================] - 0s 291us/sample - loss: 125.3393 - root_mean_squared_error: 219.2560 - val_loss: 423.3460 - val_root_mean_squared_error: 534.8360\n",
      "Epoch 39/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 120.0917 - root_mean_squared_error: 223.5637 - val_loss: 585.3660 - val_root_mean_squared_error: 724.3665\n",
      "Epoch 40/400\n",
      "163/163 [==============================] - 0s 260us/sample - loss: 106.8097 - root_mean_squared_error: 204.9305 - val_loss: 547.8820 - val_root_mean_squared_error: 675.9447\n",
      "Epoch 41/400\n",
      "163/163 [==============================] - 0s 230us/sample - loss: 111.0438 - root_mean_squared_error: 206.9244 - val_loss: 522.1951 - val_root_mean_squared_error: 645.1102\n",
      "Epoch 42/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 103.2245 - root_mean_squared_error: 206.2362 - val_loss: 587.1878 - val_root_mean_squared_error: 719.0129\n",
      "Epoch 43/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 107.5133 - root_mean_squared_error: 210.5873 - val_loss: 489.9374 - val_root_mean_squared_error: 605.6002\n",
      "Epoch 44/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 114.4731 - root_mean_squared_error: 217.5401 - val_loss: 595.4184 - val_root_mean_squared_error: 732.2585\n",
      "Epoch 45/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 100.4073 - root_mean_squared_error: 200.8619 - val_loss: 527.3008 - val_root_mean_squared_error: 642.6324\n",
      "Epoch 46/400\n",
      "163/163 [==============================] - 0s 212us/sample - loss: 99.6668 - root_mean_squared_error: 199.9473 - val_loss: 568.1123 - val_root_mean_squared_error: 683.2460\n",
      "Epoch 47/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 102.5234 - root_mean_squared_error: 204.1588 - val_loss: 544.7142 - val_root_mean_squared_error: 661.7076\n",
      "Epoch 48/400\n",
      "163/163 [==============================] - 0s 289us/sample - loss: 97.9823 - root_mean_squared_error: 198.2620 - val_loss: 609.1021 - val_root_mean_squared_error: 740.0042\n",
      "Epoch 49/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 124.9657 - root_mean_squared_error: 226.2396 - val_loss: 510.0359 - val_root_mean_squared_error: 629.7704\n",
      "Epoch 50/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 99.3602 - root_mean_squared_error: 199.3068 - val_loss: 600.0210 - val_root_mean_squared_error: 731.5254\n",
      "Epoch 51/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 100.0948 - root_mean_squared_error: 202.5719 - val_loss: 549.0613 - val_root_mean_squared_error: 674.4297\n",
      "Epoch 52/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 101.8855 - root_mean_squared_error: 206.4650 - val_loss: 476.0378 - val_root_mean_squared_error: 590.4004\n",
      "Epoch 53/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 127.7197 - root_mean_squared_error: 227.8972 - val_loss: 647.1531 - val_root_mean_squared_error: 788.4250\n",
      "Epoch 54/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 119.3468 - root_mean_squared_error: 214.7703 - val_loss: 517.0395 - val_root_mean_squared_error: 638.7896\n",
      "Epoch 55/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 111.5597 - root_mean_squared_error: 210.1368 - val_loss: 519.9356 - val_root_mean_squared_error: 642.7511\n",
      "Epoch 56/400\n",
      "163/163 [==============================] - 0s 252us/sample - loss: 107.3245 - root_mean_squared_error: 208.8642 - val_loss: 615.9674 - val_root_mean_squared_error: 751.0568\n",
      "Epoch 57/400\n",
      "163/163 [==============================] - 0s 257us/sample - loss: 98.6796 - root_mean_squared_error: 196.2500 - val_loss: 507.3618 - val_root_mean_squared_error: 623.5369\n",
      "Epoch 58/400\n",
      "163/163 [==============================] - 0s 324us/sample - loss: 100.7889 - root_mean_squared_error: 197.2121 - val_loss: 660.7461 - val_root_mean_squared_error: 804.1688\n",
      "Epoch 59/400\n",
      "163/163 [==============================] - 0s 265us/sample - loss: 119.6049 - root_mean_squared_error: 206.7266 - val_loss: 523.6234 - val_root_mean_squared_error: 650.8237\n",
      "Epoch 60/400\n",
      "163/163 [==============================] - 0s 216us/sample - loss: 112.1230 - root_mean_squared_error: 203.8856 - val_loss: 472.0436 - val_root_mean_squared_error: 584.6932\n",
      "Epoch 61/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 205.2213 - root_mean_squared_error: 293.8941 - val_loss: 495.3450 - val_root_mean_squared_error: 597.9175\n",
      "Epoch 62/400\n",
      "163/163 [==============================] - 0s 216us/sample - loss: 135.5991 - root_mean_squared_error: 220.4698 - val_loss: 484.4594 - val_root_mean_squared_error: 580.6700\n",
      "Epoch 63/400\n",
      "163/163 [==============================] - 0s 244us/sample - loss: 182.3993 - root_mean_squared_error: 273.9389 - val_loss: 502.6361 - val_root_mean_squared_error: 599.9460\n",
      "Epoch 64/400\n",
      "163/163 [==============================] - 0s 258us/sample - loss: 133.3641 - root_mean_squared_error: 217.9187 - val_loss: 525.0589 - val_root_mean_squared_error: 631.0352\n",
      "Epoch 65/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 142.4284 - root_mean_squared_error: 232.9764 - val_loss: 572.7205 - val_root_mean_squared_error: 693.6360\n",
      "Epoch 66/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 108.2390 - root_mean_squared_error: 198.5706 - val_loss: 518.5149 - val_root_mean_squared_error: 626.7318\n",
      "Epoch 67/400\n",
      "163/163 [==============================] - 0s 257us/sample - loss: 115.2592 - root_mean_squared_error: 211.2438 - val_loss: 639.4068 - val_root_mean_squared_error: 761.7397\n",
      "Epoch 68/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 112.9109 - root_mean_squared_error: 201.2599 - val_loss: 503.2059 - val_root_mean_squared_error: 606.0956\n",
      "Epoch 69/400\n",
      "163/163 [==============================] - 0s 247us/sample - loss: 108.3829 - root_mean_squared_error: 203.1459 - val_loss: 561.9295 - val_root_mean_squared_error: 677.1993\n",
      "Epoch 70/400\n",
      "163/163 [==============================] - 0s 249us/sample - loss: 113.5655 - root_mean_squared_error: 208.3647 - val_loss: 556.7345 - val_root_mean_squared_error: 667.3344\n",
      "Epoch 71/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 96.5098 - root_mean_squared_error: 193.8696 - val_loss: 564.4422 - val_root_mean_squared_error: 676.5302\n",
      "Epoch 72/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 92.7357 - root_mean_squared_error: 192.9864 - val_loss: 591.9201 - val_root_mean_squared_error: 707.9130\n",
      "Epoch 73/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 97.0011 - root_mean_squared_error: 199.8355 - val_loss: 558.1536 - val_root_mean_squared_error: 673.8734\n",
      "Epoch 74/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 92.5630 - root_mean_squared_error: 192.9858 - val_loss: 483.5460 - val_root_mean_squared_error: 591.4236\n",
      "Epoch 75/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 119.7550 - root_mean_squared_error: 216.7266 - val_loss: 700.1759 - val_root_mean_squared_error: 843.3649\n",
      "Epoch 76/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 155.1426 - root_mean_squared_error: 234.4540 - val_loss: 452.1996 - val_root_mean_squared_error: 561.5400\n",
      "Epoch 77/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 133.5327 - root_mean_squared_error: 226.7870 - val_loss: 634.4542 - val_root_mean_squared_error: 774.0383\n",
      "Epoch 78/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 101.6600 - root_mean_squared_error: 203.6159 - val_loss: 516.8008 - val_root_mean_squared_error: 629.1918\n",
      "Epoch 79/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 102.0838 - root_mean_squared_error: 203.8952 - val_loss: 602.8639 - val_root_mean_squared_error: 730.0944\n",
      "Epoch 80/400\n",
      "163/163 [==============================] - 0s 284us/sample - loss: 98.9655 - root_mean_squared_error: 194.5072 - val_loss: 568.2249 - val_root_mean_squared_error: 690.3469\n",
      "Epoch 81/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 101.1901 - root_mean_squared_error: 194.6069 - val_loss: 557.8197 - val_root_mean_squared_error: 672.9680\n",
      "Epoch 82/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 100.3776 - root_mean_squared_error: 201.0622 - val_loss: 631.5169 - val_root_mean_squared_error: 759.1138\n",
      "Epoch 83/400\n",
      "163/163 [==============================] - 0s 215us/sample - loss: 102.1629 - root_mean_squared_error: 195.8603 - val_loss: 526.1735 - val_root_mean_squared_error: 638.8306\n",
      "Epoch 84/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 94.9314 - root_mean_squared_error: 194.2694 - val_loss: 609.4467 - val_root_mean_squared_error: 741.3671\n",
      "Epoch 85/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 99.2132 - root_mean_squared_error: 204.2437 - val_loss: 619.1494 - val_root_mean_squared_error: 754.6807\n",
      "Epoch 86/400\n",
      "163/163 [==============================] - 0s 227us/sample - loss: 102.4747 - root_mean_squared_error: 201.9608 - val_loss: 492.0431 - val_root_mean_squared_error: 606.5189\n",
      "Epoch 87/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 117.9839 - root_mean_squared_error: 216.2299 - val_loss: 659.5834 - val_root_mean_squared_error: 799.4349\n",
      "Epoch 88/400\n",
      "163/163 [==============================] - 0s 220us/sample - loss: 110.2474 - root_mean_squared_error: 208.8849 - val_loss: 554.1564 - val_root_mean_squared_error: 684.7627\n",
      "Epoch 89/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 112.3415 - root_mean_squared_error: 209.2125 - val_loss: 585.3779 - val_root_mean_squared_error: 737.2545\n",
      "Epoch 90/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 101.5393 - root_mean_squared_error: 204.8016 - val_loss: 598.0898 - val_root_mean_squared_error: 749.0504\n",
      "Epoch 91/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 105.4290 - root_mean_squared_error: 206.3763 - val_loss: 486.4882 - val_root_mean_squared_error: 603.1853\n",
      "Epoch 92/400\n",
      "163/163 [==============================] - 0s 217us/sample - loss: 109.3165 - root_mean_squared_error: 214.6289 - val_loss: 606.9195 - val_root_mean_squared_error: 737.1295\n",
      "Epoch 93/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 90.5809 - root_mean_squared_error: 192.2696 - val_loss: 486.9645 - val_root_mean_squared_error: 599.0787\n",
      "Epoch 94/400\n",
      "163/163 [==============================] - 0s 217us/sample - loss: 108.1895 - root_mean_squared_error: 203.2962 - val_loss: 655.1469 - val_root_mean_squared_error: 797.9268\n",
      "Epoch 95/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 102.2725 - root_mean_squared_error: 194.6193 - val_loss: 508.1328 - val_root_mean_squared_error: 624.7862\n",
      "Epoch 96/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 96.5155 - root_mean_squared_error: 198.9308 - val_loss: 554.6305 - val_root_mean_squared_error: 670.6198\n",
      "Epoch 97/400\n",
      "163/163 [==============================] - 0s 214us/sample - loss: 97.0077 - root_mean_squared_error: 197.4871 - val_loss: 594.8963 - val_root_mean_squared_error: 719.4297\n",
      "Epoch 98/400\n",
      "163/163 [==============================] - 0s 247us/sample - loss: 87.4279 - root_mean_squared_error: 187.2766 - val_loss: 536.3864 - val_root_mean_squared_error: 656.9086\n",
      "Epoch 99/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 99.9112 - root_mean_squared_error: 198.6211 - val_loss: 572.5978 - val_root_mean_squared_error: 711.5705\n",
      "Epoch 100/400\n",
      "163/163 [==============================] - 0s 230us/sample - loss: 92.3073 - root_mean_squared_error: 195.0324 - val_loss: 594.0431 - val_root_mean_squared_error: 736.3001\n",
      "Epoch 101/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 92.4331 - root_mean_squared_error: 193.5092 - val_loss: 516.2729 - val_root_mean_squared_error: 637.6865\n",
      "Epoch 102/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 92.9497 - root_mean_squared_error: 196.2756 - val_loss: 640.1674 - val_root_mean_squared_error: 785.6433\n",
      "Epoch 103/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 109.4156 - root_mean_squared_error: 207.8631 - val_loss: 514.8281 - val_root_mean_squared_error: 641.2206\n",
      "Epoch 104/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 91.8320 - root_mean_squared_error: 194.4637 - val_loss: 570.4823 - val_root_mean_squared_error: 713.8290\n",
      "Epoch 105/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 96.0800 - root_mean_squared_error: 197.2324 - val_loss: 551.9118 - val_root_mean_squared_error: 693.1942\n",
      "Epoch 106/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 91.1459 - root_mean_squared_error: 193.1013 - val_loss: 608.3392 - val_root_mean_squared_error: 746.9396\n",
      "Epoch 107/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 97.4355 - root_mean_squared_error: 190.9155 - val_loss: 569.2278 - val_root_mean_squared_error: 688.5217\n",
      "Epoch 108/400\n",
      "163/163 [==============================] - 0s 359us/sample - loss: 94.5740 - root_mean_squared_error: 190.6858 - val_loss: 571.9698 - val_root_mean_squared_error: 689.4287\n",
      "Epoch 109/400\n",
      "163/163 [==============================] - 0s 280us/sample - loss: 87.5602 - root_mean_squared_error: 188.2986 - val_loss: 574.9720 - val_root_mean_squared_error: 698.4354\n",
      "Epoch 110/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 89.1443 - root_mean_squared_error: 188.3082 - val_loss: 588.1134 - val_root_mean_squared_error: 712.0168\n",
      "Epoch 111/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 87.7428 - root_mean_squared_error: 186.6597 - val_loss: 572.8096 - val_root_mean_squared_error: 698.1054\n",
      "Epoch 112/400\n",
      "163/163 [==============================] - 0s 336us/sample - loss: 89.3508 - root_mean_squared_error: 186.4387 - val_loss: 607.9853 - val_root_mean_squared_error: 745.2397\n",
      "Epoch 113/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 92.4741 - root_mean_squared_error: 189.2594 - val_loss: 548.4681 - val_root_mean_squared_error: 677.7303\n",
      "Epoch 114/400\n",
      "163/163 [==============================] - 0s 247us/sample - loss: 95.4158 - root_mean_squared_error: 196.0920 - val_loss: 601.8860 - val_root_mean_squared_error: 741.6480\n",
      "Epoch 115/400\n",
      "163/163 [==============================] - 0s 217us/sample - loss: 87.9846 - root_mean_squared_error: 187.6487 - val_loss: 569.2398 - val_root_mean_squared_error: 699.0537\n",
      "Epoch 116/400\n",
      "163/163 [==============================] - 0s 266us/sample - loss: 88.1319 - root_mean_squared_error: 188.5874 - val_loss: 609.2397 - val_root_mean_squared_error: 738.8294\n",
      "Epoch 117/400\n",
      "163/163 [==============================] - 0s 216us/sample - loss: 87.2593 - root_mean_squared_error: 186.2329 - val_loss: 569.2411 - val_root_mean_squared_error: 694.0637\n",
      "Epoch 118/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 87.6634 - root_mean_squared_error: 187.6338 - val_loss: 531.6514 - val_root_mean_squared_error: 647.2864\n",
      "Epoch 119/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 92.4720 - root_mean_squared_error: 196.2438 - val_loss: 600.6767 - val_root_mean_squared_error: 726.7039\n",
      "Epoch 120/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 91.0655 - root_mean_squared_error: 192.4583 - val_loss: 661.1045 - val_root_mean_squared_error: 803.2134\n",
      "Epoch 121/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 128.3037 - root_mean_squared_error: 214.8842 - val_loss: 498.3678 - val_root_mean_squared_error: 620.0498\n",
      "Epoch 122/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 113.2994 - root_mean_squared_error: 207.1186 - val_loss: 700.4883 - val_root_mean_squared_error: 850.9719\n",
      "Epoch 123/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 125.7011 - root_mean_squared_error: 208.7227 - val_loss: 483.9612 - val_root_mean_squared_error: 591.6152\n",
      "Epoch 124/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 107.6468 - root_mean_squared_error: 204.3585 - val_loss: 644.5767 - val_root_mean_squared_error: 772.3436\n",
      "Epoch 125/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 91.6392 - root_mean_squared_error: 187.0550 - val_loss: 567.4268 - val_root_mean_squared_error: 673.9704\n",
      "Epoch 126/400\n",
      "163/163 [==============================] - 0s 218us/sample - loss: 92.1544 - root_mean_squared_error: 186.8306 - val_loss: 582.1374 - val_root_mean_squared_error: 694.3574\n",
      "Epoch 127/400\n",
      "163/163 [==============================] - 0s 275us/sample - loss: 84.4752 - root_mean_squared_error: 185.6731 - val_loss: 610.8916 - val_root_mean_squared_error: 739.4925\n",
      "Epoch 128/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 89.1470 - root_mean_squared_error: 187.5399 - val_loss: 538.3303 - val_root_mean_squared_error: 662.4053\n",
      "Epoch 129/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 93.4439 - root_mean_squared_error: 195.8066 - val_loss: 669.7460 - val_root_mean_squared_error: 818.2444\n",
      "Epoch 130/400\n",
      "163/163 [==============================] - 0s 256us/sample - loss: 96.6538 - root_mean_squared_error: 192.3066 - val_loss: 527.3752 - val_root_mean_squared_error: 653.7444\n",
      "Epoch 131/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 90.4895 - root_mean_squared_error: 197.7330 - val_loss: 549.2888 - val_root_mean_squared_error: 680.4164\n",
      "Epoch 132/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 87.7756 - root_mean_squared_error: 194.5312 - val_loss: 567.3302 - val_root_mean_squared_error: 695.9281\n",
      "Epoch 133/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 83.7939 - root_mean_squared_error: 188.2586 - val_loss: 585.2379 - val_root_mean_squared_error: 723.3478\n",
      "Epoch 134/400\n",
      "163/163 [==============================] - 0s 256us/sample - loss: 85.7079 - root_mean_squared_error: 189.2228 - val_loss: 602.2122 - val_root_mean_squared_error: 743.0820\n",
      "Epoch 135/400\n",
      "163/163 [==============================] - 0s 317us/sample - loss: 92.8385 - root_mean_squared_error: 186.4327 - val_loss: 529.4186 - val_root_mean_squared_error: 651.9744\n",
      "Epoch 136/400\n",
      "163/163 [==============================] - 0s 277us/sample - loss: 86.9187 - root_mean_squared_error: 191.5540 - val_loss: 642.3077 - val_root_mean_squared_error: 784.7122\n",
      "Epoch 137/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 91.3634 - root_mean_squared_error: 195.4664 - val_loss: 533.0313 - val_root_mean_squared_error: 654.2090\n",
      "Epoch 138/400\n",
      "163/163 [==============================] - 0s 220us/sample - loss: 88.8099 - root_mean_squared_error: 191.6160 - val_loss: 601.6359 - val_root_mean_squared_error: 733.4814\n",
      "Epoch 139/400\n",
      "163/163 [==============================] - 0s 257us/sample - loss: 89.7630 - root_mean_squared_error: 187.4784 - val_loss: 582.5943 - val_root_mean_squared_error: 710.9984\n",
      "Epoch 140/400\n",
      "163/163 [==============================] - 0s 248us/sample - loss: 88.8791 - root_mean_squared_error: 184.3963 - val_loss: 554.1338 - val_root_mean_squared_error: 680.8080\n",
      "Epoch 141/400\n",
      "163/163 [==============================] - 0s 281us/sample - loss: 85.4443 - root_mean_squared_error: 189.3708 - val_loss: 545.7347 - val_root_mean_squared_error: 670.9478\n",
      "Epoch 142/400\n",
      "163/163 [==============================] - 0s 267us/sample - loss: 87.6624 - root_mean_squared_error: 187.9622 - val_loss: 585.8713 - val_root_mean_squared_error: 713.9611\n",
      "Epoch 143/400\n",
      "163/163 [==============================] - 0s 218us/sample - loss: 86.4332 - root_mean_squared_error: 189.9387 - val_loss: 633.2980 - val_root_mean_squared_error: 765.5935\n",
      "Epoch 144/400\n",
      "163/163 [==============================] - 0s 244us/sample - loss: 90.1512 - root_mean_squared_error: 188.3325 - val_loss: 555.6728 - val_root_mean_squared_error: 666.8212\n",
      "Epoch 145/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 91.9227 - root_mean_squared_error: 188.3990 - val_loss: 609.8745 - val_root_mean_squared_error: 730.9606\n",
      "Epoch 146/400\n",
      "163/163 [==============================] - 0s 227us/sample - loss: 86.8918 - root_mean_squared_error: 186.1578 - val_loss: 621.6589 - val_root_mean_squared_error: 754.7583\n",
      "Epoch 147/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 87.4675 - root_mean_squared_error: 180.7572 - val_loss: 533.9445 - val_root_mean_squared_error: 650.4844\n",
      "Epoch 148/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 91.5522 - root_mean_squared_error: 193.4902 - val_loss: 597.0446 - val_root_mean_squared_error: 721.8384\n",
      "Epoch 149/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 87.8965 - root_mean_squared_error: 188.5304 - val_loss: 525.0711 - val_root_mean_squared_error: 641.8237\n",
      "Epoch 150/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 93.0416 - root_mean_squared_error: 193.2612 - val_loss: 599.9144 - val_root_mean_squared_error: 742.3032\n",
      "Epoch 151/400\n",
      "163/163 [==============================] - 0s 275us/sample - loss: 103.2454 - root_mean_squared_error: 207.5784 - val_loss: 578.7186 - val_root_mean_squared_error: 713.5414\n",
      "Epoch 152/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 100.1100 - root_mean_squared_error: 195.2951 - val_loss: 496.0575 - val_root_mean_squared_error: 616.1100\n",
      "Epoch 153/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 108.2800 - root_mean_squared_error: 205.8274 - val_loss: 662.2140 - val_root_mean_squared_error: 809.0345\n",
      "Epoch 154/400\n",
      "163/163 [==============================] - 0s 271us/sample - loss: 103.4789 - root_mean_squared_error: 193.9771 - val_loss: 561.3417 - val_root_mean_squared_error: 682.5344\n",
      "Epoch 155/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 88.6325 - root_mean_squared_error: 184.3542 - val_loss: 580.1169 - val_root_mean_squared_error: 701.7754\n",
      "Epoch 156/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 84.2669 - root_mean_squared_error: 183.2506 - val_loss: 575.7025 - val_root_mean_squared_error: 697.0993\n",
      "Epoch 157/400\n",
      "163/163 [==============================] - 0s 459us/sample - loss: 85.3087 - root_mean_squared_error: 186.3483 - val_loss: 541.4165 - val_root_mean_squared_error: 657.5940\n",
      "Epoch 158/400\n",
      "163/163 [==============================] - 0s 272us/sample - loss: 87.7316 - root_mean_squared_error: 190.9721 - val_loss: 593.5830 - val_root_mean_squared_error: 720.8343\n",
      "Epoch 159/400\n",
      "163/163 [==============================] - 0s 277us/sample - loss: 86.4130 - root_mean_squared_error: 183.0651 - val_loss: 627.5395 - val_root_mean_squared_error: 765.0897\n",
      "Epoch 160/400\n",
      "163/163 [==============================] - 0s 262us/sample - loss: 88.2627 - root_mean_squared_error: 183.6169 - val_loss: 562.1333 - val_root_mean_squared_error: 696.9419\n",
      "Epoch 161/400\n",
      "163/163 [==============================] - 0s 264us/sample - loss: 92.0922 - root_mean_squared_error: 189.4865 - val_loss: 549.4008 - val_root_mean_squared_error: 694.6543\n",
      "Epoch 162/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 101.2127 - root_mean_squared_error: 200.3499 - val_loss: 626.3154 - val_root_mean_squared_error: 780.8389\n",
      "Epoch 163/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 82.5152 - root_mean_squared_error: 188.3127 - val_loss: 529.1865 - val_root_mean_squared_error: 653.3828\n",
      "Epoch 164/400\n",
      "163/163 [==============================] - 0s 258us/sample - loss: 89.8769 - root_mean_squared_error: 191.9905 - val_loss: 580.4478 - val_root_mean_squared_error: 705.1527\n",
      "Epoch 165/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 92.7329 - root_mean_squared_error: 198.1740 - val_loss: 581.3179 - val_root_mean_squared_error: 701.7551\n",
      "Epoch 166/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 84.8389 - root_mean_squared_error: 188.9819 - val_loss: 590.9294 - val_root_mean_squared_error: 713.6360\n",
      "Epoch 167/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 83.8704 - root_mean_squared_error: 183.5783 - val_loss: 550.2157 - val_root_mean_squared_error: 663.8795\n",
      "Epoch 168/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 88.4301 - root_mean_squared_error: 190.3256 - val_loss: 656.5961 - val_root_mean_squared_error: 786.7390\n",
      "Epoch 169/400\n",
      "163/163 [==============================] - 0s 304us/sample - loss: 94.1965 - root_mean_squared_error: 184.9397 - val_loss: 510.9270 - val_root_mean_squared_error: 619.7482\n",
      "Epoch 170/400\n",
      "163/163 [==============================] - 0s 259us/sample - loss: 95.9872 - root_mean_squared_error: 195.3696 - val_loss: 649.0846 - val_root_mean_squared_error: 789.0922\n",
      "Epoch 171/400\n",
      "163/163 [==============================] - 0s 259us/sample - loss: 90.4911 - root_mean_squared_error: 186.1229 - val_loss: 586.5407 - val_root_mean_squared_error: 719.6049\n",
      "Epoch 172/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 97.0009 - root_mean_squared_error: 188.1369 - val_loss: 544.1696 - val_root_mean_squared_error: 660.7664\n",
      "Epoch 173/400\n",
      "163/163 [==============================] - 0s 218us/sample - loss: 87.7237 - root_mean_squared_error: 180.0307 - val_loss: 656.6122 - val_root_mean_squared_error: 786.6282\n",
      "Epoch 174/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 89.2425 - root_mean_squared_error: 181.0330 - val_loss: 590.5931 - val_root_mean_squared_error: 708.6223\n",
      "Epoch 175/400\n",
      "163/163 [==============================] - 0s 262us/sample - loss: 86.6215 - root_mean_squared_error: 174.1762 - val_loss: 618.4870 - val_root_mean_squared_error: 744.5518\n",
      "Epoch 176/400\n",
      "163/163 [==============================] - 0s 273us/sample - loss: 81.9490 - root_mean_squared_error: 177.9114 - val_loss: 612.8112 - val_root_mean_squared_error: 743.8583\n",
      "Epoch 177/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 85.8637 - root_mean_squared_error: 177.3810 - val_loss: 536.8776 - val_root_mean_squared_error: 651.7704\n",
      "Epoch 178/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 90.9904 - root_mean_squared_error: 187.8907 - val_loss: 599.3836 - val_root_mean_squared_error: 717.3135\n",
      "Epoch 179/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 92.9533 - root_mean_squared_error: 191.6230 - val_loss: 618.3774 - val_root_mean_squared_error: 738.0183\n",
      "Epoch 180/400\n",
      "163/163 [==============================] - 0s 251us/sample - loss: 89.4757 - root_mean_squared_error: 185.3789 - val_loss: 571.3094 - val_root_mean_squared_error: 694.6849\n",
      "Epoch 181/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 82.2080 - root_mean_squared_error: 181.2005 - val_loss: 561.5577 - val_root_mean_squared_error: 688.5735\n",
      "Epoch 182/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 87.4316 - root_mean_squared_error: 188.3635 - val_loss: 550.8204 - val_root_mean_squared_error: 676.0533\n",
      "Epoch 183/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 96.9679 - root_mean_squared_error: 198.0255 - val_loss: 625.0789 - val_root_mean_squared_error: 749.6695\n",
      "Epoch 184/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 87.9928 - root_mean_squared_error: 182.2299 - val_loss: 527.7035 - val_root_mean_squared_error: 627.2419\n",
      "Epoch 185/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 95.7837 - root_mean_squared_error: 195.3618 - val_loss: 682.5144 - val_root_mean_squared_error: 811.5078\n",
      "Epoch 186/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 95.7943 - root_mean_squared_error: 187.0578 - val_loss: 557.5215 - val_root_mean_squared_error: 667.8993\n",
      "Epoch 187/400\n",
      "163/163 [==============================] - 0s 227us/sample - loss: 102.1722 - root_mean_squared_error: 184.2291 - val_loss: 510.6447 - val_root_mean_squared_error: 614.2430\n",
      "Epoch 188/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 167.0408 - root_mean_squared_error: 259.6650 - val_loss: 496.7076 - val_root_mean_squared_error: 595.3143\n",
      "Epoch 189/400\n",
      "163/163 [==============================] - 0s 244us/sample - loss: 111.4596 - root_mean_squared_error: 201.5309 - val_loss: 627.5961 - val_root_mean_squared_error: 753.1244\n",
      "Epoch 190/400\n",
      "163/163 [==============================] - 0s 251us/sample - loss: 94.7365 - root_mean_squared_error: 194.2801 - val_loss: 597.1322 - val_root_mean_squared_error: 724.1663\n",
      "Epoch 191/400\n",
      "163/163 [==============================] - 0s 221us/sample - loss: 98.4556 - root_mean_squared_error: 190.4399 - val_loss: 530.8143 - val_root_mean_squared_error: 651.8385\n",
      "Epoch 192/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 104.9680 - root_mean_squared_error: 201.9997 - val_loss: 615.8459 - val_root_mean_squared_error: 752.5286\n",
      "Epoch 193/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 84.6004 - root_mean_squared_error: 183.5163 - val_loss: 593.5909 - val_root_mean_squared_error: 725.0550\n",
      "Epoch 194/400\n",
      "163/163 [==============================] - 0s 324us/sample - loss: 81.5850 - root_mean_squared_error: 182.4646 - val_loss: 676.9814 - val_root_mean_squared_error: 822.5297\n",
      "Epoch 195/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 116.3363 - root_mean_squared_error: 202.3200 - val_loss: 500.6158 - val_root_mean_squared_error: 621.0848\n",
      "Epoch 196/400\n",
      "163/163 [==============================] - 0s 302us/sample - loss: 106.1005 - root_mean_squared_error: 200.7269 - val_loss: 626.9416 - val_root_mean_squared_error: 768.9055\n",
      "Epoch 197/400\n",
      "163/163 [==============================] - 0s 266us/sample - loss: 87.5569 - root_mean_squared_error: 185.3254 - val_loss: 575.8479 - val_root_mean_squared_error: 701.8461\n",
      "Epoch 198/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 94.6638 - root_mean_squared_error: 184.0329 - val_loss: 608.3534 - val_root_mean_squared_error: 735.9354\n",
      "Epoch 199/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 83.3249 - root_mean_squared_error: 174.5838 - val_loss: 562.2031 - val_root_mean_squared_error: 680.0952\n",
      "Epoch 200/400\n",
      "163/163 [==============================] - 0s 267us/sample - loss: 86.4603 - root_mean_squared_error: 178.0057 - val_loss: 616.1922 - val_root_mean_squared_error: 752.4775\n",
      "Epoch 201/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 84.5334 - root_mean_squared_error: 184.4514 - val_loss: 588.5673 - val_root_mean_squared_error: 728.6750\n",
      "Epoch 202/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 84.2019 - root_mean_squared_error: 180.7090 - val_loss: 545.4417 - val_root_mean_squared_error: 675.6868\n",
      "Epoch 203/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 92.1795 - root_mean_squared_error: 189.2400 - val_loss: 611.1941 - val_root_mean_squared_error: 739.4281\n",
      "Epoch 204/400\n",
      "163/163 [==============================] - 0s 253us/sample - loss: 81.2413 - root_mean_squared_error: 176.4039 - val_loss: 609.6054 - val_root_mean_squared_error: 730.5248\n",
      "Epoch 205/400\n",
      "163/163 [==============================] - 0s 433us/sample - loss: 87.1173 - root_mean_squared_error: 175.9929 - val_loss: 599.7345 - val_root_mean_squared_error: 721.6154\n",
      "Epoch 206/400\n",
      "163/163 [==============================] - 0s 293us/sample - loss: 88.3605 - root_mean_squared_error: 176.8345 - val_loss: 568.6675 - val_root_mean_squared_error: 687.3753\n",
      "Epoch 207/400\n",
      "163/163 [==============================] - 0s 265us/sample - loss: 83.2169 - root_mean_squared_error: 184.0483 - val_loss: 637.9425 - val_root_mean_squared_error: 770.1154\n",
      "Epoch 208/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 81.5849 - root_mean_squared_error: 174.8450 - val_loss: 544.0362 - val_root_mean_squared_error: 662.4589\n",
      "Epoch 209/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 88.7970 - root_mean_squared_error: 179.7342 - val_loss: 616.6134 - val_root_mean_squared_error: 753.4171\n",
      "Epoch 210/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 83.8277 - root_mean_squared_error: 180.9730 - val_loss: 578.4857 - val_root_mean_squared_error: 715.3697\n",
      "Epoch 211/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 81.6966 - root_mean_squared_error: 177.3010 - val_loss: 555.6659 - val_root_mean_squared_error: 683.0687\n",
      "Epoch 212/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 104.9881 - root_mean_squared_error: 200.4528 - val_loss: 637.8572 - val_root_mean_squared_error: 764.1295\n",
      "Epoch 213/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 93.8207 - root_mean_squared_error: 179.7061 - val_loss: 550.0212 - val_root_mean_squared_error: 657.6047\n",
      "Epoch 214/400\n",
      "163/163 [==============================] - 0s 220us/sample - loss: 90.4907 - root_mean_squared_error: 182.7112 - val_loss: 624.6956 - val_root_mean_squared_error: 745.7599\n",
      "Epoch 215/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 86.2779 - root_mean_squared_error: 183.0736 - val_loss: 585.7545 - val_root_mean_squared_error: 709.7351\n",
      "Epoch 216/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 82.8341 - root_mean_squared_error: 179.4073 - val_loss: 557.4462 - val_root_mean_squared_error: 688.9032\n",
      "Epoch 217/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 85.6706 - root_mean_squared_error: 184.1300 - val_loss: 715.4623 - val_root_mean_squared_error: 879.6644\n",
      "Epoch 218/400\n",
      "163/163 [==============================] - 0s 285us/sample - loss: 120.8712 - root_mean_squared_error: 207.4149 - val_loss: 476.6454 - val_root_mean_squared_error: 592.8758\n",
      "Epoch 219/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 111.5562 - root_mean_squared_error: 203.3044 - val_loss: 662.4521 - val_root_mean_squared_error: 799.7842\n",
      "Epoch 220/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 88.5597 - root_mean_squared_error: 176.6867 - val_loss: 596.0535 - val_root_mean_squared_error: 721.6266\n",
      "Epoch 221/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 91.2555 - root_mean_squared_error: 177.7829 - val_loss: 569.1921 - val_root_mean_squared_error: 695.5029\n",
      "Epoch 222/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 83.9201 - root_mean_squared_error: 176.4951 - val_loss: 577.5240 - val_root_mean_squared_error: 704.0322\n",
      "Epoch 223/400\n",
      "163/163 [==============================] - 0s 248us/sample - loss: 84.3377 - root_mean_squared_error: 179.8247 - val_loss: 671.2552 - val_root_mean_squared_error: 817.5110\n",
      "Epoch 224/400\n",
      "163/163 [==============================] - 0s 256us/sample - loss: 95.7540 - root_mean_squared_error: 181.8161 - val_loss: 543.2024 - val_root_mean_squared_error: 666.3845\n",
      "Epoch 225/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 85.3269 - root_mean_squared_error: 180.3681 - val_loss: 655.8116 - val_root_mean_squared_error: 801.2964\n",
      "Epoch 226/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 90.1060 - root_mean_squared_error: 185.9616 - val_loss: 554.7271 - val_root_mean_squared_error: 680.8223\n",
      "Epoch 227/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 87.2288 - root_mean_squared_error: 181.9560 - val_loss: 582.2577 - val_root_mean_squared_error: 717.7253\n",
      "Epoch 228/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 79.3722 - root_mean_squared_error: 178.4311 - val_loss: 660.5674 - val_root_mean_squared_error: 809.2119\n",
      "Epoch 229/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 89.7903 - root_mean_squared_error: 179.2421 - val_loss: 503.0397 - val_root_mean_squared_error: 614.1925\n",
      "Epoch 230/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 107.6169 - root_mean_squared_error: 198.4423 - val_loss: 717.4900 - val_root_mean_squared_error: 862.9224\n",
      "Epoch 231/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 110.6059 - root_mean_squared_error: 188.7016 - val_loss: 494.3990 - val_root_mean_squared_error: 604.3474\n",
      "Epoch 232/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 95.8424 - root_mean_squared_error: 192.7874 - val_loss: 632.2889 - val_root_mean_squared_error: 775.3470\n",
      "Epoch 233/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 76.7374 - root_mean_squared_error: 169.5977 - val_loss: 613.7873 - val_root_mean_squared_error: 756.6043\n",
      "Epoch 234/400\n",
      "163/163 [==============================] - 0s 221us/sample - loss: 79.9764 - root_mean_squared_error: 172.9006 - val_loss: 571.1265 - val_root_mean_squared_error: 706.1967\n",
      "Epoch 235/400\n",
      "163/163 [==============================] - 0s 223us/sample - loss: 82.6258 - root_mean_squared_error: 180.4751 - val_loss: 643.3016 - val_root_mean_squared_error: 788.4525\n",
      "Epoch 236/400\n",
      "163/163 [==============================] - 0s 219us/sample - loss: 79.9252 - root_mean_squared_error: 176.1311 - val_loss: 532.9172 - val_root_mean_squared_error: 653.2505\n",
      "Epoch 237/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 88.8527 - root_mean_squared_error: 183.2383 - val_loss: 688.6773 - val_root_mean_squared_error: 836.5134\n",
      "Epoch 238/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 86.6972 - root_mean_squared_error: 167.8801 - val_loss: 526.2176 - val_root_mean_squared_error: 647.3118\n",
      "Epoch 239/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 87.1996 - root_mean_squared_error: 180.7943 - val_loss: 669.9830 - val_root_mean_squared_error: 823.2627\n",
      "Epoch 240/400\n",
      "163/163 [==============================] - 0s 317us/sample - loss: 88.3743 - root_mean_squared_error: 177.3385 - val_loss: 616.5851 - val_root_mean_squared_error: 765.6290\n",
      "Epoch 241/400\n",
      "163/163 [==============================] - 0s 247us/sample - loss: 103.1645 - root_mean_squared_error: 187.9282 - val_loss: 535.5196 - val_root_mean_squared_error: 665.0615\n",
      "Epoch 242/400\n",
      "163/163 [==============================] - 0s 370us/sample - loss: 91.0756 - root_mean_squared_error: 188.2648 - val_loss: 677.8884 - val_root_mean_squared_error: 823.0294\n",
      "Epoch 243/400\n",
      "163/163 [==============================] - 0s 265us/sample - loss: 88.4417 - root_mean_squared_error: 179.1707 - val_loss: 550.1878 - val_root_mean_squared_error: 666.3049\n",
      "Epoch 244/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 83.9633 - root_mean_squared_error: 172.6623 - val_loss: 626.7394 - val_root_mean_squared_error: 760.4216\n",
      "Epoch 245/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 77.0499 - root_mean_squared_error: 170.8085 - val_loss: 570.2533 - val_root_mean_squared_error: 700.5820\n",
      "Epoch 246/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 81.0826 - root_mean_squared_error: 176.4908 - val_loss: 641.7442 - val_root_mean_squared_error: 789.3514\n",
      "Epoch 247/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 82.1302 - root_mean_squared_error: 175.6492 - val_loss: 623.4330 - val_root_mean_squared_error: 769.7274\n",
      "Epoch 248/400\n",
      "163/163 [==============================] - 0s 221us/sample - loss: 95.8987 - root_mean_squared_error: 183.6201 - val_loss: 558.9733 - val_root_mean_squared_error: 696.8891\n",
      "Epoch 249/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 87.4489 - root_mean_squared_error: 181.9009 - val_loss: 679.2449 - val_root_mean_squared_error: 831.9550\n",
      "Epoch 250/400\n",
      "163/163 [==============================] - 0s 260us/sample - loss: 92.2149 - root_mean_squared_error: 180.7057 - val_loss: 530.3558 - val_root_mean_squared_error: 644.5126\n",
      "Epoch 251/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 86.8813 - root_mean_squared_error: 181.6516 - val_loss: 646.9758 - val_root_mean_squared_error: 784.8547\n",
      "Epoch 252/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 77.2676 - root_mean_squared_error: 172.9955 - val_loss: 564.1782 - val_root_mean_squared_error: 691.7397\n",
      "Epoch 253/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 80.4230 - root_mean_squared_error: 174.3716 - val_loss: 608.3944 - val_root_mean_squared_error: 746.4241\n",
      "Epoch 254/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 77.8468 - root_mean_squared_error: 173.7371 - val_loss: 612.8671 - val_root_mean_squared_error: 741.1046\n",
      "Epoch 255/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 77.3685 - root_mean_squared_error: 172.3174 - val_loss: 579.0146 - val_root_mean_squared_error: 696.7883\n",
      "Epoch 256/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 76.3293 - root_mean_squared_error: 172.2428 - val_loss: 605.3925 - val_root_mean_squared_error: 733.4290\n",
      "Epoch 257/400\n",
      "163/163 [==============================] - 0s 227us/sample - loss: 79.2236 - root_mean_squared_error: 175.8351 - val_loss: 634.2703 - val_root_mean_squared_error: 771.8219\n",
      "Epoch 258/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 77.5139 - root_mean_squared_error: 171.9508 - val_loss: 613.7046 - val_root_mean_squared_error: 747.8423\n",
      "Epoch 259/400\n",
      "163/163 [==============================] - 0s 282us/sample - loss: 76.2374 - root_mean_squared_error: 169.8049 - val_loss: 584.9526 - val_root_mean_squared_error: 712.5276\n",
      "Epoch 260/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 79.0362 - root_mean_squared_error: 174.8380 - val_loss: 620.1543 - val_root_mean_squared_error: 756.2623\n",
      "Epoch 261/400\n",
      "163/163 [==============================] - 0s 257us/sample - loss: 84.2998 - root_mean_squared_error: 175.2169 - val_loss: 565.5238 - val_root_mean_squared_error: 693.9214\n",
      "Epoch 262/400\n",
      "163/163 [==============================] - 0s 248us/sample - loss: 79.1967 - root_mean_squared_error: 176.0171 - val_loss: 568.8617 - val_root_mean_squared_error: 700.6201\n",
      "Epoch 263/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 81.5092 - root_mean_squared_error: 177.1967 - val_loss: 630.1936 - val_root_mean_squared_error: 765.5413\n",
      "Epoch 264/400\n",
      "163/163 [==============================] - 0s 271us/sample - loss: 78.9327 - root_mean_squared_error: 173.2052 - val_loss: 573.0194 - val_root_mean_squared_error: 697.8026\n",
      "Epoch 265/400\n",
      "163/163 [==============================] - 0s 283us/sample - loss: 79.5359 - root_mean_squared_error: 178.0231 - val_loss: 608.3372 - val_root_mean_squared_error: 741.9431\n",
      "Epoch 266/400\n",
      "163/163 [==============================] - 0s 310us/sample - loss: 77.9576 - root_mean_squared_error: 174.1990 - val_loss: 596.2989 - val_root_mean_squared_error: 720.3682\n",
      "Epoch 267/400\n",
      "163/163 [==============================] - 0s 244us/sample - loss: 79.8951 - root_mean_squared_error: 172.8194 - val_loss: 546.0815 - val_root_mean_squared_error: 662.4927\n",
      "Epoch 268/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 84.9640 - root_mean_squared_error: 187.7857 - val_loss: 679.8601 - val_root_mean_squared_error: 838.7634\n",
      "Epoch 269/400\n",
      "163/163 [==============================] - 0s 233us/sample - loss: 113.7699 - root_mean_squared_error: 203.4761 - val_loss: 510.1068 - val_root_mean_squared_error: 638.8543\n",
      "Epoch 270/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 88.9047 - root_mean_squared_error: 189.7216 - val_loss: 630.6384 - val_root_mean_squared_error: 779.6616\n",
      "Epoch 271/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 88.8651 - root_mean_squared_error: 187.3951 - val_loss: 632.1672 - val_root_mean_squared_error: 776.1179\n",
      "Epoch 272/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 88.4562 - root_mean_squared_error: 177.6162 - val_loss: 543.9883 - val_root_mean_squared_error: 666.5378\n",
      "Epoch 273/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 87.2248 - root_mean_squared_error: 180.8609 - val_loss: 617.2633 - val_root_mean_squared_error: 752.7956\n",
      "Epoch 274/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 77.9253 - root_mean_squared_error: 172.9265 - val_loss: 651.1756 - val_root_mean_squared_error: 789.1666\n",
      "Epoch 275/400\n",
      "163/163 [==============================] - 0s 367us/sample - loss: 81.9234 - root_mean_squared_error: 174.2974 - val_loss: 552.9143 - val_root_mean_squared_error: 675.3488\n",
      "Epoch 276/400\n",
      "163/163 [==============================] - 0s 278us/sample - loss: 88.2071 - root_mean_squared_error: 177.4755 - val_loss: 669.7148 - val_root_mean_squared_error: 819.3963\n",
      "Epoch 277/400\n",
      "163/163 [==============================] - 0s 276us/sample - loss: 85.4623 - root_mean_squared_error: 180.5638 - val_loss: 559.7069 - val_root_mean_squared_error: 688.9031\n",
      "Epoch 278/400\n",
      "163/163 [==============================] - 0s 319us/sample - loss: 84.2282 - root_mean_squared_error: 172.4216 - val_loss: 589.8551 - val_root_mean_squared_error: 719.8683\n",
      "Epoch 279/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 91.0398 - root_mean_squared_error: 184.3185 - val_loss: 625.9009 - val_root_mean_squared_error: 761.1256\n",
      "Epoch 280/400\n",
      "163/163 [==============================] - 0s 267us/sample - loss: 75.7130 - root_mean_squared_error: 169.8654 - val_loss: 544.6337 - val_root_mean_squared_error: 667.6354\n",
      "Epoch 281/400\n",
      "163/163 [==============================] - 0s 250us/sample - loss: 94.4324 - root_mean_squared_error: 185.0071 - val_loss: 653.5675 - val_root_mean_squared_error: 799.9183\n",
      "Epoch 282/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 81.3355 - root_mean_squared_error: 172.9871 - val_loss: 551.9666 - val_root_mean_squared_error: 678.8820\n",
      "Epoch 283/400\n",
      "163/163 [==============================] - 0s 244us/sample - loss: 78.8608 - root_mean_squared_error: 173.2270 - val_loss: 581.1403 - val_root_mean_squared_error: 709.5563\n",
      "Epoch 284/400\n",
      "163/163 [==============================] - 0s 258us/sample - loss: 80.7774 - root_mean_squared_error: 176.9368 - val_loss: 652.7224 - val_root_mean_squared_error: 794.0309\n",
      "Epoch 285/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 89.0744 - root_mean_squared_error: 170.7389 - val_loss: 561.3167 - val_root_mean_squared_error: 692.8060\n",
      "Epoch 286/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 76.6619 - root_mean_squared_error: 174.9524 - val_loss: 603.2575 - val_root_mean_squared_error: 751.7781\n",
      "Epoch 287/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 79.8460 - root_mean_squared_error: 176.4305 - val_loss: 667.3255 - val_root_mean_squared_error: 830.7788\n",
      "Epoch 288/400\n",
      "163/163 [==============================] - 0s 266us/sample - loss: 89.5101 - root_mean_squared_error: 179.7308 - val_loss: 559.6946 - val_root_mean_squared_error: 695.5705\n",
      "Epoch 289/400\n",
      "163/163 [==============================] - 0s 249us/sample - loss: 81.9724 - root_mean_squared_error: 179.5103 - val_loss: 624.5797 - val_root_mean_squared_error: 770.7115\n",
      "Epoch 290/400\n",
      "163/163 [==============================] - 0s 224us/sample - loss: 77.5583 - root_mean_squared_error: 171.5791 - val_loss: 641.3412 - val_root_mean_squared_error: 787.9087\n",
      "Epoch 291/400\n",
      "163/163 [==============================] - 0s 221us/sample - loss: 75.2298 - root_mean_squared_error: 169.5549 - val_loss: 583.0472 - val_root_mean_squared_error: 712.1572\n",
      "Epoch 292/400\n",
      "163/163 [==============================] - 0s 221us/sample - loss: 76.4948 - root_mean_squared_error: 172.3025 - val_loss: 598.1397 - val_root_mean_squared_error: 728.6664\n",
      "Epoch 293/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 83.3140 - root_mean_squared_error: 174.9940 - val_loss: 657.3217 - val_root_mean_squared_error: 799.1876\n",
      "Epoch 294/400\n",
      "163/163 [==============================] - 0s 341us/sample - loss: 89.6369 - root_mean_squared_error: 173.4056 - val_loss: 562.1931 - val_root_mean_squared_error: 690.6799\n",
      "Epoch 295/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 86.1005 - root_mean_squared_error: 179.7276 - val_loss: 602.0549 - val_root_mean_squared_error: 750.3571\n",
      "Epoch 296/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 77.0871 - root_mean_squared_error: 176.3640 - val_loss: 645.5280 - val_root_mean_squared_error: 805.2991\n",
      "Epoch 297/400\n",
      "163/163 [==============================] - 0s 256us/sample - loss: 85.8134 - root_mean_squared_error: 182.1996 - val_loss: 569.1522 - val_root_mean_squared_error: 705.2440\n",
      "Epoch 298/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 76.2504 - root_mean_squared_error: 174.5303 - val_loss: 628.9023 - val_root_mean_squared_error: 770.6213\n",
      "Epoch 299/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 76.3296 - root_mean_squared_error: 172.9566 - val_loss: 591.0982 - val_root_mean_squared_error: 722.8492\n",
      "Epoch 300/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 74.5564 - root_mean_squared_error: 169.4154 - val_loss: 607.8723 - val_root_mean_squared_error: 744.7822\n",
      "Epoch 301/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 75.6153 - root_mean_squared_error: 170.6182 - val_loss: 572.2242 - val_root_mean_squared_error: 702.6342\n",
      "Epoch 302/400\n",
      "163/163 [==============================] - 0s 268us/sample - loss: 77.5121 - root_mean_squared_error: 173.3570 - val_loss: 630.9876 - val_root_mean_squared_error: 774.0490\n",
      "Epoch 303/400\n",
      "163/163 [==============================] - 0s 259us/sample - loss: 78.9527 - root_mean_squared_error: 172.5804 - val_loss: 600.2087 - val_root_mean_squared_error: 735.7532\n",
      "Epoch 304/400\n",
      "163/163 [==============================] - 0s 216us/sample - loss: 77.5362 - root_mean_squared_error: 172.5143 - val_loss: 606.6029 - val_root_mean_squared_error: 743.4904\n",
      "Epoch 305/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 72.8731 - root_mean_squared_error: 170.6239 - val_loss: 581.0818 - val_root_mean_squared_error: 721.6954\n",
      "Epoch 306/400\n",
      "163/163 [==============================] - 0s 253us/sample - loss: 73.7636 - root_mean_squared_error: 175.0082 - val_loss: 615.8957 - val_root_mean_squared_error: 760.0768\n",
      "Epoch 307/400\n",
      "163/163 [==============================] - 0s 291us/sample - loss: 75.8782 - root_mean_squared_error: 169.3840 - val_loss: 549.6261 - val_root_mean_squared_error: 670.7840\n",
      "Epoch 308/400\n",
      "163/163 [==============================] - 0s 320us/sample - loss: 85.6680 - root_mean_squared_error: 180.4714 - val_loss: 648.5445 - val_root_mean_squared_error: 786.4781\n",
      "Epoch 309/400\n",
      "163/163 [==============================] - 0s 323us/sample - loss: 76.8811 - root_mean_squared_error: 170.2742 - val_loss: 650.9560 - val_root_mean_squared_error: 785.6352\n",
      "Epoch 310/400\n",
      "163/163 [==============================] - 0s 266us/sample - loss: 83.9423 - root_mean_squared_error: 167.9622 - val_loss: 546.2736 - val_root_mean_squared_error: 667.0369\n",
      "Epoch 311/400\n",
      "163/163 [==============================] - 0s 301us/sample - loss: 86.6982 - root_mean_squared_error: 182.0901 - val_loss: 681.3435 - val_root_mean_squared_error: 828.2538\n",
      "Epoch 312/400\n",
      "163/163 [==============================] - 0s 280us/sample - loss: 83.7776 - root_mean_squared_error: 170.3754 - val_loss: 551.5912 - val_root_mean_squared_error: 682.3802\n",
      "Epoch 313/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 82.7399 - root_mean_squared_error: 172.8061 - val_loss: 587.5187 - val_root_mean_squared_error: 724.8622\n",
      "Epoch 314/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 90.2652 - root_mean_squared_error: 185.7578 - val_loss: 628.5006 - val_root_mean_squared_error: 769.6119\n",
      "Epoch 315/400\n",
      "163/163 [==============================] - 0s 223us/sample - loss: 78.3960 - root_mean_squared_error: 171.4489 - val_loss: 561.4274 - val_root_mean_squared_error: 681.4485\n",
      "Epoch 316/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 89.3114 - root_mean_squared_error: 180.9793 - val_loss: 649.7806 - val_root_mean_squared_error: 779.2523\n",
      "Epoch 317/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 79.4719 - root_mean_squared_error: 168.2455 - val_loss: 543.6081 - val_root_mean_squared_error: 656.2179\n",
      "Epoch 318/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 84.0156 - root_mean_squared_error: 177.4407 - val_loss: 652.6297 - val_root_mean_squared_error: 793.2966\n",
      "Epoch 319/400\n",
      "163/163 [==============================] - 0s 248us/sample - loss: 81.2584 - root_mean_squared_error: 184.5621 - val_loss: 566.7338 - val_root_mean_squared_error: 705.3901\n",
      "Epoch 320/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 77.1884 - root_mean_squared_error: 182.4500 - val_loss: 596.1280 - val_root_mean_squared_error: 743.9711\n",
      "Epoch 321/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 76.2015 - root_mean_squared_error: 182.2861 - val_loss: 607.1635 - val_root_mean_squared_error: 758.8414\n",
      "Epoch 322/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 77.9273 - root_mean_squared_error: 181.9754 - val_loss: 655.0249 - val_root_mean_squared_error: 807.8029\n",
      "Epoch 323/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 86.7843 - root_mean_squared_error: 180.9618 - val_loss: 564.6638 - val_root_mean_squared_error: 679.9666\n",
      "Epoch 324/400\n",
      "163/163 [==============================] - 0s 258us/sample - loss: 79.1196 - root_mean_squared_error: 169.9900 - val_loss: 647.8876 - val_root_mean_squared_error: 770.1591\n",
      "Epoch 325/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 82.4384 - root_mean_squared_error: 166.8550 - val_loss: 620.6416 - val_root_mean_squared_error: 737.8977\n",
      "Epoch 326/400\n",
      "163/163 [==============================] - 0s 246us/sample - loss: 78.0821 - root_mean_squared_error: 168.4504 - val_loss: 665.2333 - val_root_mean_squared_error: 805.7917\n",
      "Epoch 327/400\n",
      "163/163 [==============================] - 0s 321us/sample - loss: 95.9946 - root_mean_squared_error: 177.1842 - val_loss: 557.8367 - val_root_mean_squared_error: 689.6128\n",
      "Epoch 328/400\n",
      "163/163 [==============================] - 0s 243us/sample - loss: 80.8883 - root_mean_squared_error: 176.9761 - val_loss: 612.6985 - val_root_mean_squared_error: 750.5860\n",
      "Epoch 329/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 78.4886 - root_mean_squared_error: 172.9836 - val_loss: 595.4944 - val_root_mean_squared_error: 721.8469\n",
      "Epoch 330/400\n",
      "163/163 [==============================] - 0s 249us/sample - loss: 72.7186 - root_mean_squared_error: 169.9562 - val_loss: 600.6873 - val_root_mean_squared_error: 727.4068\n",
      "Epoch 331/400\n",
      "163/163 [==============================] - 0s 237us/sample - loss: 71.4267 - root_mean_squared_error: 169.4712 - val_loss: 643.5207 - val_root_mean_squared_error: 787.2822\n",
      "Epoch 332/400\n",
      "163/163 [==============================] - 0s 252us/sample - loss: 85.0041 - root_mean_squared_error: 174.2660 - val_loss: 560.6476 - val_root_mean_squared_error: 695.4761\n",
      "Epoch 333/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 79.5362 - root_mean_squared_error: 174.6240 - val_loss: 598.6283 - val_root_mean_squared_error: 734.9640\n",
      "Epoch 334/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 72.5327 - root_mean_squared_error: 172.0617 - val_loss: 638.4075 - val_root_mean_squared_error: 778.2424\n",
      "Epoch 335/400\n",
      "163/163 [==============================] - 0s 219us/sample - loss: 77.3095 - root_mean_squared_error: 173.3622 - val_loss: 608.6154 - val_root_mean_squared_error: 752.2812\n",
      "Epoch 336/400\n",
      "163/163 [==============================] - 0s 407us/sample - loss: 80.2105 - root_mean_squared_error: 173.6158 - val_loss: 587.7069 - val_root_mean_squared_error: 729.4245\n",
      "Epoch 337/400\n",
      "163/163 [==============================] - ETA: 0s - loss: 68.5537 - root_mean_squared_error: 123.33 - 0s 286us/sample - loss: 86.0268 - root_mean_squared_error: 177.6481 - val_loss: 586.7262 - val_root_mean_squared_error: 725.0522\n",
      "Epoch 338/400\n",
      "163/163 [==============================] - 0s 260us/sample - loss: 75.0405 - root_mean_squared_error: 168.4990 - val_loss: 664.6509 - val_root_mean_squared_error: 809.5477\n",
      "Epoch 339/400\n",
      "163/163 [==============================] - 0s 260us/sample - loss: 81.1862 - root_mean_squared_error: 166.5397 - val_loss: 583.6155 - val_root_mean_squared_error: 712.5379\n",
      "Epoch 340/400\n",
      "163/163 [==============================] - 0s 253us/sample - loss: 79.1495 - root_mean_squared_error: 170.3186 - val_loss: 651.3808 - val_root_mean_squared_error: 798.2683\n",
      "Epoch 341/400\n",
      "163/163 [==============================] - 0s 247us/sample - loss: 74.8577 - root_mean_squared_error: 164.4746 - val_loss: 630.1042 - val_root_mean_squared_error: 771.7966\n",
      "Epoch 342/400\n",
      "163/163 [==============================] - 0s 300us/sample - loss: 73.9940 - root_mean_squared_error: 166.4730 - val_loss: 593.6284 - val_root_mean_squared_error: 722.9034\n",
      "Epoch 343/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 72.4999 - root_mean_squared_error: 168.3358 - val_loss: 604.7548 - val_root_mean_squared_error: 732.7363\n",
      "Epoch 344/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 74.0588 - root_mean_squared_error: 171.1275 - val_loss: 606.8595 - val_root_mean_squared_error: 739.0900\n",
      "Epoch 345/400\n",
      "163/163 [==============================] - 0s 249us/sample - loss: 72.7590 - root_mean_squared_error: 170.1943 - val_loss: 593.6471 - val_root_mean_squared_error: 724.2473\n",
      "Epoch 346/400\n",
      "163/163 [==============================] - 0s 230us/sample - loss: 73.8595 - root_mean_squared_error: 170.2852 - val_loss: 591.2724 - val_root_mean_squared_error: 725.7673\n",
      "Epoch 347/400\n",
      "163/163 [==============================] - 0s 256us/sample - loss: 70.7238 - root_mean_squared_error: 170.4596 - val_loss: 558.9924 - val_root_mean_squared_error: 683.7581\n",
      "Epoch 348/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 82.7706 - root_mean_squared_error: 180.3222 - val_loss: 702.9219 - val_root_mean_squared_error: 849.7589\n",
      "Epoch 349/400\n",
      "163/163 [==============================] - 0s 228us/sample - loss: 101.5029 - root_mean_squared_error: 179.1395 - val_loss: 526.3846 - val_root_mean_squared_error: 637.6158\n",
      "Epoch 350/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 88.5632 - root_mean_squared_error: 178.9958 - val_loss: 646.1927 - val_root_mean_squared_error: 779.7618\n",
      "Epoch 351/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 85.7605 - root_mean_squared_error: 177.9587 - val_loss: 543.3947 - val_root_mean_squared_error: 658.8994\n",
      "Epoch 352/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 86.1342 - root_mean_squared_error: 183.1851 - val_loss: 658.5783 - val_root_mean_squared_error: 796.9247\n",
      "Epoch 353/400\n",
      "163/163 [==============================] - 0s 223us/sample - loss: 79.3519 - root_mean_squared_error: 169.0421 - val_loss: 574.5860 - val_root_mean_squared_error: 702.1929\n",
      "Epoch 354/400\n",
      "163/163 [==============================] - 0s 227us/sample - loss: 87.6385 - root_mean_squared_error: 179.9610 - val_loss: 582.9199 - val_root_mean_squared_error: 716.3658\n",
      "Epoch 355/400\n",
      "163/163 [==============================] - 0s 238us/sample - loss: 86.4175 - root_mean_squared_error: 180.2021 - val_loss: 649.9752 - val_root_mean_squared_error: 792.5668\n",
      "Epoch 356/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 81.7386 - root_mean_squared_error: 172.1978 - val_loss: 583.7648 - val_root_mean_squared_error: 712.9598\n",
      "Epoch 357/400\n",
      "163/163 [==============================] - 0s 282us/sample - loss: 78.7567 - root_mean_squared_error: 172.4366 - val_loss: 586.3479 - val_root_mean_squared_error: 714.5730\n",
      "Epoch 358/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 78.7726 - root_mean_squared_error: 175.7739 - val_loss: 640.2457 - val_root_mean_squared_error: 784.7430\n",
      "Epoch 359/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 76.3279 - root_mean_squared_error: 170.8680 - val_loss: 577.3199 - val_root_mean_squared_error: 710.8983\n",
      "Epoch 360/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 73.6347 - root_mean_squared_error: 171.8698 - val_loss: 580.2414 - val_root_mean_squared_error: 714.4965\n",
      "Epoch 361/400\n",
      "163/163 [==============================] - 0s 242us/sample - loss: 88.0405 - root_mean_squared_error: 186.5102 - val_loss: 666.8051 - val_root_mean_squared_error: 816.4916\n",
      "Epoch 362/400\n",
      "163/163 [==============================] - 0s 248us/sample - loss: 93.4942 - root_mean_squared_error: 180.2435 - val_loss: 538.4182 - val_root_mean_squared_error: 662.1367\n",
      "Epoch 363/400\n",
      "163/163 [==============================] - 0s 252us/sample - loss: 87.2095 - root_mean_squared_error: 181.3271 - val_loss: 614.2435 - val_root_mean_squared_error: 755.9660\n",
      "Epoch 364/400\n",
      "163/163 [==============================] - 0s 251us/sample - loss: 77.6338 - root_mean_squared_error: 173.7773 - val_loss: 653.7912 - val_root_mean_squared_error: 804.3670\n",
      "Epoch 365/400\n",
      "163/163 [==============================] - 0s 268us/sample - loss: 91.7920 - root_mean_squared_error: 181.0810 - val_loss: 539.6327 - val_root_mean_squared_error: 673.3895\n",
      "Epoch 366/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 87.8278 - root_mean_squared_error: 189.9216 - val_loss: 628.1935 - val_root_mean_squared_error: 783.4825\n",
      "Epoch 367/400\n",
      "163/163 [==============================] - 0s 376us/sample - loss: 81.1618 - root_mean_squared_error: 178.7673 - val_loss: 596.5656 - val_root_mean_squared_error: 738.5113\n",
      "Epoch 368/400\n",
      "163/163 [==============================] - 0s 387us/sample - loss: 76.4556 - root_mean_squared_error: 174.0550 - val_loss: 609.5289 - val_root_mean_squared_error: 744.5919\n",
      "Epoch 369/400\n",
      "163/163 [==============================] - 0s 253us/sample - loss: 71.6720 - root_mean_squared_error: 168.7493 - val_loss: 638.7727 - val_root_mean_squared_error: 779.6290\n",
      "Epoch 370/400\n",
      "163/163 [==============================] - 0s 281us/sample - loss: 74.0236 - root_mean_squared_error: 166.0447 - val_loss: 623.3779 - val_root_mean_squared_error: 768.4077\n",
      "Epoch 371/400\n",
      "163/163 [==============================] - 0s 269us/sample - loss: 86.7870 - root_mean_squared_error: 176.4109 - val_loss: 556.1335 - val_root_mean_squared_error: 694.9630\n",
      "Epoch 372/400\n",
      "163/163 [==============================] - 0s 286us/sample - loss: 83.1550 - root_mean_squared_error: 175.7701 - val_loss: 705.6630 - val_root_mean_squared_error: 874.5499\n",
      "Epoch 373/400\n",
      "163/163 [==============================] - 0s 236us/sample - loss: 101.9617 - root_mean_squared_error: 190.4291 - val_loss: 553.1298 - val_root_mean_squared_error: 694.6559\n",
      "Epoch 374/400\n",
      "163/163 [==============================] - 0s 225us/sample - loss: 89.2726 - root_mean_squared_error: 178.6577 - val_loss: 606.8967 - val_root_mean_squared_error: 759.6235\n",
      "Epoch 375/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 100.1805 - root_mean_squared_error: 188.3016 - val_loss: 602.3757 - val_root_mean_squared_error: 741.6110\n",
      "Epoch 376/400\n",
      "163/163 [==============================] - 0s 280us/sample - loss: 88.3740 - root_mean_squared_error: 174.9879 - val_loss: 590.2163 - val_root_mean_squared_error: 718.8903\n",
      "Epoch 377/400\n",
      "163/163 [==============================] - 0s 254us/sample - loss: 79.6368 - root_mean_squared_error: 173.6427 - val_loss: 593.7352 - val_root_mean_squared_error: 729.7268\n",
      "Epoch 378/400\n",
      "163/163 [==============================] - 0s 252us/sample - loss: 75.8130 - root_mean_squared_error: 172.3395 - val_loss: 577.3314 - val_root_mean_squared_error: 714.9136\n",
      "Epoch 379/400\n",
      "163/163 [==============================] - 0s 240us/sample - loss: 80.3609 - root_mean_squared_error: 177.1677 - val_loss: 593.2896 - val_root_mean_squared_error: 729.7384\n",
      "Epoch 380/400\n",
      "163/163 [==============================] - 0s 234us/sample - loss: 77.6358 - root_mean_squared_error: 178.0100 - val_loss: 657.9365 - val_root_mean_squared_error: 806.5273\n",
      "Epoch 381/400\n",
      "163/163 [==============================] - 0s 231us/sample - loss: 86.9354 - root_mean_squared_error: 177.4484 - val_loss: 588.1855 - val_root_mean_squared_error: 722.6364\n",
      "Epoch 382/400\n",
      "163/163 [==============================] - 0s 251us/sample - loss: 76.4815 - root_mean_squared_error: 172.2744 - val_loss: 551.4545 - val_root_mean_squared_error: 676.8707\n",
      "Epoch 383/400\n",
      "163/163 [==============================] - 0s 255us/sample - loss: 97.4900 - root_mean_squared_error: 190.0557 - val_loss: 685.3954 - val_root_mean_squared_error: 828.6662\n",
      "Epoch 384/400\n",
      "163/163 [==============================] - 0s 314us/sample - loss: 102.6438 - root_mean_squared_error: 181.5591 - val_loss: 539.3580 - val_root_mean_squared_error: 653.9796\n",
      "Epoch 385/400\n",
      "163/163 [==============================] - 0s 229us/sample - loss: 86.3810 - root_mean_squared_error: 174.3926 - val_loss: 672.8060 - val_root_mean_squared_error: 811.8277\n",
      "Epoch 386/400\n",
      "163/163 [==============================] - 0s 241us/sample - loss: 84.9201 - root_mean_squared_error: 167.2574 - val_loss: 599.2757 - val_root_mean_squared_error: 727.1892\n",
      "Epoch 387/400\n",
      "163/163 [==============================] - 0s 222us/sample - loss: 76.5674 - root_mean_squared_error: 160.0491 - val_loss: 655.5635 - val_root_mean_squared_error: 795.2396\n",
      "Epoch 388/400\n",
      "163/163 [==============================] - 0s 239us/sample - loss: 78.8892 - root_mean_squared_error: 163.7356 - val_loss: 578.0443 - val_root_mean_squared_error: 703.0593\n",
      "Epoch 389/400\n",
      "163/163 [==============================] - 0s 245us/sample - loss: 81.4480 - root_mean_squared_error: 170.0110 - val_loss: 662.7570 - val_root_mean_squared_error: 806.5975\n",
      "Epoch 390/400\n",
      "163/163 [==============================] - 0s 235us/sample - loss: 77.4373 - root_mean_squared_error: 168.3534 - val_loss: 609.1749 - val_root_mean_squared_error: 744.8942\n",
      "Epoch 391/400\n",
      "163/163 [==============================] - 0s 417us/sample - loss: 74.9071 - root_mean_squared_error: 167.3996 - val_loss: 553.3729 - val_root_mean_squared_error: 684.3527\n",
      "Epoch 392/400\n",
      "163/163 [==============================] - 0s 306us/sample - loss: 97.0094 - root_mean_squared_error: 186.3525 - val_loss: 676.9390 - val_root_mean_squared_error: 835.9924\n",
      "Epoch 393/400\n",
      "163/163 [==============================] - 0s 217us/sample - loss: 89.5300 - root_mean_squared_error: 176.8202 - val_loss: 581.1897 - val_root_mean_squared_error: 718.9116\n",
      "Epoch 394/400\n",
      "163/163 [==============================] - 0s 232us/sample - loss: 77.3015 - root_mean_squared_error: 172.1240 - val_loss: 582.1253 - val_root_mean_squared_error: 715.6028\n",
      "Epoch 395/400\n",
      "163/163 [==============================] - 0s 211us/sample - loss: 99.3827 - root_mean_squared_error: 193.9909 - val_loss: 640.1046 - val_root_mean_squared_error: 771.4018\n",
      "Epoch 396/400\n",
      "163/163 [==============================] - 0s 220us/sample - loss: 94.0032 - root_mean_squared_error: 177.8863 - val_loss: 529.7907 - val_root_mean_squared_error: 632.7399\n",
      "Epoch 397/400\n",
      "163/163 [==============================] - 0s 226us/sample - loss: 114.4124 - root_mean_squared_error: 206.7983 - val_loss: 675.0234 - val_root_mean_squared_error: 799.2343\n",
      "Epoch 398/400\n",
      "163/163 [==============================] - 0s 339us/sample - loss: 109.3954 - root_mean_squared_error: 177.6600 - val_loss: 560.7917 - val_root_mean_squared_error: 666.7786\n",
      "Epoch 399/400\n",
      "163/163 [==============================] - 0s 288us/sample - loss: 106.0344 - root_mean_squared_error: 191.2999 - val_loss: 636.1561 - val_root_mean_squared_error: 764.4822\n",
      "Epoch 400/400\n",
      "163/163 [==============================] - 0s 283us/sample - loss: 77.6479 - root_mean_squared_error: 165.5579 - val_loss: 586.4380 - val_root_mean_squared_error: 711.0703\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y[0], \n",
    "                   epochs=400, validation_data=(val_x,val_y[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "price_pred = predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(price_pred)), price_pred.flatten(), color='green')\n",
    "plt.scatter(range(len(price_pred)), test_y[0], color='red')\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Actual and Predicted \" + y_test.columns[0], fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse for first regressor: 31458.550499944333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101.4499339998685"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_one = mean_squared_error(test_y[0], predictions)\n",
    "print(f'mse for first regressor: {mse_one}')\n",
    "mae_one = mean_absolute_error(test_y[0], predictions)\n",
    "mae_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [52, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7c5cfb05d56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmse_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmse_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmse_three\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmse_four\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmse_five\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m    335\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 336\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [52, 1]"
     ]
    }
   ],
   "source": [
    "mse_one = mean_squared_error(test_y[0], predictions[0])\n",
    "mse_two = mean_squared_error(test_y[1], predictions[1])\n",
    "mse_three = mean_squared_error(test_y[2], predictions[2])\n",
    "mse_four = mean_squared_error(test_y[3], predictions[3])\n",
    "mse_five = mean_squared_error(test_y[4], predictions[4])\n",
    "mse_six = mean_squared_error(test_y[5], predictions[5])\n",
    "mse_seven = mean_squared_error(test_y[6], predictions[6])\n",
    "mse_eight = mean_squared_error(test_y[7], predictions[7])\n",
    "mse_nine = mean_squared_error(test_y[8], predictions[8])\n",
    "mse_ten = mean_squared_error(test_y[9], predictions[9])\n",
    "print(\"MSE FOR EVERY OUTPUT\")\n",
    "print(f'mse for first regressor: {mse_one} - second regressor: {mse_two}')\n",
    "print(f'mse for third regressor: {mse_three} - fourth regressor: {mse_four}')\n",
    "print(f'mse for fifth regressor: {mse_five} - sixth regressor: {mse_six}')\n",
    "print(f'mse for seventh regressor: {mse_seven} - eighth regressor: {mse_eight}')\n",
    "print(f'mse for nineth regressor: {mse_nine} - tenth regressor: {mse_ten}')\n",
    "mae_one = mean_absolute_error(test_y[0], predictions[0])\n",
    "mae_two = mean_absolute_error(test_y[1], predictions[1])\n",
    "mae_three = mean_absolute_error(test_y[2], predictions[2])\n",
    "mae_four = mean_absolute_error(test_y[3], predictions[3])\n",
    "mae_five = mean_absolute_error(test_y[4], predictions[4])\n",
    "mae_six = mean_absolute_error(test_y[5], predictions[5])\n",
    "mae_seven = mean_absolute_error(test_y[6], predictions[6])\n",
    "mae_eight = mean_absolute_error(test_y[7], predictions[7])\n",
    "mae_nine = mean_absolute_error(test_y[8], predictions[8])\n",
    "mae_ten = mean_absolute_error(test_y[9], predictions[9])\n",
    "print(\"MAE FOR EVERY OUTPUT\")\n",
    "print(f'mae for first regressor: {mae_one} - second regressor: {mae_two}')\n",
    "print(f'mae for third regressor: {mae_three} - fourth regressor: {mae_four}')\n",
    "print(f'mae for fifth regressor: {mae_five} - sixth regressor: {mae_six}')\n",
    "print(f'mae for seventh regressor: {mae_seven} - eighth regressor: {mae_eight}')\n",
    "print(f'mae for nineth regressor: {mae_nine} - tenth regressor: {mae_ten}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTING NEXT STEPS AFTER PREDICTION F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_Basement/slab</th>\n",
       "      <th>area_Roof/attic</th>\n",
       "      <th>area_Walls</th>\n",
       "      <th>area_doors</th>\n",
       "      <th>area_windows</th>\n",
       "      <th>U_Basement/slab</th>\n",
       "      <th>U_Roof/attic</th>\n",
       "      <th>U_Walls</th>\n",
       "      <th>U_doors</th>\n",
       "      <th>U_windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>933.785980</td>\n",
       "      <td>717.532488</td>\n",
       "      <td>3734.559384</td>\n",
       "      <td>24.830557</td>\n",
       "      <td>951.298571</td>\n",
       "      <td>0.703506</td>\n",
       "      <td>0.689101</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>2.322916</td>\n",
       "      <td>1.931714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>896.943659</td>\n",
       "      <td>838.576964</td>\n",
       "      <td>2461.632387</td>\n",
       "      <td>34.431587</td>\n",
       "      <td>624.226379</td>\n",
       "      <td>0.735581</td>\n",
       "      <td>0.777442</td>\n",
       "      <td>0.986852</td>\n",
       "      <td>2.669783</td>\n",
       "      <td>2.012945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387.132692</td>\n",
       "      <td>439.205562</td>\n",
       "      <td>783.223522</td>\n",
       "      <td>5.212477</td>\n",
       "      <td>212.515931</td>\n",
       "      <td>0.762856</td>\n",
       "      <td>3.217957</td>\n",
       "      <td>1.187156</td>\n",
       "      <td>2.906799</td>\n",
       "      <td>1.983636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585.186606</td>\n",
       "      <td>614.386545</td>\n",
       "      <td>1405.458001</td>\n",
       "      <td>14.127585</td>\n",
       "      <td>423.774434</td>\n",
       "      <td>0.784145</td>\n",
       "      <td>2.359344</td>\n",
       "      <td>1.191831</td>\n",
       "      <td>2.943692</td>\n",
       "      <td>2.025503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313.327709</td>\n",
       "      <td>370.894214</td>\n",
       "      <td>608.955564</td>\n",
       "      <td>3.437213</td>\n",
       "      <td>150.091119</td>\n",
       "      <td>0.757889</td>\n",
       "      <td>3.497023</td>\n",
       "      <td>1.184594</td>\n",
       "      <td>2.910205</td>\n",
       "      <td>1.974913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>527.071159</td>\n",
       "      <td>561.433250</td>\n",
       "      <td>1268.232009</td>\n",
       "      <td>11.946701</td>\n",
       "      <td>373.146208</td>\n",
       "      <td>0.778487</td>\n",
       "      <td>2.565284</td>\n",
       "      <td>1.192027</td>\n",
       "      <td>2.946333</td>\n",
       "      <td>2.022137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>317.893587</td>\n",
       "      <td>374.989571</td>\n",
       "      <td>619.470947</td>\n",
       "      <td>3.524842</td>\n",
       "      <td>153.274267</td>\n",
       "      <td>0.758406</td>\n",
       "      <td>3.483023</td>\n",
       "      <td>1.184589</td>\n",
       "      <td>2.908999</td>\n",
       "      <td>1.974499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>838.313361</td>\n",
       "      <td>904.888430</td>\n",
       "      <td>3226.908986</td>\n",
       "      <td>26.731844</td>\n",
       "      <td>1017.769174</td>\n",
       "      <td>0.737161</td>\n",
       "      <td>0.490867</td>\n",
       "      <td>0.938143</td>\n",
       "      <td>2.925997</td>\n",
       "      <td>2.079286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>494.721338</td>\n",
       "      <td>543.369728</td>\n",
       "      <td>2296.899587</td>\n",
       "      <td>55.802346</td>\n",
       "      <td>578.616762</td>\n",
       "      <td>0.532925</td>\n",
       "      <td>1.301909</td>\n",
       "      <td>0.898006</td>\n",
       "      <td>2.727990</td>\n",
       "      <td>1.930641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>322.009408</td>\n",
       "      <td>378.664421</td>\n",
       "      <td>629.004843</td>\n",
       "      <td>3.604182</td>\n",
       "      <td>156.208916</td>\n",
       "      <td>0.758572</td>\n",
       "      <td>3.468353</td>\n",
       "      <td>1.184255</td>\n",
       "      <td>2.907675</td>\n",
       "      <td>1.974024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1823.461394</td>\n",
       "      <td>1746.368815</td>\n",
       "      <td>4982.888239</td>\n",
       "      <td>98.018806</td>\n",
       "      <td>1635.089872</td>\n",
       "      <td>0.888394</td>\n",
       "      <td>0.397640</td>\n",
       "      <td>1.042499</td>\n",
       "      <td>3.206580</td>\n",
       "      <td>2.318479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>897.165001</td>\n",
       "      <td>837.985548</td>\n",
       "      <td>2461.381377</td>\n",
       "      <td>34.394848</td>\n",
       "      <td>624.020980</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.786804</td>\n",
       "      <td>0.986404</td>\n",
       "      <td>2.666875</td>\n",
       "      <td>2.011452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>622.734216</td>\n",
       "      <td>603.384828</td>\n",
       "      <td>1631.949868</td>\n",
       "      <td>15.398134</td>\n",
       "      <td>373.183669</td>\n",
       "      <td>0.745007</td>\n",
       "      <td>0.585158</td>\n",
       "      <td>0.975847</td>\n",
       "      <td>2.990662</td>\n",
       "      <td>2.007442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>315.985267</td>\n",
       "      <td>373.270828</td>\n",
       "      <td>615.099158</td>\n",
       "      <td>3.488364</td>\n",
       "      <td>151.966789</td>\n",
       "      <td>0.758064</td>\n",
       "      <td>3.488023</td>\n",
       "      <td>1.184414</td>\n",
       "      <td>2.909404</td>\n",
       "      <td>1.974632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>536.171571</td>\n",
       "      <td>570.187537</td>\n",
       "      <td>1290.072623</td>\n",
       "      <td>12.318626</td>\n",
       "      <td>381.291405</td>\n",
       "      <td>0.780623</td>\n",
       "      <td>2.531952</td>\n",
       "      <td>1.193576</td>\n",
       "      <td>2.949342</td>\n",
       "      <td>2.025689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>383.694788</td>\n",
       "      <td>440.301139</td>\n",
       "      <td>1105.278551</td>\n",
       "      <td>15.119463</td>\n",
       "      <td>258.631926</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.744889</td>\n",
       "      <td>1.006596</td>\n",
       "      <td>2.781114</td>\n",
       "      <td>1.900863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>237.159524</td>\n",
       "      <td>309.475034</td>\n",
       "      <td>682.028967</td>\n",
       "      <td>8.651078</td>\n",
       "      <td>119.188504</td>\n",
       "      <td>0.622228</td>\n",
       "      <td>0.703747</td>\n",
       "      <td>1.010970</td>\n",
       "      <td>2.784937</td>\n",
       "      <td>1.877287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>375.843875</td>\n",
       "      <td>429.136923</td>\n",
       "      <td>756.676769</td>\n",
       "      <td>4.925423</td>\n",
       "      <td>202.775173</td>\n",
       "      <td>0.762724</td>\n",
       "      <td>3.259449</td>\n",
       "      <td>1.188159</td>\n",
       "      <td>2.910406</td>\n",
       "      <td>1.984969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>323.233124</td>\n",
       "      <td>386.282275</td>\n",
       "      <td>963.375797</td>\n",
       "      <td>12.216031</td>\n",
       "      <td>206.470646</td>\n",
       "      <td>0.626844</td>\n",
       "      <td>0.717972</td>\n",
       "      <td>1.008855</td>\n",
       "      <td>2.789077</td>\n",
       "      <td>1.895213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>614.391067</td>\n",
       "      <td>616.144578</td>\n",
       "      <td>2413.303166</td>\n",
       "      <td>43.225231</td>\n",
       "      <td>648.938353</td>\n",
       "      <td>0.718573</td>\n",
       "      <td>0.901820</td>\n",
       "      <td>1.047618</td>\n",
       "      <td>2.943359</td>\n",
       "      <td>2.070289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>614.742684</td>\n",
       "      <td>620.415059</td>\n",
       "      <td>2338.369141</td>\n",
       "      <td>41.621502</td>\n",
       "      <td>630.579117</td>\n",
       "      <td>0.708305</td>\n",
       "      <td>0.893974</td>\n",
       "      <td>1.039405</td>\n",
       "      <td>2.920044</td>\n",
       "      <td>2.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>438.461961</td>\n",
       "      <td>258.934667</td>\n",
       "      <td>2633.748086</td>\n",
       "      <td>6.549357</td>\n",
       "      <td>535.400918</td>\n",
       "      <td>0.611276</td>\n",
       "      <td>1.168271</td>\n",
       "      <td>0.969059</td>\n",
       "      <td>2.372959</td>\n",
       "      <td>1.841907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>288.308202</td>\n",
       "      <td>352.861391</td>\n",
       "      <td>879.431495</td>\n",
       "      <td>10.823004</td>\n",
       "      <td>175.255052</td>\n",
       "      <td>0.627296</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>1.013244</td>\n",
       "      <td>2.789419</td>\n",
       "      <td>1.894316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>329.123469</td>\n",
       "      <td>386.600063</td>\n",
       "      <td>1052.002792</td>\n",
       "      <td>14.011143</td>\n",
       "      <td>229.719688</td>\n",
       "      <td>0.632952</td>\n",
       "      <td>0.748552</td>\n",
       "      <td>1.014766</td>\n",
       "      <td>2.796389</td>\n",
       "      <td>1.911096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>319.129385</td>\n",
       "      <td>381.434014</td>\n",
       "      <td>952.582769</td>\n",
       "      <td>11.961074</td>\n",
       "      <td>202.335558</td>\n",
       "      <td>0.626454</td>\n",
       "      <td>0.724685</td>\n",
       "      <td>1.010278</td>\n",
       "      <td>2.787215</td>\n",
       "      <td>1.895553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>380.054856</td>\n",
       "      <td>432.907605</td>\n",
       "      <td>766.534456</td>\n",
       "      <td>5.034375</td>\n",
       "      <td>206.407221</td>\n",
       "      <td>0.763149</td>\n",
       "      <td>3.245862</td>\n",
       "      <td>1.188139</td>\n",
       "      <td>2.909204</td>\n",
       "      <td>1.984513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>261.390986</td>\n",
       "      <td>328.192889</td>\n",
       "      <td>815.455299</td>\n",
       "      <td>10.102187</td>\n",
       "      <td>151.740307</td>\n",
       "      <td>0.628093</td>\n",
       "      <td>0.719701</td>\n",
       "      <td>1.014503</td>\n",
       "      <td>2.792456</td>\n",
       "      <td>1.892020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>607.224142</td>\n",
       "      <td>691.519284</td>\n",
       "      <td>2677.802351</td>\n",
       "      <td>16.271592</td>\n",
       "      <td>814.936524</td>\n",
       "      <td>0.717754</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.907283</td>\n",
       "      <td>2.912162</td>\n",
       "      <td>2.015383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>223.231547</td>\n",
       "      <td>296.101422</td>\n",
       "      <td>647.455701</td>\n",
       "      <td>8.302948</td>\n",
       "      <td>110.310995</td>\n",
       "      <td>0.622682</td>\n",
       "      <td>0.710764</td>\n",
       "      <td>1.012275</td>\n",
       "      <td>2.785856</td>\n",
       "      <td>1.876515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>599.875158</td>\n",
       "      <td>681.003774</td>\n",
       "      <td>2736.293419</td>\n",
       "      <td>17.203993</td>\n",
       "      <td>827.258350</td>\n",
       "      <td>0.717307</td>\n",
       "      <td>0.631986</td>\n",
       "      <td>0.901666</td>\n",
       "      <td>2.938162</td>\n",
       "      <td>2.027964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>347.727271</td>\n",
       "      <td>452.302415</td>\n",
       "      <td>2061.291450</td>\n",
       "      <td>7.734637</td>\n",
       "      <td>587.268428</td>\n",
       "      <td>0.713025</td>\n",
       "      <td>0.876186</td>\n",
       "      <td>0.894380</td>\n",
       "      <td>2.931358</td>\n",
       "      <td>1.978319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>440.229170</td>\n",
       "      <td>488.051290</td>\n",
       "      <td>1314.840835</td>\n",
       "      <td>19.583923</td>\n",
       "      <td>326.660934</td>\n",
       "      <td>0.634389</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>1.007758</td>\n",
       "      <td>2.787001</td>\n",
       "      <td>1.919177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>697.294762</td>\n",
       "      <td>495.176019</td>\n",
       "      <td>3248.363115</td>\n",
       "      <td>14.715814</td>\n",
       "      <td>762.369746</td>\n",
       "      <td>0.651814</td>\n",
       "      <td>0.920129</td>\n",
       "      <td>0.973577</td>\n",
       "      <td>2.345915</td>\n",
       "      <td>1.887395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>586.795863</td>\n",
       "      <td>615.823625</td>\n",
       "      <td>1409.237005</td>\n",
       "      <td>14.186104</td>\n",
       "      <td>425.162836</td>\n",
       "      <td>0.784217</td>\n",
       "      <td>2.353682</td>\n",
       "      <td>1.191721</td>\n",
       "      <td>2.943403</td>\n",
       "      <td>2.025408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>717.119386</td>\n",
       "      <td>672.951767</td>\n",
       "      <td>2034.864147</td>\n",
       "      <td>25.671897</td>\n",
       "      <td>466.614820</td>\n",
       "      <td>0.724630</td>\n",
       "      <td>1.006534</td>\n",
       "      <td>0.989231</td>\n",
       "      <td>2.674753</td>\n",
       "      <td>1.987614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>419.032545</td>\n",
       "      <td>465.347879</td>\n",
       "      <td>935.332848</td>\n",
       "      <td>6.993542</td>\n",
       "      <td>259.489801</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>3.037147</td>\n",
       "      <td>1.189632</td>\n",
       "      <td>2.924777</td>\n",
       "      <td>1.999446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>420.363083</td>\n",
       "      <td>466.530827</td>\n",
       "      <td>938.473139</td>\n",
       "      <td>7.030531</td>\n",
       "      <td>260.638254</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>3.031776</td>\n",
       "      <td>1.189434</td>\n",
       "      <td>2.924465</td>\n",
       "      <td>1.999278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>672.295643</td>\n",
       "      <td>628.642208</td>\n",
       "      <td>2004.769703</td>\n",
       "      <td>25.080656</td>\n",
       "      <td>446.400249</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>1.057626</td>\n",
       "      <td>0.993832</td>\n",
       "      <td>2.697789</td>\n",
       "      <td>1.991662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>653.618989</td>\n",
       "      <td>703.182101</td>\n",
       "      <td>1742.418173</td>\n",
       "      <td>15.239165</td>\n",
       "      <td>517.651067</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>0.641316</td>\n",
       "      <td>0.963297</td>\n",
       "      <td>2.722691</td>\n",
       "      <td>1.951491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>644.581635</td>\n",
       "      <td>248.709244</td>\n",
       "      <td>2524.246988</td>\n",
       "      <td>4.114202</td>\n",
       "      <td>576.914084</td>\n",
       "      <td>0.621721</td>\n",
       "      <td>1.148890</td>\n",
       "      <td>0.936397</td>\n",
       "      <td>2.540258</td>\n",
       "      <td>1.836175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>721.183191</td>\n",
       "      <td>740.834365</td>\n",
       "      <td>1729.423510</td>\n",
       "      <td>19.427990</td>\n",
       "      <td>543.577099</td>\n",
       "      <td>0.802164</td>\n",
       "      <td>1.862640</td>\n",
       "      <td>1.197053</td>\n",
       "      <td>2.956659</td>\n",
       "      <td>2.052273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>580.208159</td>\n",
       "      <td>634.649701</td>\n",
       "      <td>1567.188759</td>\n",
       "      <td>12.793769</td>\n",
       "      <td>452.830493</td>\n",
       "      <td>0.707295</td>\n",
       "      <td>0.706229</td>\n",
       "      <td>0.967752</td>\n",
       "      <td>2.715112</td>\n",
       "      <td>1.947995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>772.410396</td>\n",
       "      <td>787.586711</td>\n",
       "      <td>1850.623921</td>\n",
       "      <td>21.463777</td>\n",
       "      <td>588.267355</td>\n",
       "      <td>0.807844</td>\n",
       "      <td>1.695815</td>\n",
       "      <td>1.196269</td>\n",
       "      <td>2.955411</td>\n",
       "      <td>2.057935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>508.085909</td>\n",
       "      <td>499.972013</td>\n",
       "      <td>1854.732077</td>\n",
       "      <td>7.894390</td>\n",
       "      <td>396.484358</td>\n",
       "      <td>0.518087</td>\n",
       "      <td>0.602190</td>\n",
       "      <td>0.815447</td>\n",
       "      <td>2.632201</td>\n",
       "      <td>1.712224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>229.493174</td>\n",
       "      <td>302.229565</td>\n",
       "      <td>663.083952</td>\n",
       "      <td>8.460958</td>\n",
       "      <td>114.301981</td>\n",
       "      <td>0.622530</td>\n",
       "      <td>0.707445</td>\n",
       "      <td>1.011518</td>\n",
       "      <td>2.785722</td>\n",
       "      <td>1.876855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>583.379518</td>\n",
       "      <td>612.773440</td>\n",
       "      <td>1401.212507</td>\n",
       "      <td>14.061886</td>\n",
       "      <td>422.215289</td>\n",
       "      <td>0.784075</td>\n",
       "      <td>2.365781</td>\n",
       "      <td>1.191963</td>\n",
       "      <td>2.944027</td>\n",
       "      <td>2.025620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>544.237535</td>\n",
       "      <td>577.801974</td>\n",
       "      <td>1309.348150</td>\n",
       "      <td>12.638134</td>\n",
       "      <td>388.446896</td>\n",
       "      <td>0.782013</td>\n",
       "      <td>2.501785</td>\n",
       "      <td>1.194370</td>\n",
       "      <td>2.950898</td>\n",
       "      <td>2.027861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>547.521525</td>\n",
       "      <td>580.733381</td>\n",
       "      <td>1317.063603</td>\n",
       "      <td>12.757525</td>\n",
       "      <td>391.280311</td>\n",
       "      <td>0.782138</td>\n",
       "      <td>2.490017</td>\n",
       "      <td>1.194128</td>\n",
       "      <td>2.950288</td>\n",
       "      <td>2.027648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>312.748410</td>\n",
       "      <td>370.363908</td>\n",
       "      <td>607.656417</td>\n",
       "      <td>3.426318</td>\n",
       "      <td>149.737955</td>\n",
       "      <td>0.757633</td>\n",
       "      <td>3.497481</td>\n",
       "      <td>1.184366</td>\n",
       "      <td>2.910208</td>\n",
       "      <td>1.974892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>629.442518</td>\n",
       "      <td>656.893958</td>\n",
       "      <td>1512.191224</td>\n",
       "      <td>15.949593</td>\n",
       "      <td>463.440280</td>\n",
       "      <td>0.792775</td>\n",
       "      <td>2.178392</td>\n",
       "      <td>1.197396</td>\n",
       "      <td>2.957343</td>\n",
       "      <td>2.042138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>703.211182</td>\n",
       "      <td>500.252006</td>\n",
       "      <td>3262.094545</td>\n",
       "      <td>14.940101</td>\n",
       "      <td>767.376108</td>\n",
       "      <td>0.652479</td>\n",
       "      <td>0.915982</td>\n",
       "      <td>0.973509</td>\n",
       "      <td>2.344435</td>\n",
       "      <td>1.887195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>682.799874</td>\n",
       "      <td>486.181652</td>\n",
       "      <td>3138.585706</td>\n",
       "      <td>12.835605</td>\n",
       "      <td>731.202224</td>\n",
       "      <td>0.647223</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.973044</td>\n",
       "      <td>2.324795</td>\n",
       "      <td>1.877111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area_Basement/slab  area_Roof/attic   area_Walls  area_doors  \\\n",
       "0           933.785980       717.532488  3734.559384   24.830557   \n",
       "1           896.943659       838.576964  2461.632387   34.431587   \n",
       "2           387.132692       439.205562   783.223522    5.212477   \n",
       "3           585.186606       614.386545  1405.458001   14.127585   \n",
       "4           313.327709       370.894214   608.955564    3.437213   \n",
       "5           527.071159       561.433250  1268.232009   11.946701   \n",
       "6           317.893587       374.989571   619.470947    3.524842   \n",
       "7           838.313361       904.888430  3226.908986   26.731844   \n",
       "8           494.721338       543.369728  2296.899587   55.802346   \n",
       "9           322.009408       378.664421   629.004843    3.604182   \n",
       "10         1823.461394      1746.368815  4982.888239   98.018806   \n",
       "11          897.165001       837.985548  2461.381377   34.394848   \n",
       "12          622.734216       603.384828  1631.949868   15.398134   \n",
       "13          315.985267       373.270828   615.099158    3.488364   \n",
       "14          536.171571       570.187537  1290.072623   12.318626   \n",
       "15          383.694788       440.301139  1105.278551   15.119463   \n",
       "16          237.159524       309.475034   682.028967    8.651078   \n",
       "17          375.843875       429.136923   756.676769    4.925423   \n",
       "18          323.233124       386.282275   963.375797   12.216031   \n",
       "19          614.391067       616.144578  2413.303166   43.225231   \n",
       "20          614.742684       620.415059  2338.369141   41.621502   \n",
       "21          438.461961       258.934667  2633.748086    6.549357   \n",
       "22          288.308202       352.861391   879.431495   10.823004   \n",
       "23          329.123469       386.600063  1052.002792   14.011143   \n",
       "24          319.129385       381.434014   952.582769   11.961074   \n",
       "25          380.054856       432.907605   766.534456    5.034375   \n",
       "26          261.390986       328.192889   815.455299   10.102187   \n",
       "27          607.224142       691.519284  2677.802351   16.271592   \n",
       "28          223.231547       296.101422   647.455701    8.302948   \n",
       "29          599.875158       681.003774  2736.293419   17.203993   \n",
       "30          347.727271       452.302415  2061.291450    7.734637   \n",
       "31          440.229170       488.051290  1314.840835   19.583923   \n",
       "32          697.294762       495.176019  3248.363115   14.715814   \n",
       "33          586.795863       615.823625  1409.237005   14.186104   \n",
       "34          717.119386       672.951767  2034.864147   25.671897   \n",
       "35          419.032545       465.347879   935.332848    6.993542   \n",
       "36          420.363083       466.530827   938.473139    7.030531   \n",
       "37          672.295643       628.642208  2004.769703   25.080656   \n",
       "38          653.618989       703.182101  1742.418173   15.239165   \n",
       "39          644.581635       248.709244  2524.246988    4.114202   \n",
       "40          721.183191       740.834365  1729.423510   19.427990   \n",
       "41          580.208159       634.649701  1567.188759   12.793769   \n",
       "42          772.410396       787.586711  1850.623921   21.463777   \n",
       "43          508.085909       499.972013  1854.732077    7.894390   \n",
       "44          229.493174       302.229565   663.083952    8.460958   \n",
       "45          583.379518       612.773440  1401.212507   14.061886   \n",
       "46          544.237535       577.801974  1309.348150   12.638134   \n",
       "47          547.521525       580.733381  1317.063603   12.757525   \n",
       "48          312.748410       370.363908   607.656417    3.426318   \n",
       "49          629.442518       656.893958  1512.191224   15.949593   \n",
       "50          703.211182       500.252006  3262.094545   14.940101   \n",
       "51          682.799874       486.181652  3138.585706   12.835605   \n",
       "\n",
       "    area_windows  U_Basement/slab  U_Roof/attic   U_Walls   U_doors  U_windows  \n",
       "0     951.298571         0.703506      0.689101  0.999985  2.322916   1.931714  \n",
       "1     624.226379         0.735581      0.777442  0.986852  2.669783   2.012945  \n",
       "2     212.515931         0.762856      3.217957  1.187156  2.906799   1.983636  \n",
       "3     423.774434         0.784145      2.359344  1.191831  2.943692   2.025503  \n",
       "4     150.091119         0.757889      3.497023  1.184594  2.910205   1.974913  \n",
       "5     373.146208         0.778487      2.565284  1.192027  2.946333   2.022137  \n",
       "6     153.274267         0.758406      3.483023  1.184589  2.908999   1.974499  \n",
       "7    1017.769174         0.737161      0.490867  0.938143  2.925997   2.079286  \n",
       "8     578.616762         0.532925      1.301909  0.898006  2.727990   1.930641  \n",
       "9     156.208916         0.758572      3.468353  1.184255  2.907675   1.974024  \n",
       "10   1635.089872         0.888394      0.397640  1.042499  3.206580   2.318479  \n",
       "11    624.020980         0.735218      0.786804  0.986404  2.666875   2.011452  \n",
       "12    373.183669         0.745007      0.585158  0.975847  2.990662   2.007442  \n",
       "13    151.966789         0.758064      3.488023  1.184414  2.909404   1.974632  \n",
       "14    381.291405         0.780623      2.531952  1.193576  2.949342   2.025689  \n",
       "15    258.631926         0.626164      0.744889  1.006596  2.781114   1.900863  \n",
       "16    119.188504         0.622228      0.703747  1.010970  2.784937   1.877287  \n",
       "17    202.775173         0.762724      3.259449  1.188159  2.910406   1.984969  \n",
       "18    206.470646         0.626844      0.717972  1.008855  2.789077   1.895213  \n",
       "19    648.938353         0.718573      0.901820  1.047618  2.943359   2.070289  \n",
       "20    630.579117         0.708305      0.893974  1.039405  2.920044   2.053458  \n",
       "21    535.400918         0.611276      1.168271  0.969059  2.372959   1.841907  \n",
       "22    175.255052         0.627296      0.721534  1.013244  2.789419   1.894316  \n",
       "23    229.719688         0.632952      0.748552  1.014766  2.796389   1.911096  \n",
       "24    202.335558         0.626454      0.724685  1.010278  2.787215   1.895553  \n",
       "25    206.407221         0.763149      3.245862  1.188139  2.909204   1.984513  \n",
       "26    151.740307         0.628093      0.719701  1.014503  2.792456   1.892020  \n",
       "27    814.936524         0.717754      0.650894  0.907283  2.912162   2.015383  \n",
       "28    110.310995         0.622682      0.710764  1.012275  2.785856   1.876515  \n",
       "29    827.258350         0.717307      0.631986  0.901666  2.938162   2.027964  \n",
       "30    587.268428         0.713025      0.876186  0.894380  2.931358   1.978319  \n",
       "31    326.660934         0.634389      0.781421  1.007758  2.787001   1.919177  \n",
       "32    762.369746         0.651814      0.920129  0.973577  2.345915   1.887395  \n",
       "33    425.162836         0.784217      2.353682  1.191721  2.943403   2.025408  \n",
       "34    466.614820         0.724630      1.006534  0.989231  2.674753   1.987614  \n",
       "35    259.489801         0.767776      3.037147  1.189632  2.924777   1.999446  \n",
       "36    260.638254         0.767700      3.031776  1.189434  2.924465   1.999278  \n",
       "37    446.400249         0.732500      1.057626  0.993832  2.697789   1.991662  \n",
       "38    517.651067         0.705745      0.641316  0.963297  2.722691   1.951491  \n",
       "39    576.914084         0.621721      1.148890  0.936397  2.540258   1.836175  \n",
       "40    543.577099         0.802164      1.862640  1.197053  2.956659   2.052273  \n",
       "41    452.830493         0.707295      0.706229  0.967752  2.715112   1.947995  \n",
       "42    588.267355         0.807844      1.695815  1.196269  2.955411   2.057935  \n",
       "43    396.484358         0.518087      0.602190  0.815447  2.632201   1.712224  \n",
       "44    114.301981         0.622530      0.707445  1.011518  2.785722   1.876855  \n",
       "45    422.215289         0.784075      2.365781  1.191963  2.944027   2.025620  \n",
       "46    388.446896         0.782013      2.501785  1.194370  2.950898   2.027861  \n",
       "47    391.280311         0.782138      2.490017  1.194128  2.950288   2.027648  \n",
       "48    149.737955         0.757633      3.497481  1.184366  2.910208   1.974892  \n",
       "49    463.440280         0.792775      2.178392  1.197396  2.957343   2.042138  \n",
       "50    767.376108         0.652479      0.915982  0.973509  2.344435   1.887195  \n",
       "51    731.202224         0.647223      0.931343  0.973044  2.324795   1.877111  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(y_pred, columns = ['area_Basement/slab',\t'area_Roof/attic',\t'area_Walls',\t'area_doors',\t'area_windows',\t'U_Basement/slab',\t'U_Roof/attic',\t'U_Walls',\t'U_doors',\t'U_windows'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area_Basement', 'area_Roof', 'area_Walls', 'area_doors',\n",
       "       'area_windows', 'U_Basement', 'U_Roof', 'U_Walls', 'U_doors',\n",
       "       'U_windows'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.rename(columns={\"area_Basement/slab\": \"area_Basement\", \"area_Roof/attic\": \"area_Roof\", \"U_Roof/attic\": \"U_Roof\", \"U_Basement/slab\": \"U_Basement\"}, inplace=True)\n",
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39massign(q1\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39marea_Basement\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mU_Basement\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m(\u001b[39m18.9\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m192\u001b[39m\u001b[39m*\u001b[39m\u001b[39m24\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      2\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39massign(q2\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39marea_Roof\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mU_Roof\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m (\u001b[39m18.9\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m192\u001b[39m\u001b[39m*\u001b[39m\u001b[39m24\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      3\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39massign(q3\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39marea_Walls\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mU_Walls\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m(\u001b[39m18.9\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m192\u001b[39m\u001b[39m*\u001b[39m\u001b[39m24\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results = results.assign(q1=lambda x: x['area_Basement']* x['U_Basement'] *(18.9)*192*24/1000)\n",
    "results = results.assign(q2=lambda x: x['area_Roof']* x['U_Roof']* (18.9)*192*24/1000)\n",
    "results = results.assign(q3=lambda x: x['area_Walls']* x['U_Walls'] *(18.9)*192*24/1000)\n",
    "results = results.assign(q4=lambda x: x['area_doors']* x['U_doors'] *(18.9)*192*24/1000)\n",
    "results = results.assign(q5=lambda x: x['area_windows']* x['U_windows']* (18.9)*192*24/1000)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
